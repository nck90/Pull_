{
  "repo_name": "langflow-ai/langflow",
  "repo_url": "https://github.com/langflow-ai/langflow",
  "description": "Langflow is a powerful tool for building and deploying AI-powered agents and workflows.",
  "stars": 52040,
  "language": "Python",
  "created_at": "2023-02-08T22:28:03Z",
  "updated_at": "2025-03-19T07:05:56Z",
  "files": {
    "src/backend/tests/__init__.py": "\"\"\"Tests package for langflow.\"\"\"\n",
    "src/backend/tests/api_keys.py": "import os.path\n\n# we need to import tmpdir\n\n\ndef get_required_env_var(var: str) -> str:\n    \"\"\"Get the value of the specified environment variable.\n\n    Args:\n    var (str): The environment variable to get.\n\n    Returns:\n    str: The value of the environment variable.\n\n    Raises:\n    ValueError: If the environment variable is not set.\n    \"\"\"\n    value = os.getenv(var)\n    if not value:\n        msg = f\"Environment variable {var} is not set\"\n        raise ValueError(msg)\n    return value\n\n\ndef get_openai_api_key() -> str:\n    return get_required_env_var(\"OPENAI_API_KEY\")\n\n\ndef get_astradb_application_token() -> str:\n    return get_required_env_var(\"ASTRA_DB_APPLICATION_TOKEN\")\n\n\ndef get_astradb_api_endpoint() -> str:\n    return get_required_env_var(\"ASTRA_DB_API_ENDPOINT\")\n",
    "src/backend/tests/base.py": "import asyncio\nimport inspect\nfrom typing import Any\nfrom unittest.mock import Mock\nfrom uuid import uuid4\n\nimport pytest\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.graph.graph.base import Graph\nfrom langflow.graph.vertex.base import Vertex\nfrom typing_extensions import TypedDict\n\nfrom tests.constants import SUPPORTED_VERSIONS\nfrom tests.integration.utils import build_component_instance_for_tests\n\n\nclass VersionComponentMapping(TypedDict):\n    version: str\n    module: str\n    file_name: str\n\n\n# Sentinel value to mark undefined test cases\nDID_NOT_EXIST = object()\n\n\nclass ComponentTestBase:\n    @pytest.fixture(autouse=True)\n    def _validate_required_fixtures(\n        self,\n        component_class: type[Any],\n        default_kwargs: dict[str, Any],\n        file_names_mapping: list[VersionComponentMapping],\n    ) -> None:\n        \"\"\"Validate that all required fixtures are implemented.\"\"\"\n        # If we get here, all fixtures exist\n\n    @pytest.fixture\n    def component_class(self) -> type[Any]:\n        \"\"\"Return the component class to test.\"\"\"\n        msg = f\"{self.__class__.__name__} must implement the component_class fixture\"\n        raise NotImplementedError(msg)\n\n    @pytest.fixture\n    def default_kwargs(self) -> dict[str, Any]:\n        \"\"\"Return the default kwargs for the component.\"\"\"\n        return {}\n\n    @pytest.fixture\n    def file_names_mapping(self) -> list[VersionComponentMapping]:\n        \"\"\"Return the file names mapping for different versions.\"\"\"\n        msg = f\"{self.__class__.__name__} must implement the file_names_mapping fixture\"\n        raise NotImplementedError(msg)\n\n    async def component_setup(self, component_class: type[Any], default_kwargs: dict[str, Any]) -> Component:\n        mock_vertex = Mock(spec=Vertex)\n        mock_vertex.graph = Mock(spec=Graph)\n        mock_vertex.graph.session_id = str(uuid4())\n        mock_vertex.graph.flow_id = str(uuid4())\n        source_code = await asyncio.to_thread(inspect.getsource, component_class)\n        component_instance = component_class(_code=source_code, **default_kwargs)\n        component_instance._should_process_output = Mock(return_value=False)\n        component_instance._vertex = mock_vertex\n        return component_instance\n\n    async def test_latest_version(self, component_class: type[Any], default_kwargs: dict[str, Any]) -> None:\n        \"\"\"Test that the component works with the latest version.\"\"\"\n        component_instance = await self.component_setup(component_class, default_kwargs)\n        result = await component_instance.run()\n        assert result is not None, \"Component returned None for the latest version.\"\n\n    def test_all_versions_have_a_file_name_defined(self, file_names_mapping: list[VersionComponentMapping]) -> None:\n        \"\"\"Ensure all supported versions have a file name defined.\"\"\"\n        if not file_names_mapping:\n            msg = f\"file_names_mapping is empty for {self.__class__.__name__}. Skipping versions test.\"\n            pytest.skip(msg)\n\n        version_mappings = {mapping[\"version\"]: mapping for mapping in file_names_mapping}\n\n        for version in SUPPORTED_VERSIONS:\n            if version not in version_mappings:\n                supported_versions = \", \".join(sorted(m[\"version\"] for m in file_names_mapping))\n                msg = (\n                    f\"Version {version} not found in file_names_mapping for {self.__class__.__name__}.\\n\"\n                    f\"Currently defined versions: {supported_versions}\\n\"\n                    \"Please add this version to your component's file_names_mapping.\"\n                )\n                raise AssertionError(msg)\n\n            mapping = version_mappings[version]\n            if mapping[\"file_name\"] is None:\n                msg = (\n                    f\"file_name is None for version {version} in {self.__class__.__name__}.\\n\"\n                    \"Please provide a valid file_name in file_names_mapping or set it to DID_NOT_EXIST.\"\n                )\n                raise AssertionError(msg)\n\n            if mapping[\"module\"] is None:\n                msg = (\n                    f\"module is None for version {version} in {self.__class__.__name__}.\\n\"\n                    \"Please provide a valid module name in file_names_mapping or set it to DID_NOT_EXIST.\"\n                )\n                raise AssertionError(msg)\n\n    @pytest.mark.parametrize(\"version\", SUPPORTED_VERSIONS)\n    def test_component_versions(\n        self,\n        version: str,\n        default_kwargs: dict[str, Any],\n        file_names_mapping: list[VersionComponentMapping],\n    ) -> None:\n        \"\"\"Test if the component works across different versions.\"\"\"\n        if not file_names_mapping:\n            pytest.skip(\"No file names mapping defined for this component.\")\n        version_mappings = {mapping[\"version\"]: mapping for mapping in file_names_mapping}\n\n        mapping = version_mappings[version]\n        if mapping[\"file_name\"] is DID_NOT_EXIST:\n            pytest.skip(f\"Skipping version {version} as it does not have a file name defined.\")\n\n        try:\n            instance, component_code = build_component_instance_for_tests(\n                version, file_name=mapping[\"file_name\"], module=mapping[\"module\"], **default_kwargs\n            )\n        except Exception as e:\n            msg = (\n                f\"Failed to build component instance for {self.__class__.__name__} \"\n                f\"version {version}:\\n\"\n                f\"Module: {mapping['module']}\\n\"\n                f\"File: {mapping['file_name']}\\n\"\n                f\"Error: {e!s}\"\n            )\n            raise AssertionError(msg) from e\n\n        try:\n            result = instance()\n        except Exception as e:\n            msg = (\n                f\"Failed to execute component {self.__class__.__name__} \"\n                f\"for version {version}:\\n\"\n                f\"Module: {mapping['module']}\\n\"\n                f\"File: {mapping['file_name']}\\n\"\n                f\"Error: {e!s}\\n\"\n                f\"Component Code: {component_code}\"\n            )\n            raise AssertionError(msg) from e\n\n        if result is None:\n            msg = (\n                f\"Component {self.__class__.__name__} returned None \"\n                f\"for version {version}.\\n\"\n                f\"Module: {mapping['module']}\\n\"\n                f\"File: {mapping['file_name']}\"\n            )\n            raise AssertionError(msg)\n\n\n@pytest.mark.usefixtures(\"client\")\nclass ComponentTestBaseWithClient(ComponentTestBase):\n    pass\n\n\nclass ComponentTestBaseWithoutClient(ComponentTestBase):\n    pass\n",
    "src/backend/tests/conftest.py": "import asyncio\nimport json\nimport shutil\n\n# we need to import tmpdir\nimport tempfile\nfrom collections.abc import AsyncGenerator\nfrom contextlib import suppress\nfrom pathlib import Path\nfrom uuid import UUID\n\nimport anyio\nimport orjson\nimport pytest\nfrom asgi_lifespan import LifespanManager\nfrom blockbuster import blockbuster_ctx\nfrom dotenv import load_dotenv\nfrom fastapi.testclient import TestClient\nfrom httpx import ASGITransport, AsyncClient\nfrom langflow.components.inputs import ChatInput\nfrom langflow.graph import Graph\nfrom langflow.initial_setup.constants import STARTER_FOLDER_NAME\nfrom langflow.main import create_app\nfrom langflow.services.auth.utils import get_password_hash\nfrom langflow.services.database.models.api_key.model import ApiKey\nfrom langflow.services.database.models.flow.model import Flow, FlowCreate\nfrom langflow.services.database.models.folder.model import Folder\nfrom langflow.services.database.models.transactions.model import TransactionTable\nfrom langflow.services.database.models.user.model import User, UserCreate, UserRead\nfrom langflow.services.database.models.vertex_builds.crud import delete_vertex_builds_by_flow_id\nfrom langflow.services.database.utils import session_getter\nfrom langflow.services.deps import get_db_service\nfrom loguru import logger\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy.orm import selectinload\nfrom sqlmodel import Session, SQLModel, create_engine, select\nfrom sqlmodel.ext.asyncio.session import AsyncSession\nfrom sqlmodel.pool import StaticPool\nfrom typer.testing import CliRunner\n\nfrom tests.api_keys import get_openai_api_key\n\nload_dotenv()\n\n\n@pytest.fixture(autouse=True)\ndef blockbuster(request):\n    if \"benchmark\" in request.keywords:\n        yield\n    else:\n        with blockbuster_ctx() as bb:\n            for func in [\n                \"io.BufferedReader.read\",\n                \"io.BufferedWriter.write\",\n                \"io.TextIOWrapper.read\",\n                \"io.TextIOWrapper.write\",\n                \"os.mkdir\",\n                \"os.stat\",\n                \"os.path.abspath\",\n            ]:\n                bb.functions[func].can_block_in(\"settings/service.py\", \"initialize\")\n            for func in [\n                \"io.BufferedReader.read\",\n                \"io.TextIOWrapper.read\",\n            ]:\n                bb.functions[func].can_block_in(\"importlib_metadata/__init__.py\", \"metadata\")\n\n            (\n                bb.functions[\"os.stat\"]\n                # TODO: make set_class_code async\n                .can_block_in(\"langflow/custom/custom_component/component.py\", \"set_class_code\")\n                # TODO: follow discussion in https://github.com/encode/httpx/discussions/3456\n                .can_block_in(\"httpx/_client.py\", \"_init_transport\")\n                .can_block_in(\"rich/traceback.py\", \"_render_stack\")\n                .can_block_in(\"langchain_core/_api/internal.py\", \"is_caller_internal\")\n                .can_block_in(\"langchain_core/runnables/utils.py\", \"get_function_nonlocals\")\n            )\n\n            for func in [\"os.stat\", \"os.path.abspath\", \"os.scandir\"]:\n                bb.functions[func].can_block_in(\"alembic/util/pyfiles.py\", \"load_python_file\")\n\n            for func in [\"os.path.abspath\", \"os.scandir\"]:\n                bb.functions[func].can_block_in(\"alembic/script/base.py\", \"_load_revisions\")\n\n            (\n                bb.functions[\"os.path.abspath\"]\n                .can_block_in(\"loguru/_better_exceptions.py\", {\"_get_lib_dirs\", \"_format_exception\"})\n                .can_block_in(\"sqlalchemy/dialects/sqlite/pysqlite.py\", \"create_connect_args\")\n            )\n            yield bb\n\n\ndef pytest_configure(config):\n    config.addinivalue_line(\"markers\", \"noclient: don't create a client for this test\")\n    config.addinivalue_line(\"markers\", \"load_flows: load the flows for this test\")\n    config.addinivalue_line(\"markers\", \"api_key_required: run only if the api key is set in the environment variables\")\n    data_path = Path(__file__).parent.absolute() / \"data\"\n\n    pytest.BASIC_EXAMPLE_PATH = data_path / \"basic_example.json\"\n    pytest.COMPLEX_EXAMPLE_PATH = data_path / \"complex_example.json\"\n    pytest.OPENAPI_EXAMPLE_PATH = data_path / \"Openapi.json\"\n    pytest.GROUPED_CHAT_EXAMPLE_PATH = data_path / \"grouped_chat.json\"\n    pytest.ONE_GROUPED_CHAT_EXAMPLE_PATH = data_path / \"one_group_chat.json\"\n    pytest.VECTOR_STORE_GROUPED_EXAMPLE_PATH = data_path / \"vector_store_grouped.json\"\n    pytest.WEBHOOK_TEST = data_path / \"WebhookTest.json\"\n\n    pytest.BASIC_CHAT_WITH_PROMPT_AND_HISTORY = data_path / \"BasicChatwithPromptandHistory.json\"\n    pytest.CHAT_INPUT = data_path / \"ChatInputTest.json\"\n    pytest.TWO_OUTPUTS = data_path / \"TwoOutputsTest.json\"\n    pytest.VECTOR_STORE_PATH = data_path / \"Vector_store.json\"\n    pytest.SIMPLE_API_TEST = data_path / \"SimpleAPITest.json\"\n    pytest.MEMORY_CHATBOT_NO_LLM = data_path / \"MemoryChatbotNoLLM.json\"\n    pytest.ENV_VARIABLE_TEST = data_path / \"env_variable_test.json\"\n    pytest.LOOP_TEST = data_path / \"LoopTest.json\"\n    pytest.CODE_WITH_SYNTAX_ERROR = \"\"\"\ndef get_text():\n    retun \"Hello World\"\n    \"\"\"\n\n    # validate that all the paths are correct and the files exist\n    for path in [\n        pytest.BASIC_EXAMPLE_PATH,\n        pytest.COMPLEX_EXAMPLE_PATH,\n        pytest.OPENAPI_EXAMPLE_PATH,\n        pytest.GROUPED_CHAT_EXAMPLE_PATH,\n        pytest.ONE_GROUPED_CHAT_EXAMPLE_PATH,\n        pytest.VECTOR_STORE_GROUPED_EXAMPLE_PATH,\n        pytest.BASIC_CHAT_WITH_PROMPT_AND_HISTORY,\n        pytest.CHAT_INPUT,\n        pytest.TWO_OUTPUTS,\n        pytest.VECTOR_STORE_PATH,\n        pytest.MEMORY_CHATBOT_NO_LLM,\n        pytest.LOOP_TEST,\n    ]:\n        assert path.exists(), f\"File {path} does not exist. Available files: {list(data_path.iterdir())}\"\n\n\nasync def delete_transactions_by_flow_id(db: AsyncSession, flow_id: UUID):\n    if not flow_id:\n        return\n    stmt = select(TransactionTable).where(TransactionTable.flow_id == flow_id)\n    transactions = await db.exec(stmt)\n    for transaction in transactions:\n        await db.delete(transaction)\n\n\nasync def _delete_transactions_and_vertex_builds(session, flows: list[Flow]):\n    flow_ids = [flow.id for flow in flows]\n    for flow_id in flow_ids:\n        if not flow_id:\n            continue\n        try:\n            await delete_vertex_builds_by_flow_id(session, flow_id)\n        except Exception as e:  # noqa: BLE001\n            logger.debug(f\"Error deleting vertex builds for flow {flow_id}: {e}\")\n        try:\n            await delete_transactions_by_flow_id(session, flow_id)\n        except Exception as e:  # noqa: BLE001\n            logger.debug(f\"Error deleting transactions for flow {flow_id}: {e}\")\n\n\n@pytest.fixture\ndef caplog(caplog: pytest.LogCaptureFixture):\n    handler_id = logger.add(\n        caplog.handler,\n        format=\"{message}\",\n        level=0,\n        filter=lambda record: record[\"level\"].no >= caplog.handler.level,\n        enqueue=False,  # Set to 'True' if your test is spawning child processes.\n    )\n    yield caplog\n    logger.remove(handler_id)\n\n\n@pytest.fixture\nasync def async_client() -> AsyncGenerator:\n    app = create_app()\n    async with AsyncClient(app=app, base_url=\"http://testserver\", http2=True) as client:\n        yield client\n\n\n@pytest.fixture(name=\"session\")\ndef session_fixture():\n    engine = create_engine(\"sqlite://\", connect_args={\"check_same_thread\": False}, poolclass=StaticPool)\n    SQLModel.metadata.create_all(engine)\n    with Session(engine) as session:\n        yield session\n    SQLModel.metadata.drop_all(engine)  # Add this line to clean up tables\n\n\n@pytest.fixture\nasync def async_session():\n    engine = create_async_engine(\"sqlite+aiosqlite://\", connect_args={\"check_same_thread\": False}, poolclass=StaticPool)\n    async with engine.begin() as conn:\n        await conn.run_sync(SQLModel.metadata.create_all)\n    async with AsyncSession(engine, expire_on_commit=False) as session:\n        yield session\n    async with engine.begin() as conn:\n        await conn.run_sync(SQLModel.metadata.drop_all)\n\n\nclass Config:\n    broker_url = \"redis://localhost:6379/0\"\n    result_backend = \"redis://localhost:6379/0\"\n\n\n@pytest.fixture(name=\"load_flows_dir\")\ndef load_flows_dir():\n    with tempfile.TemporaryDirectory() as tempdir:\n        yield tempdir\n\n\n@pytest.fixture(name=\"distributed_env\")\ndef _setup_env(monkeypatch):\n    monkeypatch.setenv(\"LANGFLOW_CACHE_TYPE\", \"redis\")\n    monkeypatch.setenv(\"LANGFLOW_REDIS_HOST\", \"result_backend\")\n    monkeypatch.setenv(\"LANGFLOW_REDIS_PORT\", \"6379\")\n    monkeypatch.setenv(\"LANGFLOW_REDIS_DB\", \"0\")\n    monkeypatch.setenv(\"LANGFLOW_REDIS_EXPIRE\", \"3600\")\n    monkeypatch.setenv(\"LANGFLOW_REDIS_PASSWORD\", \"\")\n    monkeypatch.setenv(\"FLOWER_UNAUTHENTICATED_API\", \"True\")\n    monkeypatch.setenv(\"BROKER_URL\", \"redis://result_backend:6379/0\")\n    monkeypatch.setenv(\"RESULT_BACKEND\", \"redis://result_backend:6379/0\")\n    monkeypatch.setenv(\"C_FORCE_ROOT\", \"true\")\n\n\n@pytest.fixture(name=\"distributed_client\")\ndef distributed_client_fixture(\n    session: Session,  # noqa: ARG001\n    monkeypatch,\n    distributed_env,  # noqa: ARG001\n):\n    # Here we load the .env from ../deploy/.env\n    from langflow.core import celery_app\n\n    db_dir = tempfile.mkdtemp()\n    try:\n        db_path = Path(db_dir) / \"test.db\"\n        monkeypatch.setenv(\"LANGFLOW_DATABASE_URL\", f\"sqlite:///{db_path}\")\n        monkeypatch.setenv(\"LANGFLOW_AUTO_LOGIN\", \"false\")\n        # monkeypatch langflow.services.task.manager.USE_CELERY to True\n        # monkeypatch.setattr(manager, \"USE_CELERY\", True)\n        monkeypatch.setattr(celery_app, \"celery_app\", celery_app.make_celery(\"langflow\", Config))\n\n        # def get_session_override():\n        #     return session\n\n        app = create_app()\n\n        # app.dependency_overrides[get_session] = get_session_override\n        with TestClient(app) as client:\n            yield client\n    finally:\n        shutil.rmtree(db_dir)  # Clean up the temporary directory\n    app.dependency_overrides.clear()\n    monkeypatch.undo()\n\n\ndef get_graph(type_=\"basic\"):\n    \"\"\"Get a graph from a json file.\"\"\"\n    if type_ == \"basic\":\n        path = pytest.BASIC_EXAMPLE_PATH\n    elif type_ == \"complex\":\n        path = pytest.COMPLEX_EXAMPLE_PATH\n    elif type_ == \"openapi\":\n        path = pytest.OPENAPI_EXAMPLE_PATH\n\n    with path.open(encoding=\"utf-8\") as f:\n        flow_graph = json.load(f)\n    data_graph = flow_graph[\"data\"]\n    nodes = data_graph[\"nodes\"]\n    edges = data_graph[\"edges\"]\n    graph = Graph()\n    graph.add_nodes_and_edges(nodes, edges)\n    return graph\n\n\n@pytest.fixture\ndef basic_graph_data():\n    with pytest.BASIC_EXAMPLE_PATH.open(encoding=\"utf-8\") as f:\n        return json.load(f)\n\n\n@pytest.fixture\ndef basic_graph():\n    return get_graph()\n\n\n@pytest.fixture\ndef complex_graph():\n    return get_graph(\"complex\")\n\n\n@pytest.fixture\ndef openapi_graph():\n    return get_graph(\"openapi\")\n\n\n@pytest.fixture\ndef json_flow():\n    return pytest.BASIC_EXAMPLE_PATH.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef grouped_chat_json_flow():\n    return pytest.GROUPED_CHAT_EXAMPLE_PATH.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef one_grouped_chat_json_flow():\n    return pytest.ONE_GROUPED_CHAT_EXAMPLE_PATH.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef vector_store_grouped_json_flow():\n    return pytest.VECTOR_STORE_GROUPED_EXAMPLE_PATH.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_flow_with_prompt_and_history():\n    return pytest.BASIC_CHAT_WITH_PROMPT_AND_HISTORY.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_simple_api_test():\n    return pytest.SIMPLE_API_TEST.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_vector_store():\n    return pytest.VECTOR_STORE_PATH.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_webhook_test():\n    return pytest.WEBHOOK_TEST.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_memory_chatbot_no_llm():\n    return pytest.MEMORY_CHATBOT_NO_LLM.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_loop_test():\n    return pytest.LOOP_TEST.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture(autouse=True)\ndef deactivate_tracing(monkeypatch):\n    monkeypatch.setenv(\"LANGFLOW_DEACTIVATE_TRACING\", \"true\")\n    yield\n    monkeypatch.undo()\n\n\n@pytest.fixture(name=\"client\")\nasync def client_fixture(\n    session: Session,  # noqa: ARG001\n    monkeypatch,\n    request,\n    load_flows_dir,\n):\n    # Set the database url to a test database\n    if \"noclient\" in request.keywords:\n        yield\n    else:\n\n        def init_app():\n            db_dir = tempfile.mkdtemp()\n            db_path = Path(db_dir) / \"test.db\"\n            monkeypatch.setenv(\"LANGFLOW_DATABASE_URL\", f\"sqlite:///{db_path}\")\n            monkeypatch.setenv(\"LANGFLOW_AUTO_LOGIN\", \"false\")\n            if \"load_flows\" in request.keywords:\n                shutil.copyfile(\n                    pytest.BASIC_EXAMPLE_PATH, Path(load_flows_dir) / \"c54f9130-f2fa-4a3e-b22a-3856d946351b.json\"\n                )\n                monkeypatch.setenv(\"LANGFLOW_LOAD_FLOWS_PATH\", load_flows_dir)\n                monkeypatch.setenv(\"LANGFLOW_AUTO_LOGIN\", \"true\")\n            # Clear the services cache\n            from langflow.services.manager import service_manager\n\n            service_manager.factories.clear()\n            service_manager.services.clear()  # Clear the services cache\n            app = create_app()\n            db_service = get_db_service()\n            db_service.database_url = f\"sqlite:///{db_path}\"\n            db_service.reload_engine()\n            return app, db_path\n\n        app, db_path = await asyncio.to_thread(init_app)\n        # app.dependency_overrides[get_session] = get_session_override\n        async with (\n            LifespanManager(app, startup_timeout=None, shutdown_timeout=None) as manager,\n            AsyncClient(transport=ASGITransport(app=manager.app), base_url=\"http://testserver/\", http2=True) as client,\n        ):\n            yield client\n        # app.dependency_overrides.clear()\n        monkeypatch.undo()\n        # clear the temp db\n        with suppress(FileNotFoundError):\n            await anyio.Path(db_path).unlink()\n\n\n@pytest.fixture\ndef runner(tmp_path):\n    env = {\"LANGFLOW_DATABASE_URL\": f\"sqlite:///{tmp_path}/test.db\"}\n    return CliRunner(env=env)\n\n\n@pytest.fixture\nasync def test_user(client):\n    user_data = UserCreate(\n        username=\"testuser\",\n        password=\"testpassword\",  # noqa: S106\n    )\n    response = await client.post(\"api/v1/users/\", json=user_data.model_dump())\n    assert response.status_code == 201\n    user = response.json()\n    yield user\n    # Clean up\n    await client.delete(f\"/api/v1/users/{user['id']}\")\n\n\n@pytest.fixture\nasync def active_user(client):  # noqa: ARG001\n    db_manager = get_db_service()\n    async with db_manager.with_session() as session:\n        user = User(\n            username=\"activeuser\",\n            password=get_password_hash(\"testpassword\"),\n            is_active=True,\n            is_superuser=False,\n        )\n        stmt = select(User).where(User.username == user.username)\n        if active_user := (await session.exec(stmt)).first():\n            user = active_user\n        else:\n            session.add(user)\n            await session.commit()\n            await session.refresh(user)\n        user = UserRead.model_validate(user, from_attributes=True)\n    yield user\n    # Clean up\n    # Now cleanup transactions, vertex_build\n    try:\n        async with db_manager.with_session() as session:\n            user = await session.get(User, user.id, options=[selectinload(User.flows)])\n            await _delete_transactions_and_vertex_builds(session, user.flows)\n            await session.commit()\n    except Exception as e:  # noqa: BLE001\n        logger.exception(f\"Error deleting transactions and vertex builds for user: {e}\")\n\n    try:\n        async with db_manager.with_session() as session:\n            user = await session.get(User, user.id)\n            await session.delete(user)\n            await session.commit()\n    except Exception as e:  # noqa: BLE001\n        logger.exception(f\"Error deleting user: {e}\")\n\n\n@pytest.fixture\nasync def logged_in_headers(client, active_user):\n    login_data = {\"username\": active_user.username, \"password\": \"testpassword\"}\n    response = await client.post(\"api/v1/login\", data=login_data)\n    assert response.status_code == 200\n    tokens = response.json()\n    a_token = tokens[\"access_token\"]\n    return {\"Authorization\": f\"Bearer {a_token}\"}\n\n\n@pytest.fixture\nasync def active_super_user(client):  # noqa: ARG001\n    db_manager = get_db_service()\n    async with db_manager.with_session() as session:\n        user = User(\n            username=\"activeuser\",\n            password=get_password_hash(\"testpassword\"),\n            is_active=True,\n            is_superuser=True,\n        )\n        stmt = select(User).where(User.username == user.username)\n        if active_user := (await session.exec(stmt)).first():\n            user = active_user\n        else:\n            session.add(user)\n            await session.commit()\n            await session.refresh(user)\n        user = UserRead.model_validate(user, from_attributes=True)\n    yield user\n    # Clean up\n    # Now cleanup transactions, vertex_build\n    async with db_manager.with_session() as session:\n        user = await session.get(User, user.id, options=[selectinload(User.flows)])\n        await _delete_transactions_and_vertex_builds(session, user.flows)\n        await session.delete(user)\n\n        await session.commit()\n\n\n@pytest.fixture\nasync def logged_in_headers_super_user(client, active_super_user):\n    login_data = {\"username\": active_super_user.username, \"password\": \"testpassword\"}\n    response = await client.post(\"api/v1/login\", data=login_data)\n    assert response.status_code == 200\n    tokens = response.json()\n    a_token = tokens[\"access_token\"]\n    return {\"Authorization\": f\"Bearer {a_token}\"}\n\n\n@pytest.fixture\nasync def flow(\n    client,  # noqa: ARG001\n    json_flow: str,\n    active_user,\n):\n    loaded_json = json.loads(json_flow)\n    flow_data = FlowCreate(name=\"test_flow\", data=loaded_json.get(\"data\"), user_id=active_user.id)\n\n    flow = Flow.model_validate(flow_data)\n    async with session_getter(get_db_service()) as session:\n        session.add(flow)\n        await session.commit()\n        await session.refresh(flow)\n        yield flow\n        # Clean up\n        await session.delete(flow)\n        await session.commit()\n\n\n@pytest.fixture\ndef json_chat_input():\n    return pytest.CHAT_INPUT.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\ndef json_two_outputs():\n    return pytest.TWO_OUTPUTS.read_text(encoding=\"utf-8\")\n\n\n@pytest.fixture\nasync def added_flow_webhook_test(client, json_webhook_test, logged_in_headers):\n    flow = orjson.loads(json_webhook_test)\n    data = flow[\"data\"]\n    flow = FlowCreate(name=\"Basic Chat\", description=\"description\", data=data)\n    response = await client.post(\"api/v1/flows/\", json=flow.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    assert response.json()[\"name\"] == flow.name\n    assert response.json()[\"data\"] == flow.data\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture\nasync def added_flow_chat_input(client, json_chat_input, logged_in_headers):\n    flow = orjson.loads(json_chat_input)\n    data = flow[\"data\"]\n    flow = FlowCreate(name=\"Chat Input\", description=\"description\", data=data)\n    response = await client.post(\"api/v1/flows/\", json=flow.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    assert response.json()[\"name\"] == flow.name\n    assert response.json()[\"data\"] == flow.data\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture\nasync def added_flow_two_outputs(client, json_two_outputs, logged_in_headers):\n    flow = orjson.loads(json_two_outputs)\n    data = flow[\"data\"]\n    flow = FlowCreate(name=\"Two Outputs\", description=\"description\", data=data)\n    response = await client.post(\"api/v1/flows/\", json=flow.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    assert response.json()[\"name\"] == flow.name\n    assert response.json()[\"data\"] == flow.data\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture\nasync def added_vector_store(client, json_vector_store, logged_in_headers):\n    vector_store = orjson.loads(json_vector_store)\n    data = vector_store[\"data\"]\n    vector_store = FlowCreate(name=\"Vector Store\", description=\"description\", data=data)\n    response = await client.post(\"api/v1/flows/\", json=vector_store.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    assert response.json()[\"name\"] == vector_store.name\n    assert response.json()[\"data\"] == vector_store.data\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture\nasync def added_webhook_test(client, json_webhook_test, logged_in_headers):\n    webhook_test = orjson.loads(json_webhook_test)\n    data = webhook_test[\"data\"]\n    webhook_test = FlowCreate(\n        name=\"Webhook Test\", description=\"description\", data=data, endpoint_name=webhook_test[\"endpoint_name\"]\n    )\n    response = await client.post(\"api/v1/flows/\", json=webhook_test.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    assert response.json()[\"name\"] == webhook_test.name\n    assert response.json()[\"data\"] == webhook_test.data\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture\nasync def flow_component(client: AsyncClient, logged_in_headers):\n    chat_input = ChatInput()\n    graph = Graph(start=chat_input, end=chat_input)\n    graph_dict = graph.dump(name=\"Chat Input Component\")\n    flow = FlowCreate(**graph_dict)\n    response = await client.post(\"api/v1/flows/\", json=flow.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture\nasync def created_api_key(active_user):\n    hashed = get_password_hash(\"random_key\")\n    api_key = ApiKey(\n        name=\"test_api_key\",\n        user_id=active_user.id,\n        api_key=\"random_key\",\n        hashed_api_key=hashed,\n    )\n    db_manager = get_db_service()\n    async with session_getter(db_manager) as session:\n        stmt = select(ApiKey).where(ApiKey.api_key == api_key.api_key)\n        if existing_api_key := (await session.exec(stmt)).first():\n            yield existing_api_key\n            return\n        session.add(api_key)\n        await session.commit()\n        await session.refresh(api_key)\n        yield api_key\n        # Clean up\n        await session.delete(api_key)\n        await session.commit()\n\n\n@pytest.fixture(name=\"simple_api_test\")\nasync def get_simple_api_test(client, logged_in_headers, json_simple_api_test):\n    # Once the client is created, we can get the starter project\n    # Just create a new flow with the simple api test\n    flow = orjson.loads(json_simple_api_test)\n    data = flow[\"data\"]\n    flow = FlowCreate(name=\"Simple API Test\", data=data, description=\"Simple API Test\")\n    response = await client.post(\"api/v1/flows/\", json=flow.model_dump(), headers=logged_in_headers)\n    assert response.status_code == 201\n    yield response.json()\n    await client.delete(f\"api/v1/flows/{response.json()['id']}\", headers=logged_in_headers)\n\n\n@pytest.fixture(name=\"starter_project\")\nasync def get_starter_project(active_user):\n    # once the client is created, we can get the starter project\n    async with session_getter(get_db_service()) as session:\n        stmt = (\n            select(Flow)\n            .where(Flow.folder.has(Folder.name == STARTER_FOLDER_NAME))\n            .where(Flow.name == \"Basic Prompting (Hello, World)\")\n        )\n        flow = (await session.exec(stmt)).first()\n        if not flow:\n            msg = \"No starter project found\"\n            raise ValueError(msg)\n\n        # ensure openai api key is set\n        get_openai_api_key()\n        new_flow_create = FlowCreate(\n            name=flow.name,\n            description=flow.description,\n            data=flow.data,\n            user_id=active_user.id,\n        )\n        new_flow = Flow.model_validate(new_flow_create, from_attributes=True)\n        session.add(new_flow)\n        await session.commit()\n        await session.refresh(new_flow)\n        new_flow_dict = new_flow.model_dump()\n        yield new_flow_dict\n        # Clean up\n        await session.delete(new_flow)\n        await session.commit()\n",
    "src/backend/tests/constants.py": "SUPPORTED_VERSIONS = [\"1.0.19\", \"1.1.0\", \"1.1.1\"]\n",
    "src/backend/tests/data/component.py": "import random\n\nfrom langflow.custom import CustomComponent\n\n\nclass TestComponent(CustomComponent):\n    def refresh_values(self):\n        # This is a function that will be called every time the component is updated\n        # and should return a list of random strings\n        return [f\"Random {random.randint(1, 100)}\" for _ in range(5)]  # noqa: S311\n\n    def build_config(self):\n        return {\"param\": {\"display_name\": \"Param\", \"options\": self.refresh_values}}\n\n    def build(self, param: int):\n        return param\n",
    "src/backend/tests/data/component_multiple_outputs.py": "from langflow.custom import Component\nfrom langflow.inputs.inputs import IntInput, MessageTextInput\nfrom langflow.template.field.base import Output\n\n\nclass MultipleOutputsComponent(Component):\n    inputs = [\n        MessageTextInput(display_name=\"Input\", name=\"input\"),\n        IntInput(display_name=\"Number\", name=\"number\"),\n    ]\n    outputs = [\n        Output(display_name=\"Certain Output\", name=\"certain_output\", method=\"certain_output\"),\n        Output(display_name=\"Other Output\", name=\"other_output\", method=\"other_output\"),\n    ]\n\n    def certain_output(self) -> str:\n        return f\"This is my string input: {self.input}\"\n\n    def other_output(self) -> int:\n        return f\"This is my int input multiplied by 2: {self.number * 2}\"\n",
    "src/backend/tests/data/component_nested_call.py": "from random import randint\n\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import IntInput, MessageTextInput\nfrom langflow.template.field.base import Output\n\n\nclass MultipleOutputsComponent(Component):\n    inputs = [\n        MessageTextInput(display_name=\"Input\", name=\"input\"),\n        IntInput(display_name=\"Number\", name=\"number\"),\n    ]\n    outputs = [\n        Output(display_name=\"Certain Output\", name=\"certain_output\", method=\"certain_output\"),\n        Output(display_name=\"Other Output\", name=\"other_output\", method=\"other_output\"),\n    ]\n\n    def certain_output(self) -> int:\n        return randint(0, self.number)  # noqa: S311\n\n    def other_output(self) -> int:\n        return self.certain_output()\n",
    "src/backend/tests/data/component_with_templatefield.py": "import random\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Input\n\n\nclass TestComponent(CustomComponent):\n    def refresh_values(self):\n        # This is a function that will be called every time the component is updated\n        # and should return a list of random strings\n        return [f\"Random {random.randint(1, 100)}\" for _ in range(5)]  # noqa: S311\n\n    def build_config(self):\n        return {\"param\": Input(display_name=\"Param\", options=self.refresh_values)}\n\n    def build(self, param: int):\n        return param\n"
  },
  "requirements": null
}