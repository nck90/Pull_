{
  "repo_name": "openai/whisper",
  "repo_url": "https://github.com/openai/whisper",
  "description": "Robust Speech Recognition via Large-Scale Weak Supervision",
  "stars": 78370,
  "language": "Python",
  "created_at": "2022-09-16T20:02:54Z",
  "updated_at": "2025-03-19T06:54:36Z",
  "files": {
    "tests/conftest.py": "import random as rand\n\nimport numpy\nimport pytest\n\n\ndef pytest_configure(config):\n    config.addinivalue_line(\"markers\", \"requires_cuda\")\n\n\n@pytest.fixture\ndef random():\n    rand.seed(42)\n    numpy.random.seed(42)\n",
    "tests/test_audio.py": "import os.path\n\nimport numpy as np\n\nfrom whisper.audio import SAMPLE_RATE, load_audio, log_mel_spectrogram\n\n\ndef test_audio():\n    audio_path = os.path.join(os.path.dirname(__file__), \"jfk.flac\")\n    audio = load_audio(audio_path)\n    assert audio.ndim == 1\n    assert SAMPLE_RATE * 10 < audio.shape[0] < SAMPLE_RATE * 12\n    assert 0 < audio.std() < 1\n\n    mel_from_audio = log_mel_spectrogram(audio)\n    mel_from_file = log_mel_spectrogram(audio_path)\n\n    assert np.allclose(mel_from_audio, mel_from_file)\n    assert mel_from_audio.max() - mel_from_audio.min() <= 2.0\n",
    "tests/test_normalizer.py": "import pytest\n\nfrom whisper.normalizers import EnglishTextNormalizer\nfrom whisper.normalizers.english import (\n    EnglishNumberNormalizer,\n    EnglishSpellingNormalizer,\n)\n\n\n@pytest.mark.parametrize(\"std\", [EnglishNumberNormalizer(), EnglishTextNormalizer()])\ndef test_number_normalizer(std):\n    assert std(\"two\") == \"2\"\n    assert std(\"thirty one\") == \"31\"\n    assert std(\"five twenty four\") == \"524\"\n    assert std(\"nineteen ninety nine\") == \"1999\"\n    assert std(\"twenty nineteen\") == \"2019\"\n\n    assert std(\"two point five million\") == \"2500000\"\n    assert std(\"four point two billions\") == \"4200000000s\"\n    assert std(\"200 thousand\") == \"200000\"\n    assert std(\"200 thousand dollars\") == \"$200000\"\n    assert std(\"$20 million\") == \"$20000000\"\n    assert std(\"€52.4 million\") == \"€52400000\"\n    assert std(\"£77 thousands\") == \"£77000s\"\n\n    assert std(\"two double o eight\") == \"2008\"\n\n    assert std(\"three thousand twenty nine\") == \"3029\"\n    assert std(\"forty three thousand two hundred sixty\") == \"43260\"\n    assert std(\"forty three thousand two hundred and sixty\") == \"43260\"\n\n    assert std(\"nineteen fifties\") == \"1950s\"\n    assert std(\"thirty first\") == \"31st\"\n    assert std(\"thirty three thousand and three hundred and thirty third\") == \"33333rd\"\n\n    assert std(\"three billion\") == \"3000000000\"\n    assert std(\"millions\") == \"1000000s\"\n\n    assert std(\"july third twenty twenty\") == \"july 3rd 2020\"\n    assert std(\"august twenty sixth twenty twenty one\") == \"august 26th 2021\"\n    assert std(\"3 14\") == \"3 14\"\n    assert std(\"3.14\") == \"3.14\"\n    assert std(\"3 point 2\") == \"3.2\"\n    assert std(\"3 point 14\") == \"3.14\"\n    assert std(\"fourteen point 4\") == \"14.4\"\n    assert std(\"two point two five dollars\") == \"$2.25\"\n    assert std(\"two hundred million dollars\") == \"$200000000\"\n    assert std(\"$20.1 million\") == \"$20100000\"\n\n    assert std(\"ninety percent\") == \"90%\"\n    assert std(\"seventy six per cent\") == \"76%\"\n\n    assert std(\"double oh seven\") == \"007\"\n    assert std(\"double zero seven\") == \"007\"\n    assert std(\"nine one one\") == \"911\"\n    assert std(\"nine double one\") == \"911\"\n    assert std(\"one triple oh one\") == \"10001\"\n\n    assert std(\"two thousandth\") == \"2000th\"\n    assert std(\"thirty two thousandth\") == \"32000th\"\n\n    assert std(\"minus 500\") == \"-500\"\n    assert std(\"positive twenty thousand\") == \"+20000\"\n\n    assert std(\"two dollars and seventy cents\") == \"$2.70\"\n    assert std(\"3 cents\") == \"¢3\"\n    assert std(\"$0.36\") == \"¢36\"\n    assert std(\"three euros and sixty five cents\") == \"€3.65\"\n\n    assert std(\"three and a half million\") == \"3500000\"\n    assert std(\"forty eight and a half dollars\") == \"$48.5\"\n    assert std(\"b747\") == \"b 747\"\n    assert std(\"10 th\") == \"10th\"\n    assert std(\"10th\") == \"10th\"\n\n\ndef test_spelling_normalizer():\n    std = EnglishSpellingNormalizer()\n\n    assert std(\"mobilisation\") == \"mobilization\"\n    assert std(\"cancelation\") == \"cancellation\"\n\n\ndef test_text_normalizer():\n    std = EnglishTextNormalizer()\n    assert std(\"Let's\") == \"let us\"\n    assert std(\"he's like\") == \"he is like\"\n    assert std(\"she's been like\") == \"she has been like\"\n    assert std(\"10km\") == \"10 km\"\n    assert std(\"10mm\") == \"10 mm\"\n    assert std(\"RC232\") == \"rc 232\"\n\n    assert (\n        std(\"Mr. Park visited Assoc. Prof. Kim Jr.\")\n        == \"mister park visited associate professor kim junior\"\n    )\n",
    "tests/test_timing.py": "import numpy as np\nimport pytest\nimport scipy.ndimage\nimport torch\n\nfrom whisper.timing import dtw_cpu, dtw_cuda, median_filter\n\nsizes = [\n    (10, 20),\n    (32, 16),\n    (123, 1500),\n    (234, 189),\n]\nshapes = [\n    (10,),\n    (1, 15),\n    (4, 5, 345),\n    (6, 12, 240, 512),\n]\n\n\n@pytest.mark.parametrize(\"N, M\", sizes)\ndef test_dtw(N: int, M: int):\n    steps = np.concatenate([np.zeros(N - 1), np.ones(M - 1)])\n    np.random.shuffle(steps)\n    x = np.random.random((N, M)).astype(np.float32)\n\n    i, j, k = 0, 0, 0\n    trace = []\n    while True:\n        x[i, j] -= 1\n        trace.append((i, j))\n\n        if k == len(steps):\n            break\n\n        if k + 1 < len(steps) and steps[k] != steps[k + 1]:\n            i += 1\n            j += 1\n            k += 2\n            continue\n\n        if steps[k] == 0:\n            i += 1\n        if steps[k] == 1:\n            j += 1\n        k += 1\n\n    trace = np.array(trace).T\n    dtw_trace = dtw_cpu(x)\n\n    assert np.allclose(trace, dtw_trace)\n\n\n@pytest.mark.requires_cuda\n@pytest.mark.parametrize(\"N, M\", sizes)\ndef test_dtw_cuda_equivalence(N: int, M: int):\n    x_numpy = np.random.randn(N, M).astype(np.float32)\n    x_cuda = torch.from_numpy(x_numpy).cuda()\n\n    trace_cpu = dtw_cpu(x_numpy)\n    trace_cuda = dtw_cuda(x_cuda)\n\n    assert np.allclose(trace_cpu, trace_cuda)\n\n\n@pytest.mark.parametrize(\"shape\", shapes)\ndef test_median_filter(shape):\n    x = torch.randn(*shape)\n\n    for filter_width in [3, 5, 7, 13]:\n        filtered = median_filter(x, filter_width)\n\n        # using np.pad to reflect-pad, because Scipy's behavior is different near the edges.\n        pad_width = filter_width // 2\n        padded_x = np.pad(\n            x, [(0, 0)] * (x.ndim - 1) + [(pad_width, pad_width)], mode=\"reflect\"\n        )\n        scipy_filtered = scipy.ndimage.median_filter(\n            padded_x, [1] * (x.ndim - 1) + [filter_width]\n        )\n        scipy_filtered = scipy_filtered[..., pad_width:-pad_width]\n\n        assert np.allclose(filtered, scipy_filtered)\n\n\n@pytest.mark.requires_cuda\n@pytest.mark.parametrize(\"shape\", shapes)\ndef test_median_filter_equivalence(shape):\n    x = torch.randn(*shape)\n\n    for filter_width in [3, 5, 7, 13]:\n        filtered_cpu = median_filter(x, filter_width)\n        filtered_gpu = median_filter(x.cuda(), filter_width).cpu()\n\n        assert np.allclose(filtered_cpu, filtered_gpu)\n",
    "tests/test_tokenizer.py": "import pytest\n\nfrom whisper.tokenizer import get_tokenizer\n\n\n@pytest.mark.parametrize(\"multilingual\", [True, False])\ndef test_tokenizer(multilingual):\n    tokenizer = get_tokenizer(multilingual=False)\n    assert tokenizer.sot in tokenizer.sot_sequence\n    assert len(tokenizer.all_language_codes) == len(tokenizer.all_language_tokens)\n    assert all(c < tokenizer.timestamp_begin for c in tokenizer.all_language_tokens)\n\n\ndef test_multilingual_tokenizer():\n    gpt2_tokenizer = get_tokenizer(multilingual=False)\n    multilingual_tokenizer = get_tokenizer(multilingual=True)\n\n    text = \"다람쥐 헌 쳇바퀴에 타고파\"\n    gpt2_tokens = gpt2_tokenizer.encode(text)\n    multilingual_tokens = multilingual_tokenizer.encode(text)\n\n    assert gpt2_tokenizer.decode(gpt2_tokens) == text\n    assert multilingual_tokenizer.decode(multilingual_tokens) == text\n    assert len(gpt2_tokens) > len(multilingual_tokens)\n\n\ndef test_split_on_unicode():\n    multilingual_tokenizer = get_tokenizer(multilingual=True)\n\n    tokens = [8404, 871, 287, 6, 246, 526, 3210, 20378]\n    words, word_tokens = multilingual_tokenizer.split_tokens_on_unicode(tokens)\n\n    assert words == [\" elle\", \" est\", \" l\", \"'\", \"\\ufffd\", \"é\", \"rit\", \"oire\"]\n    assert word_tokens == [[8404], [871], [287], [6], [246], [526], [3210], [20378]]\n",
    "tests/test_transcribe.py": "import os\n\nimport pytest\nimport torch\n\nimport whisper\nfrom whisper.tokenizer import get_tokenizer\n\n\n@pytest.mark.parametrize(\"model_name\", whisper.available_models())\ndef test_transcribe(model_name: str):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    model = whisper.load_model(model_name).to(device)\n    audio_path = os.path.join(os.path.dirname(__file__), \"jfk.flac\")\n\n    language = \"en\" if model_name.endswith(\".en\") else None\n    result = model.transcribe(\n        audio_path, language=language, temperature=0.0, word_timestamps=True\n    )\n    assert result[\"language\"] == \"en\"\n    assert result[\"text\"] == \"\".join([s[\"text\"] for s in result[\"segments\"]])\n\n    transcription = result[\"text\"].lower()\n    assert \"my fellow americans\" in transcription\n    assert \"your country\" in transcription\n    assert \"do for you\" in transcription\n\n    tokenizer = get_tokenizer(model.is_multilingual, num_languages=model.num_languages)\n    all_tokens = [t for s in result[\"segments\"] for t in s[\"tokens\"]]\n    assert tokenizer.decode(all_tokens) == result[\"text\"]\n    assert tokenizer.decode_with_timestamps(all_tokens).startswith(\"<|0.00|>\")\n\n    timing_checked = False\n    for segment in result[\"segments\"]:\n        for timing in segment[\"words\"]:\n            assert timing[\"start\"] < timing[\"end\"]\n            if timing[\"word\"].strip(\" ,\") == \"Americans\":\n                assert timing[\"start\"] <= 1.8\n                assert timing[\"end\"] >= 1.8\n                timing_checked = True\n\n    assert timing_checked\n"
  },
  "requirements": "numba\nnumpy\ntorch\ntqdm\nmore-itertools\ntiktoken\ntriton>=2.0.0;platform_machine==\"x86_64\" and sys_platform==\"linux\" or sys_platform==\"linux2\"\n"
}