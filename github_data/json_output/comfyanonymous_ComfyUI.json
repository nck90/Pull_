{
  "repo_name": "comfyanonymous/ComfyUI",
  "repo_url": "https://github.com/comfyanonymous/ComfyUI",
  "description": "The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.",
  "stars": 71509,
  "language": "Python",
  "created_at": "2023-01-17T03:15:56Z",
  "updated_at": "2025-03-19T06:30:02Z",
  "files": {
    "tests-unit/app_test/custom_node_manager_test.py": "import pytest\nfrom aiohttp import web\nfrom unittest.mock import patch\nfrom app.custom_node_manager import CustomNodeManager\nimport json\n\npytestmark = (\n    pytest.mark.asyncio\n)  # This applies the asyncio mark to all test functions in the module\n\n\n@pytest.fixture\ndef custom_node_manager():\n    return CustomNodeManager()\n\n\n@pytest.fixture\ndef app(custom_node_manager):\n    app = web.Application()\n    routes = web.RouteTableDef()\n    custom_node_manager.add_routes(\n        routes, app, [(\"ComfyUI-TestExtension1\", \"ComfyUI-TestExtension1\")]\n    )\n    app.add_routes(routes)\n    return app\n\n\nasync def test_get_workflow_templates(aiohttp_client, app, tmp_path):\n    client = await aiohttp_client(app)\n    # Setup temporary custom nodes file structure with 1 workflow file\n    custom_nodes_dir = tmp_path / \"custom_nodes\"\n    example_workflows_dir = (\n        custom_nodes_dir / \"ComfyUI-TestExtension1\" / \"example_workflows\"\n    )\n    example_workflows_dir.mkdir(parents=True)\n    template_file = example_workflows_dir / \"workflow1.json\"\n    template_file.write_text(\"\")\n\n    with patch(\n        \"folder_paths.folder_names_and_paths\",\n        {\"custom_nodes\": ([str(custom_nodes_dir)], None)},\n    ):\n        response = await client.get(\"/workflow_templates\")\n        assert response.status == 200\n        workflows_dict = await response.json()\n        assert isinstance(workflows_dict, dict)\n        assert \"ComfyUI-TestExtension1\" in workflows_dict\n        assert isinstance(workflows_dict[\"ComfyUI-TestExtension1\"], list)\n        assert workflows_dict[\"ComfyUI-TestExtension1\"][0] == \"workflow1\"\n\n\nasync def test_build_translations_empty_when_no_locales(custom_node_manager, tmp_path):\n    custom_nodes_dir = tmp_path / \"custom_nodes\"\n    custom_nodes_dir.mkdir(parents=True)\n\n    with patch(\"folder_paths.get_folder_paths\", return_value=[str(custom_nodes_dir)]):\n        translations = custom_node_manager.build_translations()\n        assert translations == {}\n\n\nasync def test_build_translations_loads_all_files(custom_node_manager, tmp_path):\n    # Setup test directory structure\n    custom_nodes_dir = tmp_path / \"custom_nodes\" / \"test-extension\"\n    locales_dir = custom_nodes_dir / \"locales\" / \"en\"\n    locales_dir.mkdir(parents=True)\n\n    # Create test translation files\n    main_content = {\"title\": \"Test Extension\"}\n    (locales_dir / \"main.json\").write_text(json.dumps(main_content))\n\n    node_defs = {\"node1\": \"Node 1\"}\n    (locales_dir / \"nodeDefs.json\").write_text(json.dumps(node_defs))\n\n    commands = {\"cmd1\": \"Command 1\"}\n    (locales_dir / \"commands.json\").write_text(json.dumps(commands))\n\n    settings = {\"setting1\": \"Setting 1\"}\n    (locales_dir / \"settings.json\").write_text(json.dumps(settings))\n\n    with patch(\n        \"folder_paths.get_folder_paths\", return_value=[tmp_path / \"custom_nodes\"]\n    ):\n        translations = custom_node_manager.build_translations()\n\n        assert translations == {\n            \"en\": {\n                \"title\": \"Test Extension\",\n                \"nodeDefs\": {\"node1\": \"Node 1\"},\n                \"commands\": {\"cmd1\": \"Command 1\"},\n                \"settings\": {\"setting1\": \"Setting 1\"},\n            }\n        }\n\n\nasync def test_build_translations_handles_invalid_json(custom_node_manager, tmp_path):\n    # Setup test directory structure\n    custom_nodes_dir = tmp_path / \"custom_nodes\" / \"test-extension\"\n    locales_dir = custom_nodes_dir / \"locales\" / \"en\"\n    locales_dir.mkdir(parents=True)\n\n    # Create valid main.json\n    main_content = {\"title\": \"Test Extension\"}\n    (locales_dir / \"main.json\").write_text(json.dumps(main_content))\n\n    # Create invalid JSON file\n    (locales_dir / \"nodeDefs.json\").write_text(\"invalid json{\")\n\n    with patch(\n        \"folder_paths.get_folder_paths\", return_value=[tmp_path / \"custom_nodes\"]\n    ):\n        translations = custom_node_manager.build_translations()\n\n        assert translations == {\n            \"en\": {\n                \"title\": \"Test Extension\",\n            }\n        }\n\n\nasync def test_build_translations_merges_multiple_extensions(\n    custom_node_manager, tmp_path\n):\n    # Setup test directory structure for two extensions\n    custom_nodes_dir = tmp_path / \"custom_nodes\"\n    ext1_dir = custom_nodes_dir / \"extension1\" / \"locales\" / \"en\"\n    ext2_dir = custom_nodes_dir / \"extension2\" / \"locales\" / \"en\"\n    ext1_dir.mkdir(parents=True)\n    ext2_dir.mkdir(parents=True)\n\n    # Create translation files for extension 1\n    ext1_main = {\"title\": \"Extension 1\", \"shared\": \"Original\"}\n    (ext1_dir / \"main.json\").write_text(json.dumps(ext1_main))\n\n    # Create translation files for extension 2\n    ext2_main = {\"description\": \"Extension 2\", \"shared\": \"Override\"}\n    (ext2_dir / \"main.json\").write_text(json.dumps(ext2_main))\n\n    with patch(\"folder_paths.get_folder_paths\", return_value=[str(custom_nodes_dir)]):\n        translations = custom_node_manager.build_translations()\n\n        assert translations == {\n            \"en\": {\n                \"title\": \"Extension 1\",\n                \"description\": \"Extension 2\",\n                \"shared\": \"Override\",  # Second extension should override first\n            }\n        }\n",
    "tests-unit/app_test/frontend_manager_test.py": "import argparse\nimport pytest\nfrom requests.exceptions import HTTPError\nfrom unittest.mock import patch\n\nfrom app.frontend_management import (\n    FrontendManager,\n    FrontEndProvider,\n    Release,\n)\nfrom comfy.cli_args import DEFAULT_VERSION_STRING\n\n\n@pytest.fixture\ndef mock_releases():\n    return [\n        Release(\n            id=1,\n            tag_name=\"1.0.0\",\n            name=\"Release 1.0.0\",\n            prerelease=False,\n            created_at=\"2022-01-01T00:00:00Z\",\n            published_at=\"2022-01-01T00:00:00Z\",\n            body=\"Release notes for 1.0.0\",\n            assets=[{\"name\": \"dist.zip\", \"url\": \"https://example.com/dist.zip\"}],\n        ),\n        Release(\n            id=2,\n            tag_name=\"2.0.0\",\n            name=\"Release 2.0.0\",\n            prerelease=False,\n            created_at=\"2022-02-01T00:00:00Z\",\n            published_at=\"2022-02-01T00:00:00Z\",\n            body=\"Release notes for 2.0.0\",\n            assets=[{\"name\": \"dist.zip\", \"url\": \"https://example.com/dist.zip\"}],\n        ),\n    ]\n\n\n@pytest.fixture\ndef mock_provider(mock_releases):\n    provider = FrontEndProvider(\n        owner=\"test-owner\",\n        repo=\"test-repo\",\n    )\n    provider.all_releases = mock_releases\n    provider.latest_release = mock_releases[1]\n    FrontendManager.PROVIDERS = [provider]\n    return provider\n\n\ndef test_get_release(mock_provider, mock_releases):\n    version = \"1.0.0\"\n    release = mock_provider.get_release(version)\n    assert release == mock_releases[0]\n\n\ndef test_get_release_latest(mock_provider, mock_releases):\n    version = \"latest\"\n    release = mock_provider.get_release(version)\n    assert release == mock_releases[1]\n\n\ndef test_get_release_invalid_version(mock_provider):\n    version = \"invalid\"\n    with pytest.raises(ValueError):\n        mock_provider.get_release(version)\n\n\ndef test_init_frontend_default():\n    version_string = DEFAULT_VERSION_STRING\n    frontend_path = FrontendManager.init_frontend(version_string)\n    assert frontend_path == FrontendManager.default_frontend_path()\n\n\ndef test_init_frontend_invalid_version():\n    version_string = \"test-owner/test-repo@1.100.99\"\n    with pytest.raises(HTTPError):\n        FrontendManager.init_frontend_unsafe(version_string)\n\n\ndef test_init_frontend_invalid_provider():\n    version_string = \"invalid/invalid@latest\"\n    with pytest.raises(HTTPError):\n        FrontendManager.init_frontend_unsafe(version_string)\n\n\n@pytest.fixture\ndef mock_os_functions():\n    with (\n        patch(\"app.frontend_management.os.makedirs\") as mock_makedirs,\n        patch(\"app.frontend_management.os.listdir\") as mock_listdir,\n        patch(\"app.frontend_management.os.rmdir\") as mock_rmdir,\n    ):\n        mock_listdir.return_value = []  # Simulate empty directory\n        yield mock_makedirs, mock_listdir, mock_rmdir\n\n\n@pytest.fixture\ndef mock_download():\n    with patch(\"app.frontend_management.download_release_asset_zip\") as mock:\n        mock.side_effect = Exception(\"Download failed\")  # Simulate download failure\n        yield mock\n\n\ndef test_finally_block(mock_os_functions, mock_download, mock_provider):\n    # Arrange\n    mock_makedirs, mock_listdir, mock_rmdir = mock_os_functions\n    version_string = \"test-owner/test-repo@1.0.0\"\n\n    # Act & Assert\n    with pytest.raises(Exception):\n        FrontendManager.init_frontend_unsafe(version_string, mock_provider)\n\n    # Assert\n    mock_makedirs.assert_called_once()\n    mock_download.assert_called_once()\n    mock_listdir.assert_called_once()\n    mock_rmdir.assert_called_once()\n\n\ndef test_parse_version_string():\n    version_string = \"owner/repo@1.0.0\"\n    repo_owner, repo_name, version = FrontendManager.parse_version_string(\n        version_string\n    )\n    assert repo_owner == \"owner\"\n    assert repo_name == \"repo\"\n    assert version == \"1.0.0\"\n\n\ndef test_parse_version_string_invalid():\n    version_string = \"invalid\"\n    with pytest.raises(argparse.ArgumentTypeError):\n        FrontendManager.parse_version_string(version_string)\n\n\ndef test_init_frontend_default_with_mocks():\n    # Arrange\n    version_string = DEFAULT_VERSION_STRING\n\n    # Act\n    with (\n        patch(\"app.frontend_management.check_frontend_version\") as mock_check,\n        patch.object(\n            FrontendManager, \"default_frontend_path\", return_value=\"/mocked/path\"\n        ),\n    ):\n        frontend_path = FrontendManager.init_frontend(version_string)\n\n    # Assert\n    assert frontend_path == \"/mocked/path\"\n    mock_check.assert_called_once()\n\n\ndef test_init_frontend_fallback_on_error():\n    # Arrange\n    version_string = \"test-owner/test-repo@1.0.0\"\n\n    # Act\n    with (\n        patch.object(\n            FrontendManager, \"init_frontend_unsafe\", side_effect=Exception(\"Test error\")\n        ),\n        patch(\"app.frontend_management.check_frontend_version\") as mock_check,\n        patch.object(\n            FrontendManager, \"default_frontend_path\", return_value=\"/default/path\"\n        ),\n    ):\n        frontend_path = FrontendManager.init_frontend(version_string)\n\n    # Assert\n    assert frontend_path == \"/default/path\"\n    mock_check.assert_called_once()\n",
    "tests-unit/app_test/model_manager_test.py": "import pytest\nimport base64\nimport json\nimport struct\nfrom io import BytesIO\nfrom PIL import Image\nfrom aiohttp import web\nfrom unittest.mock import patch\nfrom app.model_manager import ModelFileManager\n\npytestmark = (\n    pytest.mark.asyncio\n)  # This applies the asyncio mark to all test functions in the module\n\n@pytest.fixture\ndef model_manager():\n    return ModelFileManager()\n\n@pytest.fixture\ndef app(model_manager):\n    app = web.Application()\n    routes = web.RouteTableDef()\n    model_manager.add_routes(routes)\n    app.add_routes(routes)\n    return app\n\nasync def test_get_model_preview_safetensors(aiohttp_client, app, tmp_path):\n    img = Image.new('RGB', (100, 100), 'white')\n    img_byte_arr = BytesIO()\n    img.save(img_byte_arr, format='PNG')\n    img_byte_arr.seek(0)\n    img_b64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n\n    safetensors_file = tmp_path / \"test_model.safetensors\"\n    header_bytes = json.dumps({\n        \"__metadata__\": {\n            \"ssmd_cover_images\": json.dumps([img_b64])\n        }\n    }).encode('utf-8')\n    length_bytes = struct.pack('<Q', len(header_bytes))\n    with open(safetensors_file, 'wb') as f:\n        f.write(length_bytes)\n        f.write(header_bytes)\n\n    with patch('folder_paths.folder_names_and_paths', {\n        'test_folder': ([str(tmp_path)], None)\n    }):\n        client = await aiohttp_client(app)\n        response = await client.get('/experiment/models/preview/test_folder/0/test_model.safetensors')\n\n        # Verify response\n        assert response.status == 200\n        assert response.content_type == 'image/webp'\n\n        # Verify the response contains valid image data\n        img_bytes = BytesIO(await response.read())\n        img = Image.open(img_bytes)\n        assert img.format\n        assert img.format.lower() == 'webp'\n\n        # Clean up\n        img.close()\n",
    "tests-unit/comfy_test/folder_path_test.py": "### 🗻 This file is created through the spirit of Mount Fuji at its peak\n# TODO(yoland): clean up this after I get back down\nimport sys\nimport pytest\nimport os\nimport tempfile\nfrom unittest.mock import patch\nfrom importlib import reload\n\nimport folder_paths\nimport comfy.cli_args\nfrom comfy.options import enable_args_parsing\nenable_args_parsing()\n\n\n@pytest.fixture()\ndef clear_folder_paths():\n    # Reload the module after each test to ensure isolation\n    yield\n    reload(folder_paths)\n\n@pytest.fixture\ndef temp_dir():\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        yield tmpdirname\n\n\n@pytest.fixture\ndef set_base_dir():\n    def _set_base_dir(base_dir):\n        # Mock CLI args\n        with patch.object(sys, 'argv', [\"main.py\", \"--base-directory\", base_dir]):\n            reload(comfy.cli_args)\n            reload(folder_paths)\n    yield _set_base_dir\n    # Reload the modules after each test to ensure isolation\n    with patch.object(sys, 'argv', [\"main.py\"]):\n        reload(comfy.cli_args)\n        reload(folder_paths)\n\n\ndef test_get_directory_by_type(clear_folder_paths):\n    test_dir = \"/test/dir\"\n    folder_paths.set_output_directory(test_dir)\n    assert folder_paths.get_directory_by_type(\"output\") == test_dir\n    assert folder_paths.get_directory_by_type(\"invalid\") is None\n\ndef test_annotated_filepath():\n    assert folder_paths.annotated_filepath(\"test.txt\") == (\"test.txt\", None)\n    assert folder_paths.annotated_filepath(\"test.txt [output]\") == (\"test.txt\", folder_paths.get_output_directory())\n    assert folder_paths.annotated_filepath(\"test.txt [input]\") == (\"test.txt\", folder_paths.get_input_directory())\n    assert folder_paths.annotated_filepath(\"test.txt [temp]\") == (\"test.txt\", folder_paths.get_temp_directory())\n\ndef test_get_annotated_filepath():\n    default_dir = \"/default/dir\"\n    assert folder_paths.get_annotated_filepath(\"test.txt\", default_dir) == os.path.join(default_dir, \"test.txt\")\n    assert folder_paths.get_annotated_filepath(\"test.txt [output]\") == os.path.join(folder_paths.get_output_directory(), \"test.txt\")\n\ndef test_add_model_folder_path_append(clear_folder_paths):\n    folder_paths.add_model_folder_path(\"test_folder\", \"/default/path\", is_default=True)\n    folder_paths.add_model_folder_path(\"test_folder\", \"/test/path\", is_default=False)\n    assert folder_paths.get_folder_paths(\"test_folder\") == [\"/default/path\", \"/test/path\"]\n\n\ndef test_add_model_folder_path_insert(clear_folder_paths):\n    folder_paths.add_model_folder_path(\"test_folder\", \"/test/path\", is_default=False)\n    folder_paths.add_model_folder_path(\"test_folder\", \"/default/path\", is_default=True)\n    assert folder_paths.get_folder_paths(\"test_folder\") == [\"/default/path\", \"/test/path\"]\n\n\ndef test_add_model_folder_path_re_add_existing_default(clear_folder_paths):\n    folder_paths.add_model_folder_path(\"test_folder\", \"/test/path\", is_default=False)\n    folder_paths.add_model_folder_path(\"test_folder\", \"/old_default/path\", is_default=True)\n    assert folder_paths.get_folder_paths(\"test_folder\") == [\"/old_default/path\", \"/test/path\"]\n    folder_paths.add_model_folder_path(\"test_folder\", \"/test/path\", is_default=True)\n    assert folder_paths.get_folder_paths(\"test_folder\") == [\"/test/path\", \"/old_default/path\"]\n\n\ndef test_add_model_folder_path_re_add_existing_non_default(clear_folder_paths):\n    folder_paths.add_model_folder_path(\"test_folder\", \"/test/path\", is_default=False)\n    folder_paths.add_model_folder_path(\"test_folder\", \"/default/path\", is_default=True)\n    assert folder_paths.get_folder_paths(\"test_folder\") == [\"/default/path\", \"/test/path\"]\n    folder_paths.add_model_folder_path(\"test_folder\", \"/test/path\", is_default=False)\n    assert folder_paths.get_folder_paths(\"test_folder\") == [\"/default/path\", \"/test/path\"]\n\n\ndef test_recursive_search(temp_dir):\n    os.makedirs(os.path.join(temp_dir, \"subdir\"))\n    open(os.path.join(temp_dir, \"file1.txt\"), \"w\").close()\n    open(os.path.join(temp_dir, \"subdir\", \"file2.txt\"), \"w\").close()\n\n    files, dirs = folder_paths.recursive_search(temp_dir)\n    assert set(files) == {\"file1.txt\", os.path.join(\"subdir\", \"file2.txt\")}\n    assert len(dirs) == 2  # temp_dir and subdir\n\ndef test_filter_files_extensions():\n    files = [\"file1.txt\", \"file2.jpg\", \"file3.png\", \"file4.txt\"]\n    assert folder_paths.filter_files_extensions(files, [\".txt\"]) == [\"file1.txt\", \"file4.txt\"]\n    assert folder_paths.filter_files_extensions(files, [\".jpg\", \".png\"]) == [\"file2.jpg\", \"file3.png\"]\n    assert folder_paths.filter_files_extensions(files, []) == files\n\n@patch(\"folder_paths.recursive_search\")\n@patch(\"folder_paths.folder_names_and_paths\")\ndef test_get_filename_list(mock_folder_names_and_paths, mock_recursive_search):\n    mock_folder_names_and_paths.__getitem__.return_value = ([\"/test/path\"], {\".txt\"})\n    mock_recursive_search.return_value = ([\"file1.txt\", \"file2.jpg\"], {})\n    assert folder_paths.get_filename_list(\"test_folder\") == [\"file1.txt\"]\n\ndef test_get_save_image_path(temp_dir):\n    with patch(\"folder_paths.output_directory\", temp_dir):\n        full_output_folder, filename, counter, subfolder, filename_prefix = folder_paths.get_save_image_path(\"test\", temp_dir, 100, 100)\n        assert os.path.samefile(full_output_folder, temp_dir)\n        assert filename == \"test\"\n        assert counter == 1\n        assert subfolder == \"\"\n        assert filename_prefix == \"test\"\n\n\ndef test_base_path_changes(set_base_dir):\n    test_dir = os.path.abspath(\"/test/dir\")\n    set_base_dir(test_dir)\n\n    assert folder_paths.base_path == test_dir\n    assert folder_paths.models_dir == os.path.join(test_dir, \"models\")\n    assert folder_paths.input_directory == os.path.join(test_dir, \"input\")\n    assert folder_paths.output_directory == os.path.join(test_dir, \"output\")\n    assert folder_paths.temp_directory == os.path.join(test_dir, \"temp\")\n    assert folder_paths.user_directory == os.path.join(test_dir, \"user\")\n\n    assert os.path.join(test_dir, \"custom_nodes\") in folder_paths.get_folder_paths(\"custom_nodes\")\n\n    for name in [\"checkpoints\", \"loras\", \"vae\", \"configs\", \"embeddings\", \"controlnet\", \"classifiers\"]:\n        assert folder_paths.get_folder_paths(name)[0] == os.path.join(test_dir, \"models\", name)\n\n\ndef test_base_path_change_clears_old(set_base_dir):\n    test_dir = os.path.abspath(\"/test/dir\")\n    set_base_dir(test_dir)\n\n    assert len(folder_paths.get_folder_paths(\"custom_nodes\")) == 1\n\n    single_model_paths = [\n        \"checkpoints\",\n        \"loras\",\n        \"vae\",\n        \"configs\",\n        \"clip_vision\",\n        \"style_models\",\n        \"diffusers\",\n        \"vae_approx\",\n        \"gligen\",\n        \"upscale_models\",\n        \"embeddings\",\n        \"hypernetworks\",\n        \"photomaker\",\n        \"classifiers\",\n    ]\n    for name in single_model_paths:\n        assert len(folder_paths.get_folder_paths(name)) == 1\n\n    for name in [\"controlnet\", \"diffusion_models\", \"text_encoders\"]:\n        assert len(folder_paths.get_folder_paths(name)) == 2\n",
    "tests-unit/execution_test/validate_node_input_test.py": "import pytest\nfrom comfy_execution.validation import validate_node_input\n\n\ndef test_exact_match():\n    \"\"\"Test cases where types match exactly\"\"\"\n    assert validate_node_input(\"STRING\", \"STRING\")\n    assert validate_node_input(\"STRING,INT\", \"STRING,INT\")\n    assert validate_node_input(\"INT,STRING\", \"STRING,INT\")  # Order shouldn't matter\n\n\ndef test_strict_mode():\n    \"\"\"Test strict mode validation\"\"\"\n    # Should pass - received type is subset of input type\n    assert validate_node_input(\"STRING\", \"STRING,INT\", strict=True)\n    assert validate_node_input(\"INT\", \"STRING,INT\", strict=True)\n    assert validate_node_input(\"STRING,INT\", \"STRING,INT,BOOLEAN\", strict=True)\n\n    # Should fail - received type is not subset of input type\n    assert not validate_node_input(\"STRING,INT\", \"STRING\", strict=True)\n    assert not validate_node_input(\"STRING,BOOLEAN\", \"STRING\", strict=True)\n    assert not validate_node_input(\"INT,BOOLEAN\", \"STRING,INT\", strict=True)\n\n\ndef test_non_strict_mode():\n    \"\"\"Test non-strict mode validation (default behavior)\"\"\"\n    # Should pass - types have overlap\n    assert validate_node_input(\"STRING,BOOLEAN\", \"STRING,INT\")\n    assert validate_node_input(\"STRING,INT\", \"INT,BOOLEAN\")\n    assert validate_node_input(\"STRING\", \"STRING,INT\")\n\n    # Should fail - no overlap in types\n    assert not validate_node_input(\"BOOLEAN\", \"STRING,INT\")\n    assert not validate_node_input(\"FLOAT\", \"STRING,INT\")\n    assert not validate_node_input(\"FLOAT,BOOLEAN\", \"STRING,INT\")\n\n\ndef test_whitespace_handling():\n    \"\"\"Test that whitespace is handled correctly\"\"\"\n    assert validate_node_input(\"STRING, INT\", \"STRING,INT\")\n    assert validate_node_input(\"STRING,INT\", \"STRING, INT\")\n    assert validate_node_input(\" STRING , INT \", \"STRING,INT\")\n    assert validate_node_input(\"STRING,INT\", \" STRING , INT \")\n\n\ndef test_empty_strings():\n    \"\"\"Test behavior with empty strings\"\"\"\n    assert validate_node_input(\"\", \"\")\n    assert not validate_node_input(\"STRING\", \"\")\n    assert not validate_node_input(\"\", \"STRING\")\n\n\ndef test_single_vs_multiple():\n    \"\"\"Test single type against multiple types\"\"\"\n    assert validate_node_input(\"STRING\", \"STRING,INT,BOOLEAN\")\n    assert validate_node_input(\"STRING,INT,BOOLEAN\", \"STRING\", strict=False)\n    assert not validate_node_input(\"STRING,INT,BOOLEAN\", \"STRING\", strict=True)\n\n\ndef test_non_string():\n    \"\"\"Test non-string types\"\"\"\n    obj1 = object()\n    obj2 = object()\n    assert validate_node_input(obj1, obj1)\n    assert not validate_node_input(obj1, obj2)\n\n\nclass NotEqualsOverrideTest(str):\n    \"\"\"Test class for ``__ne__`` override.\"\"\"\n\n    def __ne__(self, value: object) -> bool:\n        if self == \"*\" or value == \"*\":\n            return False\n        if self == \"LONGER_THAN_2\":\n            return not len(value) > 2\n        raise TypeError(\"This is a class for unit tests only.\")\n\n\ndef test_ne_override():\n    \"\"\"Test ``__ne__`` any override\"\"\"\n    any = NotEqualsOverrideTest(\"*\")\n    invalid_type = \"INVALID_TYPE\"\n    obj = object()\n    assert validate_node_input(any, any)\n    assert validate_node_input(any, invalid_type)\n    assert validate_node_input(any, obj)\n    assert validate_node_input(any, {})\n    assert validate_node_input(any, [])\n    assert validate_node_input(any, [1, 2, 3])\n\n\ndef test_ne_custom_override():\n    \"\"\"Test ``__ne__`` custom override\"\"\"\n    special = NotEqualsOverrideTest(\"LONGER_THAN_2\")\n\n    assert validate_node_input(special, special)\n    assert validate_node_input(special, \"*\")\n    assert validate_node_input(special, \"INVALID_TYPE\")\n    assert validate_node_input(special, [1, 2, 3])\n\n    # Should fail\n    assert not validate_node_input(special, [1, 2])\n    assert not validate_node_input(special, \"TY\")\n\n\n@pytest.mark.parametrize(\n    \"received,input_type,strict,expected\",\n    [\n        (\"STRING\", \"STRING\", False, True),\n        (\"STRING,INT\", \"STRING,INT\", False, True),\n        (\"STRING\", \"STRING,INT\", True, True),\n        (\"STRING,INT\", \"STRING\", True, False),\n        (\"BOOLEAN\", \"STRING,INT\", False, False),\n        (\"STRING,BOOLEAN\", \"STRING,INT\", False, True),\n    ],\n)\ndef test_parametrized_cases(received, input_type, strict, expected):\n    \"\"\"Parametrized test cases for various scenarios\"\"\"\n    assert validate_node_input(received, input_type, strict) == expected\n",
    "tests-unit/folder_paths_test/filter_by_content_types_test.py": "import pytest\nimport os\nimport tempfile\nfrom folder_paths import filter_files_content_types\n\n@pytest.fixture(scope=\"module\")\ndef file_extensions():\n    return {\n        'image': ['gif', 'heif', 'ico', 'jpeg', 'jpg', 'png', 'pnm', 'ppm', 'svg', 'tiff', 'webp', 'xbm', 'xpm'],\n        'audio': ['aif', 'aifc', 'aiff', 'au', 'flac', 'm4a', 'mp2', 'mp3', 'ogg', 'snd', 'wav'],\n        'video': ['avi', 'm2v', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ogv', 'qt', 'webm', 'wmv']\n    }\n\n\n@pytest.fixture(scope=\"module\")\ndef mock_dir(file_extensions):\n    with tempfile.TemporaryDirectory() as directory:\n        for content_type, extensions in file_extensions.items():\n            for extension in extensions:\n                with open(f\"{directory}/sample_{content_type}.{extension}\", \"w\") as f:\n                    f.write(f\"Sample {content_type} file in {extension} format\")\n        yield directory\n\n\ndef test_categorizes_all_correctly(mock_dir, file_extensions):\n    files = os.listdir(mock_dir)\n    for content_type, extensions in file_extensions.items():\n        filtered_files = filter_files_content_types(files, [content_type])\n        for extension in extensions:\n            assert f\"sample_{content_type}.{extension}\" in filtered_files\n\n\ndef test_categorizes_all_uniquely(mock_dir, file_extensions):\n    files = os.listdir(mock_dir)\n    for content_type, extensions in file_extensions.items():\n        filtered_files = filter_files_content_types(files, [content_type])\n        assert len(filtered_files) == len(extensions)\n\n\ndef test_handles_bad_extensions():\n    files = [\"file1.txt\", \"file2.py\", \"file3.example\", \"file4.pdf\", \"file5.ini\", \"file6.doc\", \"file7.md\"]\n    assert filter_files_content_types(files, [\"image\", \"audio\", \"video\"]) == []\n\n\ndef test_handles_no_extension():\n    files = [\"file1\", \"file2\", \"file3\", \"file4\", \"file5\", \"file6\", \"file7\"]\n    assert filter_files_content_types(files, [\"image\", \"audio\", \"video\"]) == []\n\n\ndef test_handles_no_files():\n    files = []\n    assert filter_files_content_types(files, [\"image\", \"audio\", \"video\"]) == []\n",
    "tests-unit/prompt_server_test/user_manager_test.py": "import pytest\nimport os\nfrom aiohttp import web\nfrom app.user_manager import UserManager\nfrom unittest.mock import patch\n\npytestmark = (\n    pytest.mark.asyncio\n)  # This applies the asyncio mark to all test functions in the module\n\n\n@pytest.fixture\ndef user_manager(tmp_path):\n    um = UserManager()\n    um.get_request_user_filepath = lambda req, file, **kwargs: os.path.join(\n        tmp_path, file\n    ) if file else tmp_path\n    return um\n\n\n@pytest.fixture\ndef app(user_manager):\n    app = web.Application()\n    routes = web.RouteTableDef()\n    user_manager.add_routes(routes)\n    app.add_routes(routes)\n    return app\n\n\nasync def test_listuserdata_empty_directory(aiohttp_client, app, tmp_path):\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=test_dir\")\n    assert resp.status == 404\n\n\nasync def test_listuserdata_with_files(aiohttp_client, app, tmp_path):\n    os.makedirs(tmp_path / \"test_dir\")\n    with open(tmp_path / \"test_dir\" / \"file1.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=test_dir\")\n    assert resp.status == 200\n    assert await resp.json() == [\"file1.txt\"]\n\n\nasync def test_listuserdata_recursive(aiohttp_client, app, tmp_path):\n    os.makedirs(tmp_path / \"test_dir\" / \"subdir\")\n    with open(tmp_path / \"test_dir\" / \"file1.txt\", \"w\") as f:\n        f.write(\"test content\")\n    with open(tmp_path / \"test_dir\" / \"subdir\" / \"file2.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=test_dir&recurse=true\")\n    assert resp.status == 200\n    assert set(await resp.json()) == {\"file1.txt\", \"subdir/file2.txt\"}\n\n\nasync def test_listuserdata_full_info(aiohttp_client, app, tmp_path):\n    os.makedirs(tmp_path / \"test_dir\")\n    with open(tmp_path / \"test_dir\" / \"file1.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=test_dir&full_info=true\")\n    assert resp.status == 200\n    result = await resp.json()\n    assert len(result) == 1\n    assert result[0][\"path\"] == \"file1.txt\"\n    assert \"size\" in result[0]\n    assert \"modified\" in result[0]\n\n\nasync def test_listuserdata_split_path(aiohttp_client, app, tmp_path):\n    os.makedirs(tmp_path / \"test_dir\" / \"subdir\")\n    with open(tmp_path / \"test_dir\" / \"subdir\" / \"file1.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=test_dir&recurse=true&split=true\")\n    assert resp.status == 200\n    assert await resp.json() == [[\"subdir/file1.txt\", \"subdir\", \"file1.txt\"]]\n\n\nasync def test_listuserdata_invalid_directory(aiohttp_client, app):\n    client = await aiohttp_client(app)\n    resp = await client.get(\"/userdata?dir=\")\n    assert resp.status == 400\n\n\nasync def test_listuserdata_normalized_separator(aiohttp_client, app, tmp_path):\n    os_sep = \"\\\\\"\n    with patch(\"os.sep\", os_sep):\n        with patch(\"os.path.sep\", os_sep):\n            os.makedirs(tmp_path / \"test_dir\" / \"subdir\")\n            with open(tmp_path / \"test_dir\" / \"subdir\" / \"file1.txt\", \"w\") as f:\n                f.write(\"test content\")\n\n            client = await aiohttp_client(app)\n            resp = await client.get(\"/userdata?dir=test_dir&recurse=true\")\n            assert resp.status == 200\n            result = await resp.json()\n            assert len(result) == 1\n            assert \"/\" in result[0]  # Ensure forward slash is used\n            assert \"\\\\\" not in result[0]  # Ensure backslash is not present\n            assert result[0] == \"subdir/file1.txt\"\n\n            # Test with full_info\n            resp = await client.get(\n                \"/userdata?dir=test_dir&recurse=true&full_info=true\"\n            )\n            assert resp.status == 200\n            result = await resp.json()\n            assert len(result) == 1\n            assert \"/\" in result[0][\"path\"]  # Ensure forward slash is used\n            assert \"\\\\\" not in result[0][\"path\"]  # Ensure backslash is not present\n            assert result[0][\"path\"] == \"subdir/file1.txt\"\n\n\nasync def test_post_userdata_new_file(aiohttp_client, app, tmp_path):\n    client = await aiohttp_client(app)\n    content = b\"test content\"\n    resp = await client.post(\"/userdata/test.txt\", data=content)\n\n    assert resp.status == 200\n    assert await resp.text() == '\"test.txt\"'\n\n    # Verify file was created with correct content\n    with open(tmp_path / \"test.txt\", \"rb\") as f:\n        assert f.read() == content\n\n\nasync def test_post_userdata_overwrite_existing(aiohttp_client, app, tmp_path):\n    # Create initial file\n    with open(tmp_path / \"test.txt\", \"w\") as f:\n        f.write(\"initial content\")\n\n    client = await aiohttp_client(app)\n    new_content = b\"updated content\"\n    resp = await client.post(\"/userdata/test.txt\", data=new_content)\n\n    assert resp.status == 200\n    assert await resp.text() == '\"test.txt\"'\n\n    # Verify file was overwritten\n    with open(tmp_path / \"test.txt\", \"rb\") as f:\n        assert f.read() == new_content\n\n\nasync def test_post_userdata_no_overwrite(aiohttp_client, app, tmp_path):\n    # Create initial file\n    with open(tmp_path / \"test.txt\", \"w\") as f:\n        f.write(\"initial content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.post(\"/userdata/test.txt?overwrite=false\", data=b\"new content\")\n\n    assert resp.status == 409\n\n    # Verify original content unchanged\n    with open(tmp_path / \"test.txt\", \"r\") as f:\n        assert f.read() == \"initial content\"\n\n\nasync def test_post_userdata_full_info(aiohttp_client, app, tmp_path):\n    client = await aiohttp_client(app)\n    content = b\"test content\"\n    resp = await client.post(\"/userdata/test.txt?full_info=true\", data=content)\n\n    assert resp.status == 200\n    result = await resp.json()\n    assert result[\"path\"] == \"test.txt\"\n    assert result[\"size\"] == len(content)\n    assert \"modified\" in result\n\n\nasync def test_move_userdata(aiohttp_client, app, tmp_path):\n    # Create initial file\n    with open(tmp_path / \"source.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.post(\"/userdata/source.txt/move/dest.txt\")\n\n    assert resp.status == 200\n    assert await resp.text() == '\"dest.txt\"'\n\n    # Verify file was moved\n    assert not os.path.exists(tmp_path / \"source.txt\")\n    with open(tmp_path / \"dest.txt\", \"r\") as f:\n        assert f.read() == \"test content\"\n\n\nasync def test_move_userdata_no_overwrite(aiohttp_client, app, tmp_path):\n    # Create source and destination files\n    with open(tmp_path / \"source.txt\", \"w\") as f:\n        f.write(\"source content\")\n    with open(tmp_path / \"dest.txt\", \"w\") as f:\n        f.write(\"destination content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.post(\"/userdata/source.txt/move/dest.txt?overwrite=false\")\n\n    assert resp.status == 409\n\n    # Verify files remain unchanged\n    with open(tmp_path / \"source.txt\", \"r\") as f:\n        assert f.read() == \"source content\"\n    with open(tmp_path / \"dest.txt\", \"r\") as f:\n        assert f.read() == \"destination content\"\n\n\nasync def test_move_userdata_full_info(aiohttp_client, app, tmp_path):\n    # Create initial file\n    with open(tmp_path / \"source.txt\", \"w\") as f:\n        f.write(\"test content\")\n\n    client = await aiohttp_client(app)\n    resp = await client.post(\"/userdata/source.txt/move/dest.txt?full_info=true\")\n\n    assert resp.status == 200\n    result = await resp.json()\n    assert result[\"path\"] == \"dest.txt\"\n    assert result[\"size\"] == len(\"test content\")\n    assert \"modified\" in result\n\n    # Verify file was moved\n    assert not os.path.exists(tmp_path / \"source.txt\")\n    with open(tmp_path / \"dest.txt\", \"r\") as f:\n        assert f.read() == \"test content\"\n"
  },
  "requirements": "comfyui-frontend-package==1.12.14\ntorch\ntorchsde\ntorchvision\ntorchaudio\nnumpy>=1.25.0\neinops\ntransformers>=4.28.1\ntokenizers>=0.13.3\nsentencepiece\nsafetensors>=0.4.2\naiohttp>=3.11.8\nyarl>=1.18.0\npyyaml\nPillow\nscipy\ntqdm\npsutil\n\n#non essential dependencies:\nkornia>=0.7.1\nspandrel\nsoundfile\nav\n"
}