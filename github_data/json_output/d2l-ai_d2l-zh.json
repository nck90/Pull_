{
  "repo_name": "d2l-ai/d2l-zh",
  "repo_url": "https://github.com/d2l-ai/d2l-zh",
  "description": "《动手学深度学习》：面向中文读者、能运行、可讨论。中英文版被70多个国家的500多所大学用于教学。",
  "stars": 67284,
  "language": "Python",
  "created_at": "2017-08-23T04:40:24Z",
  "updated_at": "2025-03-19T06:09:56Z",
  "files": {
    "ci/docker/print_versions.py": "import os\nimport sys\n\nif len(sys.argv) > 1:\n\tframework_name = sys.argv[1]\nelse:\n\t# Assume using d2l-builder docker container\n\t# Here all the frameworks are installed and no CUDA support\n\tframework_name = None\n\nprint(\"*\"*10, \"D2L Framework Version Details\", \"*\"*10)\n\nif framework_name:\n\t# Print CUDA version\n\tprint(\"nvcc --version\")\n\tprint(os.system(\"nvcc --version\"))\n\nif framework_name==\"pytorch\":\n\t# Print PyTorch versions\n\tprint(f\"Framework Name: {framework_name}\")\n\timport torch; print(f\"torch version: {torch.__version__}\")\n\timport torchvision; print(f\"torchvision version: {torchvision.__version__}\")\n\timport gym; print(f\"gym version: {gym.__version__}\")\n\timport gpytorch; print(f\"gpytorch version: {gpytorch.__version__}\")\n\timport syne_tune; print(f\"syne_tune version: {syne_tune.__version__}\")\n\n\nif framework_name==\"tensorflow\":\n\t# Print TensorFlow versions\n\tprint(f\"Framework Name: {framework_name}\")\n\timport tensorflow; print(f\"tensorflow version: {tensorflow.__version__}\")\n\timport tensorflow_probability; print(f\"tensorflow_probability version: {tensorflow_probability.__version__}\")\n\nif framework_name==\"jax\":\n\t# Print JAX versions\n\tprint(f\"Framework Name: {framework_name}\")\n\timport jax; print(f\"jax version: {jax.__version__}\")\n\timport jaxlib; print(f\"jaxlib version: {jaxlib.__version__}\")\n\timport flax; print(f\"flax version: {flax.__version__}\")\n\timport tensorflow_datasets; print(f\"tensorflow_datasets version: {tensorflow_datasets.__version__}\")\n\nif framework_name==\"mxnet\":\n\t# Print MXNet versions\n\tprint(f\"Framework Name: {framework_name}\")\n\timport mxnet; print(f\"MXNet version: {mxnet.__version__}\")\n\n\n# Print d2lbook version\nimport d2lbook; print(f\"d2lbook version: {d2lbook.__version__}\")\n\nprint(\"*\"*10, \"D2L Framework Version Details\", \"*\"*10)\n",
    "ci/submit-job.py": "import argparse\nimport random\nimport os\nimport re\nimport sys\nimport time\nfrom datetime import datetime\n\nimport boto3\nfrom botocore.compat import total_seconds\nfrom botocore.config import Config\n\n\njob_type_info = {\n    'ci-cpu': {\n        'job_definition': 'd2l-ci-cpu-builder:2',\n        'job_queue': 'D2L-CI-CPU'\n    },\n    'ci-cpu-push': {\n        'job_definition': 'd2l-ci-cpu-builder-push:7',\n        'job_queue': 'D2L-CI-CPU'\n    },\n    'ci-cpu-release': {\n        'job_definition': 'd2l-ci-cpu-builder-release:1',\n        'job_queue': 'D2L-CI-CPU'\n    },\n    'ci-gpu-torch': {\n        'job_definition': 'd2l-ci-zh-gpu-torch:1',\n        'job_queue': 'D2L-CI-GPU'\n    },\n    'ci-gpu-tf': {\n        'job_definition': 'd2l-ci-zh-gpu-tf:1',\n        'job_queue': 'D2L-CI-GPU'\n    },\n    'ci-gpu-mxnet': {\n        'job_definition': 'd2l-ci-zh-gpu-mxnet:1',\n        'job_queue': 'D2L-CI-GPU'\n    },\n    'ci-gpu-paddle': {\n        'job_definition': 'd2l-ci-zh-gpu-paddle:1',\n        'job_queue': 'D2L-CI-GPU'\n    }\n}\n\n# Create push job types for GPUs with same definitions\nfor job_type in list(job_type_info.keys()):\n    if job_type.startswith('ci-gpu'):\n        job_type_info[job_type+'-push'] = job_type_info[job_type]\n        job_type_info[job_type+'-release'] = job_type_info[job_type]\n\nparser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n\nparser.add_argument('--profile', help='profile name of aws account.', type=str,\n                    default=None)\nparser.add_argument('--region', help='Default region when creating new connections', type=str,\n                    default='us-west-2')\nparser.add_argument('--name', help='name of the job', type=str, default='d2l-ci')\nparser.add_argument('--job-type', help='type of job to submit.', type=str,\n                    choices=job_type_info.keys(), default='ci-cpu')\nparser.add_argument('--source-ref',\n                    help='ref in d2l-zh main github. e.g. master, refs/pull/500/head',\n                    type=str, default='master')\nparser.add_argument('--work-dir',\n                    help='working directory inside the repo. e.g. scripts/preprocess',\n                    type=str, default='.')\nparser.add_argument('--saved-output',\n                    help='output to be saved, relative to working directory. '\n                         'it can be either a single file or a directory',\n                    type=str, default='None')\nparser.add_argument('--save-path',\n                    help='s3 path where files are saved.',\n                    type=str, default='batch/temp/{}'.format(datetime.now().isoformat()))\nparser.add_argument('--command', help='command to run', type=str,\n                    default='git rev-parse HEAD | tee stdout.log')\nparser.add_argument('--remote',\n                    help='git repo address. https://github.com/d2l-ai/d2l-zh',\n                    type=str, default=\"https://github.com/d2l-ai/d2l-zh\")\nparser.add_argument('--safe-to-use-script',\n                    help='whether the script changes from the actor is safe. We assume it is safe if the actor has write permission to our repo',\n                    action='store_true')\nparser.add_argument('--original-repo', help='name of the repo', type=str, default='d2l-zh')\nparser.add_argument('--wait', help='block wait until the job completes. '\n                    'Non-zero exit code if job fails.', action='store_true')\nparser.add_argument('--timeout', help='job timeout in seconds', default=7200, type=int)\n\n\nargs = parser.parse_args()\n\nsession = boto3.Session(profile_name=args.profile, region_name=args.region)\nconfig = Config(\n    retries = dict(\n        max_attempts = 20\n    )\n)\nbatch, cloudwatch = [session.client(service_name=sn, config=config) for sn in ['batch', 'logs']]\n\n\ndef printLogs(logGroupName, logStreamName, startTime):\n    kwargs = {'logGroupName': logGroupName,\n              'logStreamName': logStreamName,\n              'startTime': startTime,\n              'startFromHead': True}\n\n    lastTimestamp = startTime - 1\n    while True:\n        logEvents = cloudwatch.get_log_events(**kwargs)\n\n        for event in logEvents['events']:\n            lastTimestamp = event['timestamp']\n            timestamp = datetime.utcfromtimestamp(lastTimestamp / 1000.0).isoformat()\n            print('[{}] {}'.format((timestamp + '.000')[:23] + 'Z', event['message']))\n\n        nextToken = logEvents['nextForwardToken']\n        if nextToken and kwargs.get('nextToken') != nextToken:\n            kwargs['nextToken'] = nextToken\n        else:\n            break\n    return lastTimestamp\n\n\ndef nowInMillis():\n    endTime = int(total_seconds(datetime.utcnow() - datetime(1970, 1, 1))) * 1000\n    return endTime\n\n\ndef main():\n    spin = ['-', '/', '|', '\\\\', '-', '/', '|', '\\\\']\n    logGroupName = '/aws/batch/job'\n\n    jobName = re.sub('[^A-Za-z0-9_\\-]', '', args.name)[:128]  # Enforce AWS Batch jobName rules\n    jobType = args.job_type\n    jobQueue = job_type_info[jobType]['job_queue']\n    jobDefinition = job_type_info[jobType]['job_definition']\n    wait = args.wait\n\n    safe_to_use_script = 'False'\n    if args.safe_to_use_script:\n        safe_to_use_script = 'True'\n\n    parameters = {\n        'SOURCE_REF': args.source_ref,\n        'WORK_DIR': args.work_dir,\n        'SAVED_OUTPUT': args.saved_output,\n        'SAVE_PATH': args.save_path,\n        'COMMAND': f\"\\\"{args.command}\\\"\",  # wrap command with double quotation mark, so that batch can treat it as a single command\n        'REMOTE': args.remote,\n        'SAFE_TO_USE_SCRIPT': safe_to_use_script,\n        'ORIGINAL_REPO': args.original_repo\n    }\n    kwargs = dict(\n        jobName=jobName,\n        jobQueue=jobQueue,\n        jobDefinition=jobDefinition,\n        parameters=parameters,\n    )\n    if args.timeout is not None:\n        kwargs['timeout'] = {'attemptDurationSeconds': args.timeout}\n    submitJobResponse = batch.submit_job(**kwargs)\n\n    jobId = submitJobResponse['jobId']\n\n    # Export Batch_JobID to Github Actions Environment Variable\n    with open(os.environ['GITHUB_ENV'], 'a') as f:\n        f.write(f'Batch_JobID={jobId}\\n')\n    os.environ['batch_jobid'] = jobId\n\n    print('Submitted job [{} - {}] to the job queue [{}]'.format(jobName, jobId, jobQueue))\n\n    spinner = 0\n    running = False\n    status_set = set()\n    startTime = 0\n    logStreamName = None\n    while wait:\n        time.sleep(random.randint(5, 10))\n        describeJobsResponse = batch.describe_jobs(jobs=[jobId])\n        status = describeJobsResponse['jobs'][0]['status']\n        if status == 'SUCCEEDED' or status == 'FAILED':\n            if logStreamName:\n                startTime = printLogs(logGroupName, logStreamName, startTime) + 1\n            print('=' * 80)\n            print('Job [{} - {}] {}'.format(jobName, jobId, status))\n            sys.exit(status == 'FAILED')\n\n        elif status == 'RUNNING':\n            logStreamName = describeJobsResponse['jobs'][0]['container']['logStreamName']\n            if not running:\n                running = True\n                print('\\rJob [{}, {}] is RUNNING.'.format(jobName, jobId))\n                if logStreamName:\n                    print('Output [{}]:\\n {}'.format(logStreamName, '=' * 80))\n            if logStreamName:\n                startTime = printLogs(logGroupName, logStreamName, startTime) + 1\n        elif status not in status_set:\n            status_set.add(status)\n            print('\\rJob [%s - %s] is %-9s... %s' % (jobName, jobId, status, spin[spinner % len(spin)]),)\n            sys.stdout.flush()\n            spinner += 1\n\n\nif __name__ == '__main__':\n    main()\n",
    "contrib/to-rm-mx-contrib-text/d2lzh/__init__.py": "from . import text\nfrom .utils import *\n\n__version__ = '1.0.0'\n",
    "contrib/to-rm-mx-contrib-text/d2lzh/text/__init__.py": "from . import vocab\nfrom . import embedding",
    "contrib/to-rm-mx-contrib-text/d2lzh/text/embedding.py": "import os\nfrom mxnet import nd, gluon\nimport tarfile\nimport zipfile\n\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\nPRETRAINED_FILE = {\n    'glove':{},\n    'fasttext':{}\n}\nPRETRAINED_FILE['glove']['glove.6b.50d.txt'] = (DATA_URL + 'glove.6B.50d.zip',\n                                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\nPRETRAINED_FILE['glove']['glove.6b.100d.txt'] = (DATA_URL + 'glove.6B.100d.zip',\n                                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\nPRETRAINED_FILE['glove']['glove.42b.300d.txt'] = (DATA_URL + 'glove.42B.300d.zip',\n                                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\nPRETRAINED_FILE['fasttext']['wiki.en'] = (DATA_URL + 'wiki.en.zip',\n                                          'c1816da3821ae9f43899be655002f6c723e91b88')\n\ndef mkdir_if_not_exist(path):\n    if not isinstance(path, str):\n        path = os.path.join(*path)\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef download(embedding_name, pretrained_file_name, cache_dir=os.path.join('..', 'data')):\n    url, sha1 = PRETRAINED_FILE[embedding_name][pretrained_file_name]\n    mkdir_if_not_exist(cache_dir)\n    return gluon.utils.download(url, cache_dir, sha1_hash=sha1)\n\ndef download_extract(embedding_name, pretrained_file_name, folder=None):\n    \"\"\"Download and extract a zip/tar file.\"\"\"\n    fname = download(embedding_name, pretrained_file_name)\n    base_dir = os.path.dirname(fname) \n    data_dir, ext = os.path.splitext(fname)\n    if ext == '.zip':\n        fp = zipfile.ZipFile(fname, 'r')\n    elif ext in ('.tar', '.gz'):\n        fp = tarfile.open(fname, 'r')\n    else:\n        assert False, 'Only zip/tar files can be extracted'\n    fp.extractall(base_dir)\n    if folder:\n        return os.path.join(base_dir, folder)\n    else:\n        return data_dir\n    \ndef get_pretrained_file_names(embedding_name=None):\n    if embedding_name is not None:\n        return PRETRAINED_FILE[embedding_name].keys()\n    else:\n        return PRETRAINED_FILE\n    \ndef create(embedding_name, pretrained_file_name, vocabulary=None):\n    return TokenEmbedding(embedding_name, pretrained_file_name.lower(), vocabulary)\n    \nclass TokenEmbedding:\n    \"\"\"Token Embedding.\"\"\"\n    def __init__(self, embedding_name, pretrained_file_name, vocabulary=None):\n        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n            embedding_name, pretrained_file_name)\n        self.unknown_idx = 0\n        self.token_to_idx = {token: idx for idx, token in\n                             enumerate(self.idx_to_token)}\n        if vocabulary is not None:\n            indices = [self.token_to_idx.get(token, self.unknown_idx)\n                   for token in vocabulary.idx_to_token]\n            self.idx_to_vec = self.idx_to_vec[nd.array(indices)]\n            self.token_to_idx = vocabulary.token_to_idx\n            self.idx_to_token = vocabulary.idx_to_token\n            \n    def _load_embedding(self, embedding_name, pretrained_file_name):\n        idx_to_token, idx_to_vec = ['<unk>'], []\n        data_dir = download_extract(embedding_name, pretrained_file_name)\n        # GloVe website: https://nlp.stanford.edu/projects/glove/\n        # fastText website: https://fasttext.cc/\n        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n            for line in f:\n                elems = line.rstrip().split(' ')\n                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n                # Skip header information, such as the top row in fastText\n                if len(elems) > 1:\n                    idx_to_token.append(token)\n                    idx_to_vec.append(elems)\n        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n        return idx_to_token, nd.array(idx_to_vec)\n\n    def get_vecs_by_tokens(self, tokens):\n        indices = [self.token_to_idx.get(token, self.unknown_idx)\n                   for token in tokens]\n        vecs = self.idx_to_vec[nd.array(indices)]\n        return vecs\n\n    def __len__(self):\n        return len(self.idx_to_token)",
    "contrib/to-rm-mx-contrib-text/d2lzh/text/vocab.py": "class Vocabulary:\n    def __init__(self, counter, min_freq=0, reserved_tokens=None):\n        if reserved_tokens is None:\n            reserved_tokens = []\n        # Sort according to frequencies\n        self.token_freqs = sorted(counter.items(), key=lambda x: x[0])\n        self.token_freqs.sort(key=lambda x: x[1], reverse=True)\n        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n        uniq_tokens += [token for token, freq in self.token_freqs\n                        if freq >= min_freq and token not in uniq_tokens]\n        self.idx_to_token, self.token_to_idx = [], dict()\n        for token in uniq_tokens:\n            self.idx_to_token.append(token)\n            self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def to_indices(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.to_indices(token) for token in tokens]",
    "contrib/to-rm-mx-contrib-text/d2lzh/utils.py": "import collections\nfrom d2lzh import text\nimport math\nimport os\nimport random\nimport sys\nimport tarfile\nimport time\nimport zipfile\n\nfrom IPython import display\nfrom matplotlib import pyplot as plt\nimport mxnet as mx\nfrom mxnet import autograd, gluon, image, init, nd\nfrom mxnet.gluon import data as gdata, loss as gloss, nn, utils as gutils\nimport numpy as np\n\n\nVOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n\n\nVOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n                [0, 64, 128]]\n\n\ndef bbox_to_rect(bbox, color):\n    \"\"\"Convert bounding box to matplotlib format.\"\"\"\n    return plt.Rectangle(xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0],\n                         height=bbox[3]-bbox[1], fill=False, edgecolor=color,\n                         linewidth=2)\n\n\nclass Benchmark():\n    \"\"\"Benchmark programs.\"\"\"\n    def __init__(self, prefix=None):\n        self.prefix = prefix + ' ' if prefix else ''\n\n    def __enter__(self):\n        self.start = time.time()\n\n    def __exit__(self, *args):\n        print('%stime: %.4f sec' % (self.prefix, time.time() - self.start))\n\n\ndef corr2d(X, K):\n    \"\"\"Compute 2D cross-correlation.\"\"\"\n    h, w = K.shape\n    Y = nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n    return Y\n\n\ndef count_tokens(samples):\n    \"\"\"Count tokens in the data set.\"\"\"\n    token_counter = collections.Counter()\n    for sample in samples:\n        for token in sample:\n            if token not in token_counter:\n                token_counter[token] = 1\n            else:\n                token_counter[token] += 1\n    return token_counter\n\n\ndef data_iter(batch_size, features, labels):\n    \"\"\"Iterate through a data set.\"\"\"\n    num_examples = len(features)\n    indices = list(range(num_examples))\n    random.shuffle(indices)\n    for i in range(0, num_examples, batch_size):\n        j = nd.array(indices[i: min(i + batch_size, num_examples)])\n        yield features.take(j), labels.take(j)\n\n\ndef data_iter_consecutive(corpus_indices, batch_size, num_steps, ctx=None):\n    \"\"\"Sample mini-batches in a consecutive order from sequential data.\"\"\"\n    corpus_indices = nd.array(corpus_indices, ctx=ctx)\n    data_len = len(corpus_indices)\n    batch_len = data_len // batch_size\n    indices = corpus_indices[0 : batch_size * batch_len].reshape((\n        batch_size, batch_len))\n    epoch_size = (batch_len - 1) // num_steps\n    for i in range(epoch_size):\n        i = i * num_steps\n        X = indices[:, i : i + num_steps]\n        Y = indices[:, i + 1 : i + num_steps + 1]\n        yield X, Y\n\n\ndef data_iter_random(corpus_indices, batch_size, num_steps, ctx=None):\n    \"\"\"Sample mini-batches in a random order from sequential data.\"\"\"\n    num_examples = (len(corpus_indices) - 1) // num_steps\n    epoch_size = num_examples // batch_size\n    example_indices = list(range(num_examples))\n    random.shuffle(example_indices)\n\n    def _data(pos):\n        return corpus_indices[pos : pos + num_steps]\n\n    for i in range(epoch_size):\n        i = i * batch_size\n        batch_indices = example_indices[i : i + batch_size]\n        X = nd.array(\n            [_data(j * num_steps) for j in batch_indices], ctx=ctx)\n        Y = nd.array(\n            [_data(j * num_steps + 1) for j in batch_indices], ctx=ctx)\n        yield X, Y\n\n\ndef download_imdb(data_dir='../data'):\n    \"\"\"Download the IMDB data set for sentiment analysis.\"\"\"\n    url = ('http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz')\n    sha1 = '01ada507287d82875905620988597833ad4e0903'\n    fname = gutils.download(url, data_dir, sha1_hash=sha1)\n    with tarfile.open(fname, 'r') as f:\n        f.extractall(data_dir)\n\n\ndef _download_pikachu(data_dir):\n    root_url = ('https://apache-mxnet.s3-accelerate.amazonaws.com/'\n                'gluon/dataset/pikachu/')\n    dataset = {'train.rec': 'e6bcb6ffba1ac04ff8a9b1115e650af56ee969c8',\n               'train.idx': 'dcf7318b2602c06428b9988470c731621716c393',\n               'val.rec': 'd6c33f799b4d058e82f2cb5bd9a976f69d72d520'}\n    for k, v in dataset.items():\n        gutils.download(root_url + k, os.path.join(data_dir, k), sha1_hash=v)\n\n\ndef download_voc_pascal(data_dir='../data'):\n    \"\"\"Download the Pascal VOC2012 Dataset.\"\"\"\n    voc_dir = os.path.join(data_dir, 'VOCdevkit/VOC2012')\n    url = ('http://host.robots.ox.ac.uk/pascal/VOC/voc2012'\n           '/VOCtrainval_11-May-2012.tar')\n    sha1 = '4e443f8a2eca6b1dac8a6c57641b67dd40621a49'\n    fname = gutils.download(url, data_dir, sha1_hash=sha1)\n    with tarfile.open(fname, 'r') as f:\n        f.extractall(data_dir)\n    return voc_dir\n\n\ndef evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n    if isinstance(ctx, mx.Context):\n        ctx = [ctx]\n    acc_sum, n = nd.array([0]), 0\n    for batch in data_iter:\n        features, labels, _ = _get_batch(batch, ctx)\n        for X, y in zip(features, labels):\n            y = y.astype('float32')\n            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n            n += y.size\n        acc_sum.wait_to_read()\n    return acc_sum.asscalar() / n\n\n\ndef _get_batch(batch, ctx):\n    \"\"\"Return features and labels on ctx.\"\"\"\n    features, labels = batch\n    if labels.dtype != features.dtype:\n        labels = labels.astype(features.dtype)\n    return (gutils.split_and_load(features, ctx),\n            gutils.split_and_load(labels, ctx), features.shape[0])\n\n\ndef get_data_ch7():\n    \"\"\"Get the data set used in Chapter 7.\"\"\"\n    data = np.genfromtxt('../data/airfoil_self_noise.dat', delimiter='\\t')\n    data = (data - data.mean(axis=0)) / data.std(axis=0)\n    return nd.array(data[:, :-1]), nd.array(data[:, -1])\n\n\ndef get_fashion_mnist_labels(labels):\n    \"\"\"Get text label for fashion mnist.\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n\n\ndef get_tokenized_imdb(data):\n    \"\"\"Get the tokenized IMDB data set for sentiment analysis.\"\"\"\n    def tokenizer(text):\n        return [tok.lower() for tok in text.split(' ')]\n    return [tokenizer(review) for review, _ in data]\n\n\ndef get_vocab_imdb(data):\n    \"\"\"Get the vocab for the IMDB data set for sentiment analysis.\"\"\"\n    tokenized_data = get_tokenized_imdb(data)\n    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n    return text.vocab.Vocabulary(counter, min_freq=5,\n                                 reserved_tokens=['<pad>'])\n\n\ndef grad_clipping(params, theta, ctx):\n    \"\"\"Clip the gradient.\"\"\"\n    if theta is not None:\n        norm = nd.array([0], ctx)\n        for param in params:\n            norm += (param.grad ** 2).sum()\n        norm = norm.sqrt().asscalar()\n        if norm > theta:\n            for param in params:\n                param.grad[:] *= theta / norm\n\n\ndef linreg(X, w, b):\n    \"\"\"Linear regression.\"\"\"\n    return nd.dot(X, w) + b\n\n\ndef load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n    root = os.path.expanduser(root)\n    transformer = []\n    if resize:\n        transformer += [gdata.vision.transforms.Resize(resize)]\n    transformer += [gdata.vision.transforms.ToTensor()]\n    transformer = gdata.vision.transforms.Compose(transformer)\n\n    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n    num_workers = 0 if sys.platform.startswith('win32') else 4\n\n    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n                                  batch_size, shuffle=True,\n                                  num_workers=num_workers)\n    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n                                 batch_size, shuffle=False,\n                                 num_workers=num_workers)\n    return train_iter, test_iter\n\n\ndef load_data_jay_lyrics():\n    \"\"\"Load the Jay Chou lyric data set (available in the Chinese book).\"\"\"\n    with zipfile.ZipFile('../data/jaychou_lyrics.txt.zip') as zin:\n        with zin.open('jaychou_lyrics.txt') as f:\n            corpus_chars = f.read().decode('utf-8')\n    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n    corpus_chars = corpus_chars[0:10000]\n    idx_to_char = list(set(corpus_chars))\n    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n    vocab_size = len(char_to_idx)\n    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n\n\ndef load_data_pikachu(batch_size, edge_size=256):\n    \"\"\"Download the pikachu dataest and then load into memory.\"\"\"\n    data_dir = '../data/pikachu'\n    _download_pikachu(data_dir)\n    train_iter = image.ImageDetIter(\n        path_imgrec=os.path.join(data_dir, 'train.rec'),\n        path_imgidx=os.path.join(data_dir, 'train.idx'),\n        batch_size=batch_size,\n        data_shape=(3, edge_size, edge_size),\n        shuffle=True,\n        rand_crop=1,\n        min_object_covered=0.95,\n        max_attempts=200)\n    val_iter = image.ImageDetIter(\n        path_imgrec=os.path.join(data_dir, 'val.rec'),\n        batch_size=batch_size,\n        data_shape=(3, edge_size, edge_size),\n        shuffle=False)\n    return train_iter, val_iter\n\n\ndef load_data_time_machine():\n    \"\"\"Load the time machine data set (available in the English book).\"\"\"\n    with open('../data/timemachine.txt') as f:\n        corpus_chars = f.read()\n    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ').lower()\n    corpus_chars = corpus_chars[0:10000]\n    idx_to_char = list(set(corpus_chars))\n    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n    vocab_size = len(char_to_idx)\n    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n\n\ndef _make_list(obj, default_values=None):\n    if obj is None:\n        obj = default_values\n    elif not isinstance(obj, (list, tuple)):\n        obj = [obj]\n    return obj\n\n\ndef mkdir_if_not_exist(path):\n    \"\"\"Make a directory if it does not exist.\"\"\"\n    if not os.path.exists(os.path.join(*path)):\n        os.makedirs(os.path.join(*path))\n\n\ndef predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n                num_hiddens, vocab_size, ctx, idx_to_char, char_to_idx):\n    \"\"\"Predict next chars with a RNN model\"\"\"\n    state = init_rnn_state(1, num_hiddens, ctx)\n    output = [char_to_idx[prefix[0]]]\n    for t in range(num_chars + len(prefix) - 1):\n        X = to_onehot(nd.array([output[-1]], ctx=ctx), vocab_size)\n        (Y, state) = rnn(X, state, params)\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])\n        else:\n            output.append(int(Y[0].argmax(axis=1).asscalar()))\n    return ''.join([idx_to_char[i] for i in output])\n\n\ndef predict_rnn_gluon(prefix, num_chars, model, vocab_size, ctx, idx_to_char,\n                      char_to_idx):\n    \"\"\"Precit next chars with a Gluon RNN model\"\"\"\n    state = model.begin_state(batch_size=1, ctx=ctx)\n    output = [char_to_idx[prefix[0]]]\n    for t in range(num_chars + len(prefix) - 1):\n        X = nd.array([output[-1]], ctx=ctx).reshape((1, 1))\n        (Y, state) = model(X, state)\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])\n        else:\n            output.append(int(Y.argmax(axis=1).asscalar()))\n    return ''.join([idx_to_char[i] for i in output])\n\n\ndef predict_sentiment(net, vocab, sentence):\n    \"\"\"Predict the sentiment of a given sentence.\"\"\"\n    sentence = nd.array(vocab.to_indices(sentence), ctx=try_gpu())\n    label = nd.argmax(net(sentence.reshape((1, -1))), axis=1)\n    return 'positive' if label.asscalar() == 1 else 'negative'\n\n\ndef preprocess_imdb(data, vocab):\n    \"\"\"Preprocess the IMDB data set for sentiment analysis.\"\"\"\n    max_l = 500\n\n    def pad(x):\n        return x[:max_l] if len(x) > max_l else x + [\n            vocab.token_to_idx['<pad>']] * (max_l - len(x))\n\n    tokenized_data = get_tokenized_imdb(data)\n    features = nd.array([pad(vocab.to_indices(x)) for x in tokenized_data])\n    labels = nd.array([score for _, score in data])\n    return features, labels\n\n\ndef read_imdb(folder='train'):\n    \"\"\"Read the IMDB data set for sentiment analysis.\"\"\"\n    data = []\n    for label in ['pos', 'neg']:\n        folder_name = os.path.join('../data/aclImdb/', folder, label)\n        for file in os.listdir(folder_name):\n            with open(os.path.join(folder_name, file), 'rb') as f:\n                review = f.read().decode('utf-8').replace('\\n', '').lower()\n                data.append([review, 1 if label == 'pos' else 0])\n    random.shuffle(data)\n    return data\n\n\ndef read_voc_images(root='../data/VOCdevkit/VOC2012', is_train=True):\n    \"\"\"Read VOC images.\"\"\"\n    txt_fname = '%s/ImageSets/Segmentation/%s' % (\n        root, 'train.txt' if is_train else 'val.txt')\n    with open(txt_fname, 'r') as f:\n        images = f.read().split()\n    features, labels = [None] * len(images), [None] * len(images)\n    for i, fname in enumerate(images):\n        features[i] = image.imread('%s/JPEGImages/%s.jpg' % (root, fname))\n        labels[i] = image.imread(\n            '%s/SegmentationClass/%s.png' % (root, fname))\n    return features, labels\n\n\nclass Residual(nn.Block):\n    \"\"\"The residual block.\"\"\"\n    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n        super(Residual, self).__init__(**kwargs)\n        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1,\n                               strides=strides)\n        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.Conv2D(num_channels, kernel_size=1,\n                                   strides=strides)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm()\n        self.bn2 = nn.BatchNorm()\n\n    def forward(self, X):\n        Y = nd.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        if self.conv3:\n            X = self.conv3(X)\n        return nd.relu(Y + X)\n\n\ndef resnet18(num_classes):\n    \"\"\"The ResNet-18 model.\"\"\"\n    net = nn.Sequential()\n    net.add(nn.Conv2D(64, kernel_size=3, strides=1, padding=1),\n            nn.BatchNorm(), nn.Activation('relu'))\n\n    def resnet_block(num_channels, num_residuals, first_block=False):\n        blk = nn.Sequential()\n        for i in range(num_residuals):\n            if i == 0 and not first_block:\n                blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n            else:\n                blk.add(Residual(num_channels))\n        return blk\n\n    net.add(resnet_block(64, 2, first_block=True),\n            resnet_block(128, 2),\n            resnet_block(256, 2),\n            resnet_block(512, 2))\n    net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))\n    return net\n\n\nclass RNNModel(nn.Block):\n    \"\"\"RNN model.\"\"\"\n    def __init__(self, rnn_layer, vocab_size, **kwargs):\n        super(RNNModel, self).__init__(**kwargs)\n        self.rnn = rnn_layer\n        self.vocab_size = vocab_size\n        self.dense = nn.Dense(vocab_size)\n\n    def forward(self, inputs, state):\n        X = nd.one_hot(inputs.T, self.vocab_size)\n        Y, state = self.rnn(X, state)\n        output = self.dense(Y.reshape((-1, Y.shape[-1])))\n        return output, state\n\n    def begin_state(self, *args, **kwargs):\n        return self.rnn.begin_state(*args, **kwargs)\n\n\ndef semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\n             legend=None, figsize=(3.5, 2.5)):\n    \"\"\"Plot x and log(y).\"\"\"\n    set_figsize(figsize)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)\n    plt.semilogy(x_vals, y_vals)\n    if x2_vals and y2_vals:\n        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n        plt.legend(legend)\n    plt.show()\n\n\ndef set_figsize(figsize=(3.5, 2.5)):\n    \"\"\"Set matplotlib figure size.\"\"\"\n    use_svg_display()\n    plt.rcParams['figure.figsize'] = figsize\n\n\ndef sgd(params, lr, batch_size):\n    \"\"\"Mini-batch stochastic gradient descent.\"\"\"\n    for param in params:\n        param[:] = param - lr * param.grad / batch_size\n\n\ndef show_bboxes(axes, bboxes, labels=None, colors=None):\n    \"\"\"Show bounding boxes.\"\"\"\n    labels = _make_list(labels)\n    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'k'])\n    for i, bbox in enumerate(bboxes):\n        color = colors[i % len(colors)]\n        rect = bbox_to_rect(bbox.asnumpy(), color)\n        axes.add_patch(rect)\n        if labels and len(labels) > i:\n            text_color = 'k' if color == 'w' else 'w'\n            axes.text(rect.xy[0], rect.xy[1], labels[i],\n                      va='center', ha='center', fontsize=9, color=text_color,\n                      bbox=dict(facecolor=color, lw=0))\n\n\ndef show_fashion_mnist(images, labels):\n    \"\"\"Plot Fashion-MNIST images with labels.\"\"\"\n    use_svg_display()\n    _, figs = plt.subplots(1, len(images), figsize=(12, 12))\n    for f, img, lbl in zip(figs, images, labels):\n        f.imshow(img.reshape((28, 28)).asnumpy())\n        f.set_title(lbl)\n        f.axes.get_xaxis().set_visible(False)\n        f.axes.get_yaxis().set_visible(False)\n\n\ndef show_images(imgs, num_rows, num_cols, scale=2):\n    \"\"\"Plot a list of images.\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n    for i in range(num_rows):\n        for j in range(num_cols):\n            axes[i][j].imshow(imgs[i * num_cols + j].asnumpy())\n            axes[i][j].axes.get_xaxis().set_visible(False)\n            axes[i][j].axes.get_yaxis().set_visible(False)\n    return axes\n\n\ndef show_trace_2d(f, res):\n    \"\"\"Show the trace of 2d variables during optimization.\"\"\"\n    x1, x2 = zip(*res)\n    set_figsize()\n    plt.plot(x1, x2, '-o', color='#ff7f0e')\n    x1 = np.arange(-5.5, 1.0, 0.1)\n    x2 = np.arange(min(-3.0, min(x2) - 1), max(1.0, max(x2) + 1), 0.1)\n    x1, x2 = np.meshgrid(x1, x2)\n    plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n    plt.xlabel('x1')\n    plt.ylabel('x2')\n\n\ndef squared_loss(y_hat, y):\n    \"\"\"Squared loss.\"\"\"\n    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n\n\ndef to_onehot(X, size):\n    \"\"\"Represent inputs with one-hot encoding.\"\"\"\n    return [nd.one_hot(x, size) for x in X.T]\n\n\ndef train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs):\n    \"\"\"Train and evaluate a model.\"\"\"\n    print('training on', ctx)\n    if isinstance(ctx, mx.Context):\n        ctx = [ctx]\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n        for i, batch in enumerate(train_iter):\n            Xs, ys, batch_size = _get_batch(batch, ctx)   \n            with autograd.record():\n                y_hats = [net(X) for X in Xs]\n                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n            for l in ls:\n                l.backward()\n            trainer.step(batch_size)\n            train_l_sum += sum([l.sum().asscalar() for l in ls])\n            n += sum([l.size for l in ls])\n            train_acc_sum += sum([(y_hat.argmax(axis=1) == y).sum().asscalar()\n                                 for y_hat, y in zip(y_hats, ys)])\n            m += sum([y.size for y in ys])\n        test_acc = evaluate_accuracy(test_iter, net, ctx)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n              'time %.1f sec'\n              % (epoch + 1, train_l_sum / n, train_acc_sum / m, test_acc,\n                 time.time() - start))\n\n\ndef train_2d(trainer):\n    \"\"\"Optimize the objective function of 2d variables with a customized trainer.\"\"\"\n    x1, x2 = -5, -2\n    s_x1, s_x2 = 0, 0\n    res = [(x1, x2)]\n    for i in range(20):\n        x1, x2, s_x1, s_x2 = trainer(x1, x2, s_x1, s_x2)\n        res.append((x1, x2))\n    print('epoch %d, x1 %f, x2 %f' % (i+1, x1, x2))\n    return res\n\n\ndef train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                          vocab_size, ctx, corpus_indices, idx_to_char,\n                          char_to_idx, is_random_iter, num_epochs, num_steps,\n                          lr, clipping_theta, batch_size, pred_period,\n                          pred_len, prefixes):\n    \"\"\"Train an RNN model and predict the next item in the sequence.\"\"\"\n    if is_random_iter:\n        data_iter_fn = data_iter_random\n    else:\n        data_iter_fn = data_iter_consecutive\n    params = get_params()\n    loss = gloss.SoftmaxCrossEntropyLoss()\n\n    for epoch in range(num_epochs):\n        if not is_random_iter:\n            state = init_rnn_state(batch_size, num_hiddens, ctx)\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, ctx)\n        for X, Y in data_iter:\n            if is_random_iter:\n                state = init_rnn_state(batch_size, num_hiddens, ctx)\n            else:\n                for s in state:\n                    s.detach()\n            with autograd.record():\n                inputs = to_onehot(X, vocab_size)\n                (outputs, state) = rnn(inputs, state, params)\n                outputs = nd.concat(*outputs, dim=0)\n                y = Y.T.reshape((-1,))\n                l = loss(outputs, y).mean()\n            l.backward()\n            grad_clipping(params, clipping_theta, ctx)\n            sgd(params, lr, 1)\n            l_sum += l.asscalar() * y.size\n            n += y.size\n\n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn(\n                    prefix, pred_len, rnn, params, init_rnn_state,\n                    num_hiddens, vocab_size, ctx, idx_to_char, char_to_idx))\n\n\ndef train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes):\n    \"\"\"Train an Gluon RNN model and predict the next item in the sequence.\"\"\"\n    loss = gloss.SoftmaxCrossEntropyLoss()\n    model.initialize(ctx=ctx, force_reinit=True, init=init.Normal(0.01))\n    trainer = gluon.Trainer(model.collect_params(), 'sgd',\n                            {'learning_rate': lr, 'momentum': 0, 'wd': 0})\n\n    for epoch in range(num_epochs):\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = data_iter_consecutive(\n            corpus_indices, batch_size, num_steps, ctx)\n        state = model.begin_state(batch_size=batch_size, ctx=ctx)\n        for X, Y in data_iter:\n            for s in state:\n                s.detach()\n            with autograd.record():\n                (output, state) = model(X, state)\n                y = Y.T.reshape((-1,))\n                l = loss(output, y).mean()\n            l.backward()\n            params = [p.data() for p in model.collect_params().values()]\n            grad_clipping(params, clipping_theta, ctx)\n            trainer.step(1)\n            l_sum += l.asscalar() * y.size\n            n += y.size\n\n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn_gluon(\n                    prefix, pred_len, model, vocab_size, ctx, idx_to_char,\n                    char_to_idx))\n\n\ndef train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n              params=None, lr=None, trainer=None):\n    \"\"\"Train and evaluate a model with CPU.\"\"\"\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n        for X, y in train_iter:\n            with autograd.record():\n                y_hat = net(X)\n                l = loss(y_hat, y).sum()\n            l.backward()\n            if trainer is None:\n                sgd(params, lr, batch_size)\n            else:\n                trainer.step(batch_size)\n            y = y.astype('float32')\n            train_l_sum += l.asscalar()\n            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n            n += y.size\n        test_acc = evaluate_accuracy(test_iter, net)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n\n\ndef train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx,\n              num_epochs):\n    \"\"\"Train and evaluate a model with CPU or GPU.\"\"\"\n    print('training on', ctx)\n    loss = gloss.SoftmaxCrossEntropyLoss()\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n        for X, y in train_iter:\n            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n            with autograd.record():\n                y_hat = net(X)\n                l = loss(y_hat, y).sum()\n            l.backward()\n            trainer.step(batch_size)\n            y = y.astype('float32')\n            train_l_sum += l.asscalar()\n            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n            n += y.size\n        test_acc = evaluate_accuracy(test_iter, net, ctx)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n              'time %.1f sec'\n              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n                 time.time() - start))\n\n\ndef train_ch7(trainer_fn, states, hyperparams, features, labels, batch_size=10,\n              num_epochs=2):\n    \"\"\"Train a linear regression model.\"\"\"\n    net, loss = linreg, squared_loss\n    w, b = nd.random.normal(scale=0.01, shape=(features.shape[1], 1)), nd.zeros(1)\n    w.attach_grad()\n    b.attach_grad()\n\n    def eval_loss():\n        return loss(net(features, w, b), labels).mean().asscalar()\n\n    ls = [eval_loss()]\n    data_iter = gdata.DataLoader(\n        gdata.ArrayDataset(features, labels), batch_size, shuffle=True)\n    for _ in range(num_epochs):\n        start = time.time()\n        for batch_i, (X, y) in enumerate(data_iter):\n            with autograd.record():\n                l = loss(net(X, w, b), y).mean()\n            l.backward()\n            trainer_fn([w, b], states, hyperparams)\n            if (batch_i + 1) * batch_size % 100 == 0:\n                ls.append(eval_loss())\n    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\n    set_figsize()\n    plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n\n\ndef train_gluon_ch7(trainer_name, trainer_hyperparams, features, labels,\n                    batch_size=10, num_epochs=2):\n    \"\"\"Train a linear regression model with a given Gluon trainer.\"\"\"\n    net = nn.Sequential()\n    net.add(nn.Dense(1))\n    net.initialize(init.Normal(sigma=0.01))\n    loss = gloss.L2Loss()\n\n    def eval_loss():\n        return loss(net(features), labels).mean().asscalar()\n\n    ls = [eval_loss()]\n    data_iter = gdata.DataLoader(\n        gdata.ArrayDataset(features, labels), batch_size, shuffle=True)\n    trainer = gluon.Trainer(net.collect_params(),\n                            trainer_name, trainer_hyperparams)\n    for _ in range(num_epochs):\n        start = time.time()\n        for batch_i, (X, y) in enumerate(data_iter):\n            with autograd.record():\n                l = loss(net(X), y)\n            l.backward()\n            trainer.step(batch_size)\n            if (batch_i + 1) * batch_size % 100 == 0:\n                ls.append(eval_loss())\n    print('loss: %f, %f sec per epoch' % (ls[-1], time.time() - start))\n    set_figsize()\n    plt.plot(np.linspace(0, num_epochs, len(ls)), ls)\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n\n\ndef try_all_gpus():\n    \"\"\"Return all available GPUs, or [mx.cpu()] if there is no GPU.\"\"\"\n    ctxes = []\n    try:\n        for i in range(16):\n            ctx = mx.gpu(i)\n            _ = nd.array([0], ctx=ctx)\n            ctxes.append(ctx)\n    except mx.base.MXNetError:\n        pass\n    if not ctxes:\n        ctxes = [mx.cpu()]\n    return ctxes\n\n\ndef try_gpu():\n    \"\"\"If GPU is available, return mx.gpu(0); else return mx.cpu().\"\"\"\n    try:\n        ctx = mx.gpu()\n        _ = nd.array([0], ctx=ctx)\n    except mx.base.MXNetError:\n        ctx = mx.cpu()\n    return ctx\n\n\ndef use_svg_display():\n    \"\"\"Use svg format to display plot in jupyter\"\"\"\n    display.set_matplotlib_formats('svg')\n\n\ndef voc_label_indices(colormap, colormap2label):\n    \"\"\"Assign label indices for Pascal VOC2012 Dataset.\"\"\"\n    colormap = colormap.astype('int32')\n    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n           + colormap[:, :, 2])\n    return colormap2label[idx]\n\n\ndef voc_rand_crop(feature, label, height, width):\n    \"\"\"Random cropping for images of the Pascal VOC2012 Dataset.\"\"\"\n    feature, rect = image.random_crop(feature, (width, height))\n    label = image.fixed_crop(label, *rect)\n    return feature, label\n\n\nclass VOCSegDataset(gdata.Dataset):\n    \"\"\"The Pascal VOC2012 Dataset.\"\"\"\n    def __init__(self, is_train, crop_size, voc_dir, colormap2label):\n        self.rgb_mean = nd.array([0.485, 0.456, 0.406])\n        self.rgb_std = nd.array([0.229, 0.224, 0.225])\n        self.crop_size = crop_size\n        data, labels = read_voc_images(root=voc_dir, is_train=is_train)\n        self.data = [self.normalize_image(im) for im in self.filter(data)]\n        self.labels = self.filter(labels)\n        self.colormap2label = colormap2label\n        print('read ' + str(len(self.data)) + ' examples')\n\n    def normalize_image(self, data):\n        return (data.astype('float32') / 255 - self.rgb_mean) / self.rgb_std\n\n    def filter(self, images):\n        return [im for im in images if (\n            im.shape[0] >= self.crop_size[0] and\n            im.shape[1] >= self.crop_size[1])]\n\n    def __getitem__(self, idx):\n        data, labels = voc_rand_crop(self.data[idx], self.labels[idx],\n                                     *self.crop_size)\n        return (data.transpose((2, 0, 1)),\n                voc_label_indices(labels, self.colormap2label))\n\n    def __len__(self):\n        return len(self.data)\n",
    "d2l/__init__.py": "\"\"\"Saved source code for \"Dive into Deep Learing\" (https://d2l.ai).\n\nPlease import d2l by one of the following ways:\n\nfrom d2l import mxnet as d2l  # Use MXNet as the backend\nfrom d2l import torch as d2l  # Use PyTorch as the backend\nfrom d2l import tensorflow as d2l  # Use TensorFlow as the backend\nfrom d2l import paddle as d2l  # Use Paddle as the backend\n\n\"\"\"\n\n__version__ = \"2.0.0\"\n",
    "d2l/mxnet.py": "USE_MXNET = True\nUSE_PYTORCH = False\nUSE_TENSORFLOW = False\n\nDATA_HUB = dict()\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n\nfrom mxnet import autograd, context, gluon, image, init, np, npx\nfrom mxnet.gluon import nn, rnn\nfrom mxnet.gluon.data.vision import transforms\n\nnn_Module = nn.Block\n\n#################   WARNING   ################\n# The below part is generated automatically through:\n#    d2lbook build lib\n# Don't edit it directly\n\nimport collections\nimport hashlib\nimport math\nimport os\nimport random\nimport re\nimport shutil\nimport sys\nimport tarfile\nimport time\nimport zipfile\nfrom collections import defaultdict\nimport pandas as pd\nimport requests\nfrom IPython import display\nfrom matplotlib import pyplot as plt\nfrom matplotlib_inline import backend_inline\n\nd2l = sys.modules[__name__]\n\nfrom mxnet import autograd, context, gluon, image, init, np, npx\nfrom mxnet.gluon import nn, rnn\n\ndef use_svg_display():\n    \"\"\"使用svg格式在Jupyter中显示绘图\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    backend_inline.set_matplotlib_formats('svg')\n\ndef set_figsize(figsize=(3.5, 2.5)):\n    \"\"\"设置matplotlib的图表大小\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    use_svg_display()\n    d2l.plt.rcParams['figure.figsize'] = figsize\n\ndef set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n    \"\"\"设置matplotlib的轴\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel)\n    axes.set_xscale(xscale)\n    axes.set_yscale(yscale)\n    axes.set_xlim(xlim)\n    axes.set_ylim(ylim)\n    if legend:\n        axes.legend(legend)\n    axes.grid()\n\ndef plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n         ylim=None, xscale='linear', yscale='linear',\n         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n    \"\"\"绘制数据点\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    if legend is None:\n        legend = []\n\n    set_figsize(figsize)\n    axes = axes if axes else d2l.plt.gca()\n\n    # 如果X有一个轴，输出True\n    def has_one_axis(X):\n        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n                and not hasattr(X[0], \"__len__\"))\n\n    if has_one_axis(X):\n        X = [X]\n    if Y is None:\n        X, Y = [[]] * len(X), X\n    elif has_one_axis(Y):\n        Y = [Y]\n    if len(X) != len(Y):\n        X = X * len(Y)\n    axes.cla()\n    for x, y, fmt in zip(X, Y, fmts):\n        if len(x):\n            axes.plot(x, y, fmt)\n        else:\n            axes.plot(y, fmt)\n    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n\nclass Timer:\n    \"\"\"记录多次运行时间\"\"\"\n    def __init__(self):\n        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n        self.times = []\n        self.start()\n\n    def start(self):\n        \"\"\"启动计时器\"\"\"\n        self.tik = time.time()\n\n    def stop(self):\n        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n        self.times.append(time.time() - self.tik)\n        return self.times[-1]\n\n    def avg(self):\n        \"\"\"返回平均时间\"\"\"\n        return sum(self.times) / len(self.times)\n\n    def sum(self):\n        \"\"\"返回时间总和\"\"\"\n        return sum(self.times)\n\n    def cumsum(self):\n        \"\"\"返回累计时间\"\"\"\n        return np.array(self.times).cumsum().tolist()\n\ndef synthetic_data(w, b, num_examples):\n    \"\"\"生成y=Xw+b+噪声\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    X = d2l.normal(0, 1, (num_examples, len(w)))\n    y = d2l.matmul(X, w) + b\n    y += d2l.normal(0, 0.01, y.shape)\n    return X, d2l.reshape(y, (-1, 1))\n\ndef linreg(X, w, b):\n    \"\"\"线性回归模型\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    return d2l.matmul(X, w) + b\n\ndef squared_loss(y_hat, y):\n    \"\"\"均方损失\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    return (y_hat - d2l.reshape(y, y_hat.shape)) ** 2 / 2\n\ndef sgd(params, lr, batch_size):\n    \"\"\"小批量随机梯度下降\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    for param in params:\n        param[:] = param - lr * param.grad / batch_size\n\ndef load_array(data_arrays, batch_size, is_train=True):\n    \"\"\"构造一个Gluon数据迭代器\n\n    Defined in :numref:`sec_linear_concise`\"\"\"\n    dataset = gluon.data.ArrayDataset(*data_arrays)\n    return gluon.data.DataLoader(dataset, batch_size, shuffle=is_train)\n\ndef get_fashion_mnist_labels(labels):\n    \"\"\"返回Fashion-MNIST数据集的文本标签\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n\ndef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n    \"\"\"绘制图像列表\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten()\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        ax.imshow(d2l.numpy(img))\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n\ndef get_dataloader_workers():\n    \"\"\"在非Windows的平台上，使用4个进程来读取数据\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    return 0 if sys.platform.startswith('win') else 4\n\ndef load_data_fashion_mnist(batch_size, resize=None):\n    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    dataset = gluon.data.vision\n    trans = [dataset.transforms.ToTensor()]\n    if resize:\n        trans.insert(0, dataset.transforms.Resize(resize))\n    trans = dataset.transforms.Compose(trans)\n    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans)\n    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans)\n    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n                                  num_workers=get_dataloader_workers()),\n            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n                                  num_workers=get_dataloader_workers()))\n\ndef accuracy(y_hat, y):\n    \"\"\"计算预测正确的数量\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n        y_hat = d2l.argmax(y_hat, axis=1)\n    cmp = d2l.astype(y_hat, y.dtype) == y\n    return float(d2l.reduce_sum(d2l.astype(cmp, y.dtype)))\n\ndef evaluate_accuracy(net, data_iter):\n    \"\"\"计算在指定数据集上模型的精度\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    metric = Accumulator(2)  # 正确预测数、预测总数\n    for X, y in data_iter:\n        metric.add(accuracy(net(X), y), d2l.size(y))\n    return metric[0] / metric[1]\n\nclass Accumulator:\n    \"\"\"在n个变量上累加\"\"\"\n    def __init__(self, n):\n        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n        self.data = [0.0] * n\n\n    def add(self, *args):\n        self.data = [a + float(b) for a, b in zip(self.data, args)]\n\n    def reset(self):\n        self.data = [0.0] * len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\ndef train_epoch_ch3(net, train_iter, loss, updater):\n    \"\"\"训练模型一个迭代周期（定义见第3章）\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    # 训练损失总和、训练准确度总和、样本数\n    metric = Accumulator(3)\n    if isinstance(updater, gluon.Trainer):\n        updater = updater.step\n    for X, y in train_iter:\n        # 计算梯度并更新参数\n        with autograd.record():\n            y_hat = net(X)\n            l = loss(y_hat, y)\n        l.backward()\n        updater(X.shape[0])\n        metric.add(float(l.sum()), accuracy(y_hat, y), y.size)\n    # 返回训练损失和训练精度\n    return metric[0] / metric[2], metric[1] / metric[2]\n\nclass Animator:\n    \"\"\"在动画中绘制数据\"\"\"\n    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n                 figsize=(3.5, 2.5)):\n        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n        # 增量地绘制多条线\n        if legend is None:\n            legend = []\n        d2l.use_svg_display()\n        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n        if nrows * ncols == 1:\n            self.axes = [self.axes, ]\n        # 使用lambda函数捕获参数\n        self.config_axes = lambda: d2l.set_axes(\n            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n        self.X, self.Y, self.fmts = None, None, fmts\n\n    def add(self, x, y):\n        # 向图表中添加多个数据点\n        if not hasattr(y, \"__len__\"):\n            y = [y]\n        n = len(y)\n        if not hasattr(x, \"__len__\"):\n            x = [x] * n\n        if not self.X:\n            self.X = [[] for _ in range(n)]\n        if not self.Y:\n            self.Y = [[] for _ in range(n)]\n        for i, (a, b) in enumerate(zip(x, y)):\n            if a is not None and b is not None:\n                self.X[i].append(a)\n                self.Y[i].append(b)\n        self.axes[0].cla()\n        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n            self.axes[0].plot(x, y, fmt)\n        self.config_axes()\n        display.display(self.fig)\n        display.clear_output(wait=True)\n\ndef train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n    \"\"\"训练模型（定义见第3章）\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n                        legend=['train loss', 'train acc', 'test acc'])\n    for epoch in range(num_epochs):\n        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n        test_acc = evaluate_accuracy(net, test_iter)\n        animator.add(epoch + 1, train_metrics + (test_acc,))\n    train_loss, train_acc = train_metrics\n    assert train_loss < 0.5, train_loss\n    assert train_acc <= 1 and train_acc > 0.7, train_acc\n    assert test_acc <= 1 and test_acc > 0.7, test_acc\n\ndef predict_ch3(net, test_iter, n=6):\n    \"\"\"预测标签（定义见第3章）\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    for X, y in test_iter:\n        break\n    trues = d2l.get_fashion_mnist_labels(y)\n    preds = d2l.get_fashion_mnist_labels(d2l.argmax(net(X), axis=1))\n    titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n    d2l.show_images(\n        d2l.reshape(X[0:n], (n, 28, 28)), 1, n, titles=titles[0:n])\n\ndef evaluate_loss(net, data_iter, loss):\n    \"\"\"评估给定数据集上模型的损失\n\n    Defined in :numref:`sec_model_selection`\"\"\"\n    metric = d2l.Accumulator(2)  # 损失的总和,样本数量\n    for X, y in data_iter:\n        l = loss(net(X), y)\n        metric.add(d2l.reduce_sum(l), d2l.size(l))\n    return metric[0] / metric[1]\n\nDATA_HUB = dict()\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n\ndef download(name, cache_dir=os.path.join('..', 'data')):\n    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\n\n    Defined in :numref:`sec_kaggle_house`\"\"\"\n    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n    url, sha1_hash = DATA_HUB[name]\n    os.makedirs(cache_dir, exist_ok=True)\n    fname = os.path.join(cache_dir, url.split('/')[-1])\n    if os.path.exists(fname):\n        sha1 = hashlib.sha1()\n        with open(fname, 'rb') as f:\n            while True:\n                data = f.read(1048576)\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() == sha1_hash:\n            return fname  # 命中缓存\n    print(f'正在从{url}下载{fname}...')\n    r = requests.get(url, stream=True, verify=True)\n    with open(fname, 'wb') as f:\n        f.write(r.content)\n    return fname\n\ndef download_extract(name, folder=None):\n    \"\"\"下载并解压zip/tar文件\n\n    Defined in :numref:`sec_kaggle_house`\"\"\"\n    fname = download(name)\n    base_dir = os.path.dirname(fname)\n    data_dir, ext = os.path.splitext(fname)\n    if ext == '.zip':\n        fp = zipfile.ZipFile(fname, 'r')\n    elif ext in ('.tar', '.gz'):\n        fp = tarfile.open(fname, 'r')\n    else:\n        assert False, '只有zip/tar文件可以被解压缩'\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n\ndef download_all():\n    \"\"\"下载DATA_HUB中的所有文件\n\n    Defined in :numref:`sec_kaggle_house`\"\"\"\n    for name in DATA_HUB:\n        download(name)\n\nDATA_HUB['kaggle_house_train'] = (\n    DATA_URL + 'kaggle_house_pred_train.csv',\n    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n\nDATA_HUB['kaggle_house_test'] = (\n    DATA_URL + 'kaggle_house_pred_test.csv',\n    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n\ndef try_gpu(i=0):\n    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\n\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    return npx.gpu(i) if npx.num_gpus() >= i + 1 else npx.cpu()\n\ndef try_all_gpus():\n    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu()]\n\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    devices = [npx.gpu(i) for i in range(npx.num_gpus())]\n    return devices if devices else [npx.cpu()]\n\ndef corr2d(X, K):\n    \"\"\"计算二维互相关运算\n\n    Defined in :numref:`sec_conv_layer`\"\"\"\n    h, w = K.shape\n    Y = d2l.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = d2l.reduce_sum((X[i: i + h, j: j + w] * K))\n    return Y\n\ndef evaluate_accuracy_gpu(net, data_iter, device=None):\n    \"\"\"使用GPU计算模型在数据集上的精度\n\n    Defined in :numref:`sec_lenet`\"\"\"\n    if not device:  # 查询第一个参数所在的第一个设备\n        device = list(net.collect_params().values())[0].list_ctx()[0]\n    metric = d2l.Accumulator(2)  # 正确预测的数量，总预测的数量\n    for X, y in data_iter:\n        X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n        metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n    return metric[0] / metric[1]\n\ndef train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n    \"\"\"用GPU训练模型(在第六章定义)\n\n    Defined in :numref:`sec_lenet`\"\"\"\n    net.initialize(force_reinit=True, ctx=device, init=init.Xavier())\n    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n    trainer = gluon.Trainer(net.collect_params(),\n                            'sgd', {'learning_rate': lr})\n    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n                            legend=['train loss', 'train acc', 'test acc'])\n    timer, num_batches = d2l.Timer(), len(train_iter)\n    for epoch in range(num_epochs):\n        metric = d2l.Accumulator(3)  # 训练损失之和，训练准确率之和，样本数\n        for i, (X, y) in enumerate(train_iter):\n            timer.start()\n            # 下面是与“d2l.train_epoch_ch3”的主要不同\n            X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n            with autograd.record():\n                y_hat = net(X)\n                l = loss(y_hat, y)\n            l.backward()\n            trainer.step(X.shape[0])\n            metric.add(l.sum(), d2l.accuracy(y_hat, y), X.shape[0])\n            timer.stop()\n            train_l = metric[0] / metric[2]\n            train_acc = metric[1] / metric[2]\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (train_l, train_acc, None))\n        test_acc = evaluate_accuracy_gpu(net, test_iter)\n        animator.add(epoch + 1, (None, None, test_acc))\n    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n          f'test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n          f'on {str(device)}')\n\nclass Residual(nn.Block):\n    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n        super().__init__(**kwargs)\n        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1,\n                               strides=strides)\n        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.Conv2D(num_channels, kernel_size=1,\n                                   strides=strides)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm()\n        self.bn2 = nn.BatchNorm()\n\n    def forward(self, X):\n        Y = npx.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        if self.conv3:\n            X = self.conv3(X)\n        return npx.relu(Y + X)\n\nd2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n\ndef read_time_machine():\n    \"\"\"将时间机器数据集加载到文本行的列表中\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    with open(d2l.download('time_machine'), 'r') as f:\n        lines = f.readlines()\n    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n\ndef tokenize(lines, token='word'):\n    \"\"\"将文本行拆分为单词或字符词元\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    if token == 'word':\n        return [line.split() for line in lines]\n    elif token == 'char':\n        return [list(line) for line in lines]\n    else:\n        print('错误：未知词元类型：' + token)\n\nclass Vocab:\n    \"\"\"文本词表\"\"\"\n    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n        \"\"\"Defined in :numref:`sec_text_preprocessing`\"\"\"\n        if tokens is None:\n            tokens = []\n        if reserved_tokens is None:\n            reserved_tokens = []\n        # 按出现频率排序\n        counter = count_corpus(tokens)\n        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                   reverse=True)\n        # 未知词元的索引为0\n        self.idx_to_token = ['<unk>'] + reserved_tokens\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n        for token, freq in self._token_freqs:\n            if freq < min_freq:\n                break\n            if token not in self.token_to_idx:\n                self.idx_to_token.append(token)\n                self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\n    @property\n    def unk(self):  # 未知词元的索引为0\n        return 0\n\n    @property\n    def token_freqs(self):\n        return self._token_freqs\n\ndef count_corpus(tokens):\n    \"\"\"统计词元的频率\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    # 这里的tokens是1D列表或2D列表\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        # 将词元列表展平成一个列表\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)\n\ndef load_corpus_time_machine(max_tokens=-1):\n    \"\"\"返回时光机器数据集的词元索引列表和词表\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    lines = read_time_machine()\n    tokens = tokenize(lines, 'char')\n    vocab = Vocab(tokens)\n    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n    # 所以将所有文本行展平到一个列表中\n    corpus = [vocab[token] for line in tokens for token in line]\n    if max_tokens > 0:\n        corpus = corpus[:max_tokens]\n    return corpus, vocab\n\ndef seq_data_iter_random(corpus, batch_size, num_steps):\n    \"\"\"使用随机抽样生成一个小批量子序列\n\n    Defined in :numref:`sec_language_model`\"\"\"\n    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n    corpus = corpus[random.randint(0, num_steps - 1):]\n    # 减去1，是因为我们需要考虑标签\n    num_subseqs = (len(corpus) - 1) // num_steps\n    # 长度为num_steps的子序列的起始索引\n    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n    # 在随机抽样的迭代过程中，\n    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n    random.shuffle(initial_indices)\n\n    def data(pos):\n        # 返回从pos位置开始的长度为num_steps的序列\n        return corpus[pos: pos + num_steps]\n\n    num_batches = num_subseqs // batch_size\n    for i in range(0, batch_size * num_batches, batch_size):\n        # 在这里，initial_indices包含子序列的随机起始索引\n        initial_indices_per_batch = initial_indices[i: i + batch_size]\n        X = [data(j) for j in initial_indices_per_batch]\n        Y = [data(j + 1) for j in initial_indices_per_batch]\n        yield d2l.tensor(X), d2l.tensor(Y)\n\ndef seq_data_iter_sequential(corpus, batch_size, num_steps):\n    \"\"\"使用顺序分区生成一个小批量子序列\n\n    Defined in :numref:`sec_language_model`\"\"\"\n    # 从随机偏移量开始划分序列\n    offset = random.randint(0, num_steps)\n    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n    Xs = d2l.tensor(corpus[offset: offset + num_tokens])\n    Ys = d2l.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n    num_batches = Xs.shape[1] // num_steps\n    for i in range(0, num_steps * num_batches, num_steps):\n        X = Xs[:, i: i + num_steps]\n        Y = Ys[:, i: i + num_steps]\n        yield X, Y\n\nclass SeqDataLoader:\n    \"\"\"加载序列数据的迭代器\"\"\"\n    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n        \"\"\"Defined in :numref:`sec_language_model`\"\"\"\n        if use_random_iter:\n            self.data_iter_fn = d2l.seq_data_iter_random\n        else:\n            self.data_iter_fn = d2l.seq_data_iter_sequential\n        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\n        self.batch_size, self.num_steps = batch_size, num_steps\n\n    def __iter__(self):\n        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n\ndef load_data_time_machine(batch_size, num_steps,\n                           use_random_iter=False, max_tokens=10000):\n    \"\"\"返回时光机器数据集的迭代器和词表\n\n    Defined in :numref:`sec_language_model`\"\"\"\n    data_iter = SeqDataLoader(\n        batch_size, num_steps, use_random_iter, max_tokens)\n    return data_iter, data_iter.vocab\n\nclass RNNModelScratch:\n    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n    def __init__(self, vocab_size, num_hiddens, device, get_params,\n                 init_state, forward_fn):\n        \"\"\"Defined in :numref:`sec_rnn_scratch`\"\"\"\n        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n        self.params = get_params(vocab_size, num_hiddens, device)\n        self.init_state, self.forward_fn = init_state, forward_fn\n\n    def __call__(self, X, state):\n        X = npx.one_hot(X.T, self.vocab_size)\n        return self.forward_fn(X, state, self.params)\n\n    def begin_state(self, batch_size, ctx):\n        return self.init_state(batch_size, self.num_hiddens, ctx)\n\ndef predict_ch8(prefix, num_preds, net, vocab, device):\n    \"\"\"在prefix后面生成新字符\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    state = net.begin_state(batch_size=1, ctx=device)\n    outputs = [vocab[prefix[0]]]\n    get_input = lambda: d2l.reshape(\n        d2l.tensor([outputs[-1]], ctx=device), (1, 1))\n    for y in prefix[1:]:  # 预热期\n        _, state = net(get_input(), state)\n        outputs.append(vocab[y])\n    for _ in range(num_preds):  # 预测num_preds步\n        y, state = net(get_input(), state)\n        outputs.append(int(y.argmax(axis=1).reshape(1)))\n    return ''.join([vocab.idx_to_token[i] for i in outputs])\n\ndef grad_clipping(net, theta):\n    \"\"\"裁剪梯度\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    if isinstance(net, gluon.Block):\n        params = [p.data() for p in net.collect_params().values()]\n    else:\n        params = net.params\n    norm = math.sqrt(sum((p.grad ** 2).sum() for p in params))\n    if norm > theta:\n        for param in params:\n            param.grad[:] *= theta / norm\n\ndef train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n    \"\"\"训练模型一个迭代周期（定义见第8章）\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    state, timer = None, d2l.Timer()\n    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n    for X, Y in train_iter:\n        if state is None or use_random_iter:\n            # 在第一次迭代或使用随机抽样时初始化state\n            state = net.begin_state(batch_size=X.shape[0], ctx=device)\n        else:\n            for s in state:\n                s.detach()\n        y = Y.T.reshape(-1)\n        X, y = X.as_in_ctx(device), y.as_in_ctx(device)\n        with autograd.record():\n            y_hat, state = net(X, state)\n            l = loss(y_hat, y).mean()\n        l.backward()\n        grad_clipping(net, 1)\n        updater(batch_size=1)  # 因为已经调用了mean函数\n        metric.add(l * d2l.size(y), d2l.size(y))\n    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n\ndef train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n              use_random_iter=False):\n    \"\"\"训练模型（定义见第8章）\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n                            legend=['train'], xlim=[10, num_epochs])\n    # 初始化\n    if isinstance(net, gluon.Block):\n        net.initialize(ctx=device, force_reinit=True,\n                         init=init.Normal(0.01))\n        trainer = gluon.Trainer(net.collect_params(),\n                                'sgd', {'learning_rate': lr})\n        updater = lambda batch_size: trainer.step(batch_size)\n    else:\n        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n    # 训练和预测\n    for epoch in range(num_epochs):\n        ppl, speed = train_epoch_ch8(\n            net, train_iter, loss, updater, device, use_random_iter)\n        if (epoch + 1) % 10 == 0:\n            animator.add(epoch + 1, [ppl])\n    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n    print(predict('time traveller'))\n    print(predict('traveller'))\n\nclass RNNModel(nn.Block):\n    \"\"\"循环神经网络模型\n\n    Defined in :numref:`sec_rnn-concise`\"\"\"\n    def __init__(self, rnn_layer, vocab_size, **kwargs):\n        super(RNNModel, self).__init__(**kwargs)\n        self.rnn = rnn_layer\n        self.vocab_size = vocab_size\n        self.dense = nn.Dense(vocab_size)\n\n    def forward(self, inputs, state):\n        X = npx.one_hot(inputs.T, self.vocab_size)\n        Y, state = self.rnn(X, state)\n        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n        # 它的输出形状是(时间步数*批量大小,词表大小)\n        output = self.dense(Y.reshape(-1, Y.shape[-1]))\n        return output, state\n\n    def begin_state(self, *args, **kwargs):\n        return self.rnn.begin_state(*args, **kwargs)\n\nd2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n\ndef read_data_nmt():\n    \"\"\"载入“英语－法语”数据集\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    data_dir = d2l.download_extract('fra-eng')\n    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n             encoding='utf-8') as f:\n        return f.read()\n\ndef preprocess_nmt(text):\n    \"\"\"预处理“英语－法语”数据集\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    def no_space(char, prev_char):\n        return char in set(',.!?') and prev_char != ' '\n\n    # 使用空格替换不间断空格\n    # 使用小写字母替换大写字母\n    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n    # 在单词和标点符号之间插入空格\n    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n           for i, char in enumerate(text)]\n    return ''.join(out)\n\ndef tokenize_nmt(text, num_examples=None):\n    \"\"\"词元化“英语－法语”数据数据集\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    source, target = [], []\n    for i, line in enumerate(text.split('\\n')):\n        if num_examples and i > num_examples:\n            break\n        parts = line.split('\\t')\n        if len(parts) == 2:\n            source.append(parts[0].split(' '))\n            target.append(parts[1].split(' '))\n    return source, target\n\ndef show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n    \"\"\"绘制列表长度对的直方图\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    d2l.set_figsize()\n    _, _, patches = d2l.plt.hist(\n        [[len(l) for l in xlist], [len(l) for l in ylist]])\n    d2l.plt.xlabel(xlabel)\n    d2l.plt.ylabel(ylabel)\n    for patch in patches[1].patches:\n        patch.set_hatch('/')\n    d2l.plt.legend(legend)\n\ndef truncate_pad(line, num_steps, padding_token):\n    \"\"\"截断或填充文本序列\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    if len(line) > num_steps:\n        return line[:num_steps]  # 截断\n    return line + [padding_token] * (num_steps - len(line))  # 填充\n\ndef build_array_nmt(lines, vocab, num_steps):\n    \"\"\"将机器翻译的文本序列转换成小批量\n\n    Defined in :numref:`subsec_mt_data_loading`\"\"\"\n    lines = [vocab[l] for l in lines]\n    lines = [l + [vocab['<eos>']] for l in lines]\n    array = d2l.tensor([truncate_pad(\n        l, num_steps, vocab['<pad>']) for l in lines])\n    valid_len = d2l.reduce_sum(\n        d2l.astype(array != vocab['<pad>'], d2l.int32), 1)\n    return array, valid_len\n\ndef load_data_nmt(batch_size, num_steps, num_examples=600):\n    \"\"\"返回翻译数据集的迭代器和词表\n\n    Defined in :numref:`subsec_mt_data_loading`\"\"\"\n    text = preprocess_nmt(read_data_nmt())\n    source, target = tokenize_nmt(text, num_examples)\n    src_vocab = d2l.Vocab(source, min_freq=2,\n                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n    tgt_vocab = d2l.Vocab(target, min_freq=2,\n                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n    data_iter = d2l.load_array(data_arrays, batch_size)\n    return data_iter, src_vocab, tgt_vocab\n\nclass Encoder(nn.Block):\n    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n    def __init__(self, **kwargs):\n        super(Encoder, self).__init__(**kwargs)\n\n    def forward(self, X, *args):\n        raise NotImplementedError\n\nclass Decoder(nn.Block):\n    \"\"\"编码器-解码器架构的基本解码器接口\n\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n    def __init__(self, **kwargs):\n        super(Decoder, self).__init__(**kwargs)\n\n    def init_state(self, enc_outputs, *args):\n        raise NotImplementedError\n\n    def forward(self, X, state):\n        raise NotImplementedError\n\nclass EncoderDecoder(nn.Block):\n    \"\"\"编码器-解码器架构的基类\n\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n    def __init__(self, encoder, decoder, **kwargs):\n        super(EncoderDecoder, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, enc_X, dec_X, *args):\n        enc_outputs = self.encoder(enc_X, *args)\n        dec_state = self.decoder.init_state(enc_outputs, *args)\n        return self.decoder(dec_X, dec_state)\n\nclass Seq2SeqEncoder(d2l.Encoder):\n    \"\"\"用于序列到序列学习的循环神经网络编码器\n\n    Defined in :numref:`sec_seq2seq`\"\"\"\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqEncoder, self).__init__(**kwargs)\n        # 嵌入层\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = rnn.GRU(num_hiddens, num_layers, dropout=dropout)\n\n    def forward(self, X, *args):\n        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n        X = self.embedding(X)\n        # 在循环神经网络模型中，第一个轴对应于时间步\n        X = X.swapaxes(0, 1)\n        state = self.rnn.begin_state(batch_size=X.shape[1], ctx=X.ctx)\n        output, state = self.rnn(X, state)\n        # output的形状:(num_steps,batch_size,num_hiddens)\n        # state的形状:(num_layers,batch_size,num_hiddens)\n        return output, state\n\nclass MaskedSoftmaxCELoss(gluon.loss.SoftmaxCELoss):\n    \"\"\"带遮蔽的softmax交叉熵损失函数\n\n    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n    # pred的形状：(batch_size,num_steps,vocab_size)\n    # label的形状：(batch_size,num_steps)\n    # valid_len的形状：(batch_size,)\n    def forward(self, pred, label, valid_len):\n        # weights的形状：(batch_size,num_steps,1)\n        weights = np.expand_dims(np.ones_like(label), axis=-1)\n        weights = npx.sequence_mask(weights, valid_len, True, axis=1)\n        return super(MaskedSoftmaxCELoss, self).forward(pred, label, weights)\n\ndef train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n    \"\"\"训练序列到序列模型\n\n    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n    net.initialize(init.Xavier(), force_reinit=True, ctx=device)\n    trainer = gluon.Trainer(net.collect_params(), 'adam',\n                            {'learning_rate': lr})\n    loss = MaskedSoftmaxCELoss()\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n                            xlim=[10, num_epochs])\n    for epoch in range(num_epochs):\n        timer = d2l.Timer()\n        metric = d2l.Accumulator(2)  # 训练损失求和，词元数量\n        for batch in data_iter:\n            X, X_valid_len, Y, Y_valid_len = [\n                x.as_in_ctx(device) for x in batch]\n            bos = np.array([tgt_vocab['<bos>']] * Y.shape[0],\n                       ctx=device).reshape(-1, 1)\n            dec_input = np.concatenate([bos, Y[:, :-1]], 1)  # 强制教学\n            with autograd.record():\n                Y_hat, _ = net(X, dec_input, X_valid_len)\n                l = loss(Y_hat, Y, Y_valid_len)\n            l.backward()\n            d2l.grad_clipping(net, 1)\n            num_tokens = Y_valid_len.sum()\n            trainer.step(num_tokens)\n            metric.add(l.sum(), num_tokens)\n        if (epoch + 1) % 10 == 0:\n            animator.add(epoch + 1, (metric[0] / metric[1],))\n    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n        f'tokens/sec on {str(device)}')\n\ndef predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n                    device, save_attention_weights=False):\n    \"\"\"序列到序列模型的预测\n\n    Defined in :numref:`sec_seq2seq_training`\"\"\"\n    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n        src_vocab['<eos>']]\n    enc_valid_len = np.array([len(src_tokens)], ctx=device)\n    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n    # 添加批量轴\n    enc_X = np.expand_dims(np.array(src_tokens, ctx=device), axis=0)\n    enc_outputs = net.encoder(enc_X, enc_valid_len)\n    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n    # 添加批量轴\n    dec_X = np.expand_dims(np.array([tgt_vocab['<bos>']], ctx=device),\n                           axis=0)\n    output_seq, attention_weight_seq = [], []\n    for _ in range(num_steps):\n        Y, dec_state = net.decoder(dec_X, dec_state)\n        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n        dec_X = Y.argmax(axis=2)\n        pred = dec_X.squeeze(axis=0).astype('int32').item()\n        # 保存注意力权重（稍后讨论）\n        if save_attention_weights:\n            attention_weight_seq.append(net.decoder.attention_weights)\n        # 一旦序列结束词元被预测，输出序列的生成就完成了\n        if pred == tgt_vocab['<eos>']:\n            break\n        output_seq.append(pred)\n    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n\ndef bleu(pred_seq, label_seq, k):\n    \"\"\"计算BLEU\n\n    Defined in :numref:`sec_seq2seq_training`\"\"\"\n    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n    len_pred, len_label = len(pred_tokens), len(label_tokens)\n    score = math.exp(min(0, 1 - len_label / len_pred))\n    for n in range(1, k + 1):\n        num_matches, label_subs = 0, collections.defaultdict(int)\n        for i in range(len_label - n + 1):\n            label_subs[' '.join(label_tokens[i: i + n])] += 1\n        for i in range(len_pred - n + 1):\n            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n                num_matches += 1\n                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n    return score\n\ndef show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n                  cmap='Reds'):\n    \"\"\"显示矩阵热图\n\n    Defined in :numref:`sec_attention-cues`\"\"\"\n    d2l.use_svg_display()\n    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize,\n                                 sharex=True, sharey=True, squeeze=False)\n    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n            pcm = ax.imshow(d2l.numpy(matrix), cmap=cmap)\n            if i == num_rows - 1:\n                ax.set_xlabel(xlabel)\n            if j == 0:\n                ax.set_ylabel(ylabel)\n            if titles:\n                ax.set_title(titles[j])\n    fig.colorbar(pcm, ax=axes, shrink=0.6);\n\ndef masked_softmax(X, valid_lens):\n    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\n\n    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n    # X:3D张量，valid_lens:1D或2D张量\n    if valid_lens is None:\n        return npx.softmax(X)\n    else:\n        shape = X.shape\n        if valid_lens.ndim == 1:\n            valid_lens = valid_lens.repeat(shape[1])\n        else:\n            valid_lens = valid_lens.reshape(-1)\n        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n        X = npx.sequence_mask(X.reshape(-1, shape[-1]), valid_lens, True,\n                              value=-1e6, axis=1)\n        return npx.softmax(X).reshape(shape)\n\nclass AdditiveAttention(nn.Block):\n    \"\"\"加性注意力\n\n    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n    def __init__(self, num_hiddens, dropout, **kwargs):\n        super(AdditiveAttention, self).__init__(**kwargs)\n        # 使用'flatten=False'只转换最后一个轴，以便其他轴的形状保持不变\n        self.W_k = nn.Dense(num_hiddens, use_bias=False, flatten=False)\n        self.W_q = nn.Dense(num_hiddens, use_bias=False, flatten=False)\n        self.w_v = nn.Dense(1, use_bias=False, flatten=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, queries, keys, values, valid_lens):\n        queries, keys = self.W_q(queries), self.W_k(keys)\n        # 在维度扩展后，\n        # queries的形状：(batch_size，查询的个数，1，num_hidden)\n        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)\n        # 使用广播的方式进行求和\n        features = np.expand_dims(queries, axis=2) + np.expand_dims(\n            keys, axis=1)\n        features = np.tanh(features)\n        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n        scores = np.squeeze(self.w_v(features), axis=-1)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        # values的形状：(batch_size，“键－值”对的个数，值的维度)\n        return npx.batch_dot(self.dropout(self.attention_weights), values)\n\nclass DotProductAttention(nn.Block):\n    \"\"\"缩放点积注意力\n\n    Defined in :numref:`subsec_additive-attention`\"\"\"\n    def __init__(self, dropout, **kwargs):\n        super(DotProductAttention, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n\n    # queries的形状：(batch_size，查询的个数，d)\n    # keys的形状：(batch_size，“键－值”对的个数，d)\n    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n    def forward(self, queries, keys, values, valid_lens=None):\n        d = queries.shape[-1]\n        # 设置transpose_b=True为了交换keys的最后两个维度\n        scores = npx.batch_dot(queries, keys, transpose_b=True) / math.sqrt(d)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        return npx.batch_dot(self.dropout(self.attention_weights), values)\n\nclass AttentionDecoder(d2l.Decoder):\n    \"\"\"带有注意力机制解码器的基本接口\n\n    Defined in :numref:`sec_seq2seq_attention`\"\"\"\n    def __init__(self, **kwargs):\n        super(AttentionDecoder, self).__init__(**kwargs)\n\n    @property\n    def attention_weights(self):\n        raise NotImplementedError\n\nclass MultiHeadAttention(nn.Block):\n    \"\"\"多头注意力\n\n    Defined in :numref:`sec_multihead-attention`\"\"\"\n    def __init__(self, num_hiddens, num_heads, dropout, use_bias=False,\n                 **kwargs):\n        super(MultiHeadAttention, self).__init__(**kwargs)\n        self.num_heads = num_heads\n        self.attention = d2l.DotProductAttention(dropout)\n        self.W_q = nn.Dense(num_hiddens, use_bias=use_bias, flatten=False)\n        self.W_k = nn.Dense(num_hiddens, use_bias=use_bias, flatten=False)\n        self.W_v = nn.Dense(num_hiddens, use_bias=use_bias, flatten=False)\n        self.W_o = nn.Dense(num_hiddens, use_bias=use_bias, flatten=False)\n\n    def forward(self, queries, keys, values, valid_lens):\n        # queries，keys，values的形状:\n        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n        # valid_lens　的形状:\n        # (batch_size，)或(batch_size，查询的个数)\n        # 经过变换后，输出的queries，keys，values　的形状:\n        # (batch_size*num_heads，查询或者“键－值”对的个数，\n        # num_hiddens/num_heads)\n        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n        values = transpose_qkv(self.W_v(values), self.num_heads)\n\n        if valid_lens is not None:\n            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n            # 然后如此复制第二项，然后诸如此类。\n            valid_lens = valid_lens.repeat(self.num_heads, axis=0)\n\n        # output的形状:(batch_size*num_heads，查询的个数，\n        # num_hiddens/num_heads)\n        output = self.attention(queries, keys, values, valid_lens)\n\n        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n        output_concat = transpose_output(output, self.num_heads)\n        return self.W_o(output_concat)\n\ndef transpose_qkv(X, num_heads):\n    \"\"\"为了多注意力头的并行计算而变换形状\n\n    Defined in :numref:`sec_multihead-attention`\"\"\"\n    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n    # num_hiddens/num_heads)\n    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n\n    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n    # num_hiddens/num_heads)\n    X = X.transpose(0, 2, 1, 3)\n\n    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n    # num_hiddens/num_heads)\n    return X.reshape(-1, X.shape[2], X.shape[3])\n\n\ndef transpose_output(X, num_heads):\n    \"\"\"逆转transpose_qkv函数的操作\n\n    Defined in :numref:`sec_multihead-attention`\"\"\"\n    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n    X = X.transpose(0, 2, 1, 3)\n    return X.reshape(X.shape[0], X.shape[1], -1)\n\nclass PositionalEncoding(nn.Block):\n    \"\"\"位置编码\n\n    Defined in :numref:`sec_self-attention-and-positional-encoding`\"\"\"\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        # 创建一个足够长的P\n        self.P = d2l.zeros((1, max_len, num_hiddens))\n        X = d2l.arange(max_len).reshape(-1, 1) / np.power(\n            10000, np.arange(0, num_hiddens, 2) / num_hiddens)\n        self.P[:, :, 0::2] = np.sin(X)\n        self.P[:, :, 1::2] = np.cos(X)\n\n    def forward(self, X):\n        X = X + self.P[:, :X.shape[1], :].as_in_ctx(X.ctx)\n        return self.dropout(X)\n\nclass PositionWiseFFN(nn.Block):\n    \"\"\"基于位置的前馈网络\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n        super(PositionWiseFFN, self).__init__(**kwargs)\n        self.dense1 = nn.Dense(ffn_num_hiddens, flatten=False,\n                               activation='relu')\n        self.dense2 = nn.Dense(ffn_num_outputs, flatten=False)\n\n    def forward(self, X):\n        return self.dense2(self.dense1(X))\n\nclass AddNorm(nn.Block):\n    \"\"\"残差连接后进行层规范化\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, dropout, **kwargs):\n        super(AddNorm, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm()\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)\n\nclass EncoderBlock(nn.Block):\n    \"\"\"Transformer编码器块\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,\n                 use_bias=False, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n        self.attention = d2l.MultiHeadAttention(\n            num_hiddens, num_heads, dropout, use_bias)\n        self.addnorm1 = AddNorm(dropout)\n        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = AddNorm(dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n        return self.addnorm2(Y, self.ffn(Y))\n\nclass TransformerEncoder(d2l.Encoder):\n    \"\"\"Transformer编码器\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for _ in range(num_layers):\n            self.blks.add(\n                EncoderBlock(num_hiddens, ffn_num_hiddens, num_heads, dropout,\n                             use_bias))\n\n    def forward(self, X, valid_lens, *args):\n        # 因为位置编码值在-1和1之间，\n        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n        # 然后再与位置编码相加。\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens)\n            self.attention_weights[\n                i] = blk.attention.attention.attention_weights\n        return X\n\ndef annotate(text, xy, xytext):\n    d2l.plt.gca().annotate(text, xy=xy, xytext=xytext,\n                           arrowprops=dict(arrowstyle='->'))\n\ndef train_2d(trainer, steps=20, f_grad=None):\n    \"\"\"用定制的训练机优化2D目标函数\n\n    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n    # s1和s2是稍后将使用的内部状态变量\n    x1, x2, s1, s2 = -5, -2, 0, 0\n    results = [(x1, x2)]\n    for i in range(steps):\n        if f_grad:\n            x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)\n        else:\n            x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n        results.append((x1, x2))\n    print(f'epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n    return results\n\ndef show_trace_2d(f, results):\n    \"\"\"显示优化过程中2D变量的轨迹\n\n    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n    d2l.set_figsize()\n    d2l.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n    x1, x2 = d2l.meshgrid(d2l.arange(-5.5, 1.0, 0.1),\n                          d2l.arange(-3.0, 1.0, 0.1))\n    d2l.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n    d2l.plt.xlabel('x1')\n    d2l.plt.ylabel('x2')\n\nd2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat',\n                           '76e5be1548fd8222e5074cf0faae75edff8cf93f')\n\ndef get_data_ch11(batch_size=10, n=1500):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    data = np.genfromtxt(d2l.download('airfoil'),\n                         dtype=np.float32, delimiter='\\t')\n    data = (data - data.mean(axis=0)) / data.std(axis=0)\n    data_iter = d2l.load_array(\n        (data[:n, :-1], data[:n, -1]), batch_size, is_train=True)\n    return data_iter, data.shape[1]-1\n\ndef train_ch11(trainer_fn, states, hyperparams, data_iter,\n               feature_dim, num_epochs=2):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    # 初始化模型\n    w = np.random.normal(scale=0.01, size=(feature_dim, 1))\n    b = np.zeros(1)\n    w.attach_grad()\n    b.attach_grad()\n    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n    # 训练模型\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n    n, timer = 0, d2l.Timer()\n    for _ in range(num_epochs):\n        for X, y in data_iter:\n            with autograd.record():\n                l = loss(net(X), y).mean()\n            l.backward()\n            trainer_fn([w, b], states, hyperparams)\n            n += X.shape[0]\n            if n % 200 == 0:\n                timer.stop()\n                animator.add(n/X.shape[0]/len(data_iter),\n                             (d2l.evaluate_loss(net, data_iter, loss),))\n                timer.start()\n    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')\n    return timer.cumsum(), animator.Y[0]\n\ndef train_concise_ch11(tr_name, hyperparams, data_iter, num_epochs=2):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    # 初始化模型\n    net = nn.Sequential()\n    net.add(nn.Dense(1))\n    net.initialize(init.Normal(sigma=0.01))\n    trainer = gluon.Trainer(net.collect_params(), tr_name, hyperparams)\n    loss = gluon.loss.L2Loss()\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n    n, timer = 0, d2l.Timer()\n    for _ in range(num_epochs):\n        for X, y in data_iter:\n            with autograd.record():\n                l = loss(net(X), y)\n            l.backward()\n            trainer.step(X.shape[0])\n            n += X.shape[0]\n            if n % 200 == 0:\n                timer.stop()\n                animator.add(n/X.shape[0]/len(data_iter),\n                             (d2l.evaluate_loss(net, data_iter, loss),))\n                timer.start()\n    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')\n\nclass Benchmark:\n    \"\"\"用于测量运行时间\"\"\"\n    def __init__(self, description='Done'):\n        \"\"\"Defined in :numref:`sec_hybridize`\"\"\"\n        self.description = description\n\n    def __enter__(self):\n        self.timer = d2l.Timer()\n        return self\n\n    def __exit__(self, *args):\n        print(f'{self.description}: {self.timer.stop():.4f} sec')\n\ndef split_batch(X, y, devices):\n    \"\"\"将X和y拆分到多个设备上\n\n    Defined in :numref:`sec_multi_gpu`\"\"\"\n    assert X.shape[0] == y.shape[0]\n    return (gluon.utils.split_and_load(X, devices),\n            gluon.utils.split_and_load(y, devices))\n\ndef resnet18(num_classes):\n    \"\"\"稍加修改的ResNet-18模型\n\n    Defined in :numref:`sec_multi_gpu_concise`\"\"\"\n    def resnet_block(num_channels, num_residuals, first_block=False):\n        blk = nn.Sequential()\n        for i in range(num_residuals):\n            if i == 0 and not first_block:\n                blk.add(d2l.Residual(\n                    num_channels, use_1x1conv=True, strides=2))\n            else:\n                blk.add(d2l.Residual(num_channels))\n        return blk\n\n    net = nn.Sequential()\n    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n    net.add(nn.Conv2D(64, kernel_size=3, strides=1, padding=1),\n            nn.BatchNorm(), nn.Activation('relu'))\n    net.add(resnet_block(64, 2, first_block=True),\n            resnet_block(128, 2),\n            resnet_block(256, 2),\n            resnet_block(512, 2))\n    net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))\n    return net\n\ndef evaluate_accuracy_gpus(net, data_iter, split_f=d2l.split_batch):\n    \"\"\"使用多个GPU计算数据集上模型的精度\n\n    Defined in :numref:`sec_multi_gpu_concise`\"\"\"\n    # 查询设备列表\n    devices = list(net.collect_params().values())[0].list_ctx()\n    # 正确预测的数量，预测的总数量\n    metric = d2l.Accumulator(2)\n    for features, labels in data_iter:\n        X_shards, y_shards = split_f(features, labels, devices)\n        # 并行运行\n        pred_shards = [net(X_shard) for X_shard in X_shards]\n        metric.add(sum(float(d2l.accuracy(pred_shard, y_shard)) for\n                       pred_shard, y_shard in zip(\n                           pred_shards, y_shards)), labels.size)\n    return metric[0] / metric[1]\n\ndef train_batch_ch13(net, features, labels, loss, trainer, devices,\n                     split_f=d2l.split_batch):\n    \"\"\"用多GPU进行小批量训练\n\n    Defined in :numref:`sec_image_augmentation`\"\"\"\n    X_shards, y_shards = split_f(features, labels, devices)\n    with autograd.record():\n        pred_shards = [net(X_shard) for X_shard in X_shards]\n        ls = [loss(pred_shard, y_shard) for pred_shard, y_shard\n              in zip(pred_shards, y_shards)]\n    for l in ls:\n        l.backward()\n    # True标志允许使用过时的梯度，这很有用（例如，在微调BERT中）\n    trainer.step(labels.shape[0], ignore_stale_grad=True)\n    train_loss_sum = sum([float(l.sum()) for l in ls])\n    train_acc_sum = sum(d2l.accuracy(pred_shard, y_shard)\n                        for pred_shard, y_shard in zip(pred_shards, y_shards))\n    return train_loss_sum, train_acc_sum\n\ndef train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n               devices=d2l.try_all_gpus(), split_f=d2l.split_batch):\n    \"\"\"用多GPU进行模型训练\n\n    Defined in :numref:`sec_image_augmentation`\"\"\"\n    timer, num_batches = d2l.Timer(), len(train_iter)\n    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n                            legend=['train loss', 'train acc', 'test acc'])\n    for epoch in range(num_epochs):\n        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n        metric = d2l.Accumulator(4)\n        for i, (features, labels) in enumerate(train_iter):\n            timer.start()\n            l, acc = train_batch_ch13(\n                net, features, labels, loss, trainer, devices, split_f)\n            metric.add(l, acc, labels.shape[0], labels.size)\n            timer.stop()\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (metric[0] / metric[2], metric[1] / metric[3],\n                              None))\n        test_acc = d2l.evaluate_accuracy_gpus(net, test_iter, split_f)\n        animator.add(epoch + 1, (None, None, test_acc))\n    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n          f'{str(devices)}')\n\nd2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip',\n                         'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n\ndef box_corner_to_center(boxes):\n    \"\"\"从（左上，右下）转换到（中间，宽度，高度）\n\n    Defined in :numref:`sec_bbox`\"\"\"\n    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    cx = (x1 + x2) / 2\n    cy = (y1 + y2) / 2\n    w = x2 - x1\n    h = y2 - y1\n    boxes = d2l.stack((cx, cy, w, h), axis=-1)\n    return boxes\n\ndef box_center_to_corner(boxes):\n    \"\"\"从（中间，宽度，高度）转换到（左上，右下）\n\n    Defined in :numref:`sec_bbox`\"\"\"\n    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    x1 = cx - 0.5 * w\n    y1 = cy - 0.5 * h\n    x2 = cx + 0.5 * w\n    y2 = cy + 0.5 * h\n    boxes = d2l.stack((x1, y1, x2, y2), axis=-1)\n    return boxes\n\ndef bbox_to_rect(bbox, color):\n    \"\"\"Defined in :numref:`sec_bbox`\"\"\"\n    # 将边界框(左上x,左上y,右下x,右下y)格式转换成matplotlib格式：\n    # ((左上x,左上y),宽,高)\n    return d2l.plt.Rectangle(\n        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],\n        fill=False, edgecolor=color, linewidth=2)\n\ndef multibox_prior(data, sizes, ratios):\n    \"\"\"生成以每个像素为中心具有不同形状的锚框\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    in_height, in_width = data.shape[-2:]\n    device, num_sizes, num_ratios = data.ctx, len(sizes), len(ratios)\n    boxes_per_pixel = (num_sizes + num_ratios - 1)\n    size_tensor = d2l.tensor(sizes, ctx=device)\n    ratio_tensor = d2l.tensor(ratios, ctx=device)\n\n    # 为了将锚点移动到像素的中心，需要设置偏移量。\n    # 因为一个像素的高为1且宽为1，我们选择偏移我们的中心0.5\n    offset_h, offset_w = 0.5, 0.5\n    steps_h = 1.0 / in_height  # 在y轴上缩放步长\n    steps_w = 1.0 / in_width  # 在x轴上缩放步长\n\n    # 生成锚框的所有中心点\n    center_h = (d2l.arange(in_height, ctx=device) + offset_h) * steps_h\n    center_w = (d2l.arange(in_width, ctx=device) + offset_w) * steps_w\n    shift_x, shift_y = d2l.meshgrid(center_w, center_h)\n    shift_x, shift_y = shift_x.reshape(-1), shift_y.reshape(-1)\n\n    # 生成“boxes_per_pixel”个高和宽，\n    # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax)\n    w = np.concatenate((size_tensor * np.sqrt(ratio_tensor[0]),\n                        sizes[0] * np.sqrt(ratio_tensor[1:]))) \\\n                        * in_height / in_width  # 处理矩形输入\n    h = np.concatenate((size_tensor / np.sqrt(ratio_tensor[0]),\n                        sizes[0] / np.sqrt(ratio_tensor[1:])))\n    # 除以2来获得半高和半宽\n    anchor_manipulations = np.tile(np.stack((-w, -h, w, h)).T,\n                                   (in_height * in_width, 1)) / 2\n\n    # 每个中心点都将有“boxes_per_pixel”个锚框，\n    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n    out_grid = d2l.stack([shift_x, shift_y, shift_x, shift_y],\n                         axis=1).repeat(boxes_per_pixel, axis=0)\n    output = out_grid + anchor_manipulations\n    return np.expand_dims(output, axis=0)\n\ndef show_bboxes(axes, bboxes, labels=None, colors=None):\n    \"\"\"显示所有边界框\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    def _make_list(obj, default_values=None):\n        if obj is None:\n            obj = default_values\n        elif not isinstance(obj, (list, tuple)):\n            obj = [obj]\n        return obj\n\n    labels = _make_list(labels)\n    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n    for i, bbox in enumerate(bboxes):\n        color = colors[i % len(colors)]\n        rect = d2l.bbox_to_rect(d2l.numpy(bbox), color)\n        axes.add_patch(rect)\n        if labels and len(labels) > i:\n            text_color = 'k' if color == 'w' else 'w'\n            axes.text(rect.xy[0], rect.xy[1], labels[i],\n                      va='center', ha='center', fontsize=9, color=text_color,\n                      bbox=dict(facecolor=color, lw=0))\n\ndef box_iou(boxes1, boxes2):\n    \"\"\"计算两个锚框或边界框列表中成对的交并比\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n                              (boxes[:, 3] - boxes[:, 1]))\n    # boxes1,boxes2,areas1,areas2的形状:\n    # boxes1：(boxes1的数量,4),\n    # boxes2：(boxes2的数量,4),\n    # areas1：(boxes1的数量,),\n    # areas2：(boxes2的数量,)\n    areas1 = box_area(boxes1)\n    areas2 = box_area(boxes2)\n\n    # inter_upperlefts,inter_lowerrights,inters的形状:\n    # (boxes1的数量,boxes2的数量,2)\n    inter_upperlefts = np.maximum(boxes1[:, None, :2], boxes2[:, :2])\n    inter_lowerrights = np.minimum(boxes1[:, None, 2:], boxes2[:, 2:])\n    inters = (inter_lowerrights - inter_upperlefts).clip(min=0)\n    # inter_areasandunion_areas的形状:(boxes1的数量,boxes2的数量)\n    inter_areas = inters[:, :, 0] * inters[:, :, 1]\n    union_areas = areas1[:, None] + areas2 - inter_areas\n    return inter_areas / union_areas\n\ndef assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):\n    \"\"\"将最接近的真实边界框分配给锚框\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]\n    # 位于第i行和第j列的元素x_ij是锚框i和真实边界框j的IoU\n    jaccard = box_iou(anchors, ground_truth)\n    # 对于每个锚框，分配的真实边界框的张量\n    anchors_bbox_map = np.full((num_anchors,), -1, dtype=np.int32, ctx=device)\n    # 根据阈值，决定是否分配真实边界框\n    max_ious, indices = np.max(jaccard, axis=1), np.argmax(jaccard, axis=1)\n    anc_i = np.nonzero(max_ious >= iou_threshold)[0]\n    box_j = indices[max_ious >= iou_threshold]\n    anchors_bbox_map[anc_i] = box_j\n    col_discard = np.full((num_anchors,), -1)\n    row_discard = np.full((num_gt_boxes,), -1)\n    for _ in range(num_gt_boxes):\n        max_idx = np.argmax(jaccard)\n        box_idx = (max_idx % num_gt_boxes).astype('int32')\n        anc_idx = (max_idx / num_gt_boxes).astype('int32')\n        anchors_bbox_map[anc_idx] = box_idx\n        jaccard[:, box_idx] = col_discard\n        jaccard[anc_idx, :] = row_discard\n    return anchors_bbox_map\n\ndef offset_boxes(anchors, assigned_bb, eps=1e-6):\n    \"\"\"对锚框偏移量的转换\n\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    c_anc = d2l.box_corner_to_center(anchors)\n    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)\n    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]\n    offset_wh = 5 * d2l.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])\n    offset = d2l.concat([offset_xy, offset_wh], axis=1)\n    return offset\n\ndef multibox_target(anchors, labels):\n    \"\"\"使用真实边界框标记锚框\n\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    batch_size, anchors = labels.shape[0], anchors.squeeze(0)\n    batch_offset, batch_mask, batch_class_labels = [], [], []\n    device, num_anchors = anchors.ctx, anchors.shape[0]\n    for i in range(batch_size):\n        label = labels[i, :, :]\n        anchors_bbox_map = assign_anchor_to_bbox(\n            label[:, 1:], anchors, device)\n        bbox_mask = np.tile((np.expand_dims((anchors_bbox_map >= 0),\n                                            axis=-1)), (1, 4)).astype('int32')\n        # 将类标签和分配的边界框坐标初始化为零\n        class_labels = d2l.zeros(num_anchors, dtype=np.int32, ctx=device)\n        assigned_bb = d2l.zeros((num_anchors, 4), dtype=np.float32,\n                                ctx=device)\n        # 使用真实边界框来标记锚框的类别。\n        # 如果一个锚框没有被分配，标记其为背景（值为零）\n        indices_true = np.nonzero(anchors_bbox_map >= 0)[0]\n        bb_idx = anchors_bbox_map[indices_true]\n        class_labels[indices_true] = label[bb_idx, 0].astype('int32') + 1\n        assigned_bb[indices_true] = label[bb_idx, 1:]\n        # 偏移量转换\n        offset = offset_boxes(anchors, assigned_bb) * bbox_mask\n        batch_offset.append(offset.reshape(-1))\n        batch_mask.append(bbox_mask.reshape(-1))\n        batch_class_labels.append(class_labels)\n    bbox_offset = d2l.stack(batch_offset)\n    bbox_mask = d2l.stack(batch_mask)\n    class_labels = d2l.stack(batch_class_labels)\n    return (bbox_offset, bbox_mask, class_labels)\n\ndef offset_inverse(anchors, offset_preds):\n    \"\"\"根据带有预测偏移量的锚框来预测边界框\n\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    anc = d2l.box_corner_to_center(anchors)\n    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]\n    pred_bbox_wh = d2l.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]\n    pred_bbox = d2l.concat((pred_bbox_xy, pred_bbox_wh), axis=1)\n    predicted_bbox = d2l.box_center_to_corner(pred_bbox)\n    return predicted_bbox\n\ndef nms(boxes, scores, iou_threshold):\n    \"\"\"对预测边界框的置信度进行排序\n\n    Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"\n    B = scores.argsort()[::-1]\n    keep = []  # 保留预测边界框的指标\n    while B.size > 0:\n        i = B[0]\n        keep.append(i)\n        if B.size == 1: break\n        iou = box_iou(boxes[i, :].reshape(-1, 4),\n                      boxes[B[1:], :].reshape(-1, 4)).reshape(-1)\n        inds = np.nonzero(iou <= iou_threshold)[0]\n        B = B[inds + 1]\n    return np.array(keep, dtype=np.int32, ctx=boxes.ctx)\n\ndef multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,\n                       pos_threshold=0.009999999):\n    \"\"\"使用非极大值抑制来预测边界框\n\n    Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"\n    device, batch_size = cls_probs.ctx, cls_probs.shape[0]\n    anchors = np.squeeze(anchors, axis=0)\n    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]\n    out = []\n    for i in range(batch_size):\n        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)\n        conf, class_id = np.max(cls_prob[1:], 0), np.argmax(cls_prob[1:], 0)\n        predicted_bb = offset_inverse(anchors, offset_pred)\n        keep = nms(predicted_bb, conf, nms_threshold)\n\n        # 找到所有的non_keep索引，并将类设置为背景\n        all_idx = np.arange(num_anchors, dtype=np.int32, ctx=device)\n        combined = d2l.concat((keep, all_idx))\n        unique, counts = np.unique(combined, return_counts=True)\n        non_keep = unique[counts == 1]\n        all_id_sorted = d2l.concat((keep, non_keep))\n        class_id[non_keep] = -1\n        class_id = class_id[all_id_sorted].astype('float32')\n        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]\n        # pos_threshold是一个用于非背景预测的阈值\n        below_min_idx = (conf < pos_threshold)\n        class_id[below_min_idx] = -1\n        conf[below_min_idx] = 1 - conf[below_min_idx]\n        pred_info = d2l.concat((np.expand_dims(class_id, axis=1),\n                                np.expand_dims(conf, axis=1),\n                                predicted_bb), axis=1)\n        out.append(pred_info)\n    return d2l.stack(out)\n\nd2l.DATA_HUB['banana-detection'] = (\n    d2l.DATA_URL + 'banana-detection.zip',\n    '5de26c8fce5ccdea9f91267273464dc968d20d72')\n\ndef read_data_bananas(is_train=True):\n    \"\"\"读取香蕉检测数据集中的图像和标签\n\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    data_dir = d2l.download_extract('banana-detection')\n    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train\n                             else 'bananas_val', 'label.csv')\n    csv_data = pd.read_csv(csv_fname)\n    csv_data = csv_data.set_index('img_name')\n    images, targets = [], []\n    for img_name, target in csv_data.iterrows():\n        images.append(image.imread(\n            os.path.join(data_dir, 'bananas_train' if is_train else\n                         'bananas_val', 'images', f'{img_name}')))\n        # 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y），\n        # 其中所有图像都具有相同的香蕉类（索引为0）\n        targets.append(list(target))\n    return images, np.expand_dims(np.array(targets), 1) / 256\n\nclass BananasDataset(gluon.data.Dataset):\n    \"\"\"一个用于加载香蕉检测数据集的自定义数据集\n\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    def __init__(self, is_train):\n        self.features, self.labels = read_data_bananas(is_train)\n        print('read ' + str(len(self.features)) + (f' training examples' if\n              is_train else f' validation examples'))\n\n    def __getitem__(self, idx):\n        return (self.features[idx].astype('float32').transpose(2, 0, 1),\n                self.labels[idx])\n\n    def __len__(self):\n        return len(self.features)\n\ndef load_data_bananas(batch_size):\n    \"\"\"加载香蕉检测数据集\n\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    train_iter = gluon.data.DataLoader(BananasDataset(is_train=True),\n                                       batch_size, shuffle=True)\n    val_iter = gluon.data.DataLoader(BananasDataset(is_train=False),\n                                     batch_size)\n    return train_iter, val_iter\n\nd2l.DATA_HUB['voc2012'] = (d2l.DATA_URL + 'VOCtrainval_11-May-2012.tar',\n                           '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n\ndef read_voc_images(voc_dir, is_train=True):\n    \"\"\"读取所有VOC图像并标注\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',\n                             'train.txt' if is_train else 'val.txt')\n    with open(txt_fname, 'r') as f:\n        images = f.read().split()\n    features, labels = [], []\n    for i, fname in enumerate(images):\n        features.append(image.imread(os.path.join(\n            voc_dir, 'JPEGImages', f'{fname}.jpg')))\n        labels.append(image.imread(os.path.join(\n            voc_dir, 'SegmentationClass', f'{fname}.png')))\n    return features, labels\n\nVOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n                [0, 64, 128]]\n\nVOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n\ndef voc_colormap2label():\n    \"\"\"构建从RGB到VOC类别索引的映射\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    colormap2label = np.zeros(256 ** 3)\n    for i, colormap in enumerate(VOC_COLORMAP):\n        colormap2label[\n            (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n    return colormap2label\n\ndef voc_label_indices(colormap, colormap2label):\n    \"\"\"将VOC标签中的RGB值映射到它们的类别索引\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    colormap = colormap.astype(np.int32)\n    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n           + colormap[:, :, 2])\n    return colormap2label[idx]\n\ndef voc_rand_crop(feature, label, height, width):\n    \"\"\"随机裁剪特征和标签图像\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    feature, rect = image.random_crop(feature, (width, height))\n    label = image.fixed_crop(label, *rect)\n    return feature, label\n\nclass VOCSegDataset(gluon.data.Dataset):\n    \"\"\"一个用于加载VOC数据集的自定义数据集\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    def __init__(self, is_train, crop_size, voc_dir):\n        self.rgb_mean = np.array([0.485, 0.456, 0.406])\n        self.rgb_std = np.array([0.229, 0.224, 0.225])\n        self.crop_size = crop_size\n        features, labels = read_voc_images(voc_dir, is_train=is_train)\n        self.features = [self.normalize_image(feature)\n                         for feature in self.filter(features)]\n        self.labels = self.filter(labels)\n        self.colormap2label = voc_colormap2label()\n        print('read ' + str(len(self.features)) + ' examples')\n\n    def normalize_image(self, img):\n        return (img.astype('float32') / 255 - self.rgb_mean) / self.rgb_std\n\n    def filter(self, imgs):\n        return [img for img in imgs if (\n            img.shape[0] >= self.crop_size[0] and\n            img.shape[1] >= self.crop_size[1])]\n\n    def __getitem__(self, idx):\n        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n                                       *self.crop_size)\n        return (feature.transpose(2, 0, 1),\n                voc_label_indices(label, self.colormap2label))\n\n    def __len__(self):\n        return len(self.features)\n\ndef load_data_voc(batch_size, crop_size):\n    \"\"\"加载VOC语义分割数据集\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    voc_dir = d2l.download_extract('voc2012', os.path.join(\n        'VOCdevkit', 'VOC2012'))\n    num_workers = d2l.get_dataloader_workers()\n    train_iter = gluon.data.DataLoader(\n        VOCSegDataset(True, crop_size, voc_dir), batch_size,\n        shuffle=True, last_batch='discard', num_workers=num_workers)\n    test_iter = gluon.data.DataLoader(\n        VOCSegDataset(False, crop_size, voc_dir), batch_size,\n        last_batch='discard', num_workers=num_workers)\n    return train_iter, test_iter\n\nd2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip',\n                                '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n\ndef read_csv_labels(fname):\n    \"\"\"读取fname来给标签字典返回一个文件名\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    with open(fname, 'r') as f:\n        # 跳过文件头行(列名)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\ndef copyfile(filename, target_dir):\n    \"\"\"将文件复制到目标目录\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n\ndef reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"将验证集从原始的训练集中拆分出来\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    # 训练数据集中样本最少的类别中的样本数\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # 验证集中每个类别的样本数\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label\n\ndef reorg_test(data_dir):\n    \"\"\"在预测期间整理测试集，以方便读取\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))\n\nd2l.DATA_HUB['dog_tiny'] = (d2l.DATA_URL + 'kaggle_dog_tiny.zip',\n                            '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d')\n\nd2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip',\n                       '319d85e578af0cdc590547f26231e4e31cdf1e42')\n\ndef read_ptb():\n    \"\"\"将PTB数据集加载到文本行的列表中\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    data_dir = d2l.download_extract('ptb')\n    # Readthetrainingset.\n    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n        raw_text = f.read()\n    return [line.split() for line in raw_text.split('\\n')]\n\ndef subsample(sentences, vocab):\n    \"\"\"下采样高频词\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    # 排除未知词元'<unk>'\n    sentences = [[token for token in line if vocab[token] != vocab.unk]\n                 for line in sentences]\n    counter = d2l.count_corpus(sentences)\n    num_tokens = sum(counter.values())\n\n    # 如果在下采样期间保留词元，则返回True\n    def keep(token):\n        return(random.uniform(0, 1) <\n               math.sqrt(1e-4 / counter[token] * num_tokens))\n\n    return ([[token for token in line if keep(token)] for line in sentences],\n            counter)\n\ndef get_centers_and_contexts(corpus, max_window_size):\n    \"\"\"返回跳元模型中的中心词和上下文词\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    centers, contexts = [], []\n    for line in corpus:\n        # 要形成“中心词-上下文词”对，每个句子至少需要有2个词\n        if len(line) < 2:\n            continue\n        centers += line\n        for i in range(len(line)):  # 上下文窗口中间i\n            window_size = random.randint(1, max_window_size)\n            indices = list(range(max(0, i - window_size),\n                                 min(len(line), i + 1 + window_size)))\n            # 从上下文词中排除中心词\n            indices.remove(i)\n            contexts.append([line[idx] for idx in indices])\n    return centers, contexts\n\nclass RandomGenerator:\n    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n    def __init__(self, sampling_weights):\n        \"\"\"Defined in :numref:`sec_word2vec_data`\"\"\"\n        # Exclude\n        self.population = list(range(1, len(sampling_weights) + 1))\n        self.sampling_weights = sampling_weights\n        self.candidates = []\n        self.i = 0\n\n    def draw(self):\n        if self.i == len(self.candidates):\n            # 缓存k个随机采样结果\n            self.candidates = random.choices(\n                self.population, self.sampling_weights, k=10000)\n            self.i = 0\n        self.i += 1\n        return self.candidates[self.i - 1]\n\ngenerator = RandomGenerator([2, 3, 4])\n[generator.draw() for _ in range(10)]\n\ndef get_negatives(all_contexts, vocab, counter, K):\n    \"\"\"返回负采样中的噪声词\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    # 索引为1、2、...（索引0是词表中排除的未知标记）\n    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n                        for i in range(1, len(vocab))]\n    all_negatives, generator = [], RandomGenerator(sampling_weights)\n    for contexts in all_contexts:\n        negatives = []\n        while len(negatives) < len(contexts) * K:\n            neg = generator.draw()\n            # 噪声词不能是上下文词\n            if neg not in contexts:\n                negatives.append(neg)\n        all_negatives.append(negatives)\n    return all_negatives\n\ndef batchify(data):\n    \"\"\"返回带有负采样的跳元模型的小批量样本\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    max_len = max(len(c) + len(n) for _, c, n in data)\n    centers, contexts_negatives, masks, labels = [], [], [], []\n    for center, context, negative in data:\n        cur_len = len(context) + len(negative)\n        centers += [center]\n        contexts_negatives += \\\n            [context + negative + [0] * (max_len - cur_len)]\n        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n    return (d2l.reshape(d2l.tensor(centers), (-1, 1)), d2l.tensor(\n        contexts_negatives), d2l.tensor(masks), d2l.tensor(labels))\n\ndef load_data_ptb(batch_size, max_window_size, num_noise_words):\n    \"\"\"下载PTB数据集，然后将其加载到内存中\n\n    Defined in :numref:`subsec_word2vec-minibatch-loading`\"\"\"\n    sentences = read_ptb()\n    vocab = d2l.Vocab(sentences, min_freq=10)\n    subsampled, counter = subsample(sentences, vocab)\n    corpus = [vocab[line] for line in subsampled]\n    all_centers, all_contexts = get_centers_and_contexts(\n        corpus, max_window_size)\n    all_negatives = get_negatives(\n        all_contexts, vocab, counter, num_noise_words)\n    dataset = gluon.data.ArrayDataset(\n        all_centers, all_contexts, all_negatives)\n    data_iter = gluon.data.DataLoader(\n        dataset, batch_size, shuffle=True,batchify_fn=batchify,\n        num_workers=d2l.get_dataloader_workers())\n    return data_iter, vocab\n\nd2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n\nd2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n\nd2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n\nd2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n                           'c1816da3821ae9f43899be655002f6c723e91b88')\n\nclass TokenEmbedding:\n    \"\"\"GloVe嵌入\"\"\"\n    def __init__(self, embedding_name):\n        \"\"\"Defined in :numref:`sec_synonyms`\"\"\"\n        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n            embedding_name)\n        self.unknown_idx = 0\n        self.token_to_idx = {token: idx for idx, token in\n                             enumerate(self.idx_to_token)}\n\n    def _load_embedding(self, embedding_name):\n        idx_to_token, idx_to_vec = ['<unk>'], []\n        data_dir = d2l.download_extract(embedding_name)\n        # GloVe网站：https://nlp.stanford.edu/projects/glove/\n        # fastText网站：https://fasttext.cc/\n        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n            for line in f:\n                elems = line.rstrip().split(' ')\n                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n                # 跳过标题信息，例如fastText中的首行\n                if len(elems) > 1:\n                    idx_to_token.append(token)\n                    idx_to_vec.append(elems)\n        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n        return idx_to_token, d2l.tensor(idx_to_vec)\n\n    def __getitem__(self, tokens):\n        indices = [self.token_to_idx.get(token, self.unknown_idx)\n                   for token in tokens]\n        vecs = self.idx_to_vec[d2l.tensor(indices)]\n        return vecs\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\ndef get_tokens_and_segments(tokens_a, tokens_b=None):\n    \"\"\"获取输入序列的词元及其片段索引\n\n    Defined in :numref:`sec_bert`\"\"\"\n    tokens = ['<cls>'] + tokens_a + ['<sep>']\n    # 0和1分别标记片段A和B\n    segments = [0] * (len(tokens_a) + 2)\n    if tokens_b is not None:\n        tokens += tokens_b + ['<sep>']\n        segments += [1] * (len(tokens_b) + 1)\n    return tokens, segments\n\nclass BERTEncoder(nn.Block):\n    \"\"\"BERT编码器\n\n    Defined in :numref:`subsec_bert_input_rep`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n                 num_layers, dropout, max_len=1000, **kwargs):\n        super(BERTEncoder, self).__init__(**kwargs)\n        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.segment_embedding = nn.Embedding(2, num_hiddens)\n        self.blks = nn.Sequential()\n        for _ in range(num_layers):\n            self.blks.add(d2l.EncoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, True))\n        # 在BERT中，位置嵌入是可学习的，因此我们创建一个足够长的位置嵌入参数\n        self.pos_embedding = self.params.get('pos_embedding',\n                                             shape=(1, max_len, num_hiddens))\n\n    def forward(self, tokens, segments, valid_lens):\n        # 在以下代码段中，X的形状保持不变：（批量大小，最大序列长度，num_hiddens）\n        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n        X = X + self.pos_embedding.data(ctx=X.ctx)[:, :X.shape[1], :]\n        for blk in self.blks:\n            X = blk(X, valid_lens)\n        return X\n\nclass MaskLM(nn.Block):\n    \"\"\"BERT的掩蔽语言模型任务\n\n    Defined in :numref:`subsec_bert_input_rep`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, **kwargs):\n        super(MaskLM, self).__init__(**kwargs)\n        self.mlp = nn.Sequential()\n        self.mlp.add(\n            nn.Dense(num_hiddens, flatten=False, activation='relu'))\n        self.mlp.add(nn.LayerNorm())\n        self.mlp.add(nn.Dense(vocab_size, flatten=False))\n\n    def forward(self, X, pred_positions):\n        num_pred_positions = pred_positions.shape[1]\n        pred_positions = pred_positions.reshape(-1)\n        batch_size = X.shape[0]\n        batch_idx = np.arange(0, batch_size)\n        # 假设batch_size=2，num_pred_positions=3\n        # 那么batch_idx是np.array（[0,0,0,1,1,1]）\n        batch_idx = np.repeat(batch_idx, num_pred_positions)\n        masked_X = X[batch_idx, pred_positions]\n        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n        mlm_Y_hat = self.mlp(masked_X)\n        return mlm_Y_hat\n\nclass NextSentencePred(nn.Block):\n    \"\"\"BERT的下一句预测任务\n\n    Defined in :numref:`subsec_mlm`\"\"\"\n    def __init__(self, **kwargs):\n        super(NextSentencePred, self).__init__(**kwargs)\n        self.output = nn.Dense(2)\n\n    def forward(self, X):\n        # X的形状：(batchsize，num_hiddens)\n        return self.output(X)\n\nclass BERTModel(nn.Block):\n    \"\"\"BERT模型\n\n    Defined in :numref:`subsec_nsp`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n                 num_layers, dropout, max_len=1000):\n        super(BERTModel, self).__init__()\n        self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,\n                                   num_heads, num_layers, dropout, max_len)\n        self.hidden = nn.Dense(num_hiddens, activation='tanh')\n        self.mlm = MaskLM(vocab_size, num_hiddens)\n        self.nsp = NextSentencePred()\n\n    def forward(self, tokens, segments, valid_lens=None,\n                pred_positions=None):\n        encoded_X = self.encoder(tokens, segments, valid_lens)\n        if pred_positions is not None:\n            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n        else:\n            mlm_Y_hat = None\n        # 用于下一句预测的多层感知机分类器的隐藏层，0是“<cls>”标记的索引\n        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n        return encoded_X, mlm_Y_hat, nsp_Y_hat\n\nd2l.DATA_HUB['wikitext-2'] = (\n    'https://s3.amazonaws.com/research.metamind.io/wikitext/'\n    'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n\ndef _read_wiki(data_dir):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n    with open(file_name, 'r') as f:\n        lines = f.readlines()\n    # 大写字母转换为小写字母\n    paragraphs = [line.strip().lower().split(' . ')\n                  for line in lines if len(line.split(' . ')) >= 2]\n    random.shuffle(paragraphs)\n    return paragraphs\n\ndef _get_next_sentence(sentence, next_sentence, paragraphs):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    if random.random() < 0.5:\n        is_next = True\n    else:\n        # paragraphs是三重列表的嵌套\n        next_sentence = random.choice(random.choice(paragraphs))\n        is_next = False\n    return sentence, next_sentence, is_next\n\ndef _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    nsp_data_from_paragraph = []\n    for i in range(len(paragraph) - 1):\n        tokens_a, tokens_b, is_next = _get_next_sentence(\n            paragraph[i], paragraph[i + 1], paragraphs)\n        # 考虑1个'<cls>'词元和2个'<sep>'词元\n        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n            continue\n        tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n        nsp_data_from_paragraph.append((tokens, segments, is_next))\n    return nsp_data_from_paragraph\n\ndef _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,\n                        vocab):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    # 为遮蔽语言模型的输入创建新的词元副本，其中输入可能包含替换的“<mask>”或随机词元\n    mlm_input_tokens = [token for token in tokens]\n    pred_positions_and_labels = []\n    # 打乱后用于在遮蔽语言模型任务中获取15%的随机词元进行预测\n    random.shuffle(candidate_pred_positions)\n    for mlm_pred_position in candidate_pred_positions:\n        if len(pred_positions_and_labels) >= num_mlm_preds:\n            break\n        masked_token = None\n        # 80%的时间：将词替换为“<mask>”词元\n        if random.random() < 0.8:\n            masked_token = '<mask>'\n        else:\n            # 10%的时间：保持词不变\n            if random.random() < 0.5:\n                masked_token = tokens[mlm_pred_position]\n            # 10%的时间：用随机词替换该词\n            else:\n                masked_token = random.choice(vocab.idx_to_token)\n        mlm_input_tokens[mlm_pred_position] = masked_token\n        pred_positions_and_labels.append(\n            (mlm_pred_position, tokens[mlm_pred_position]))\n    return mlm_input_tokens, pred_positions_and_labels\n\ndef _get_mlm_data_from_tokens(tokens, vocab):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    candidate_pred_positions = []\n    # tokens是一个字符串列表\n    for i, token in enumerate(tokens):\n        # 在遮蔽语言模型任务中不会预测特殊词元\n        if token in ['<cls>', '<sep>']:\n            continue\n        candidate_pred_positions.append(i)\n    # 遮蔽语言模型任务中预测15%的随机词元\n    num_mlm_preds = max(1, round(len(tokens) * 0.15))\n    mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(\n        tokens, candidate_pred_positions, num_mlm_preds, vocab)\n    pred_positions_and_labels = sorted(pred_positions_and_labels,\n                                       key=lambda x: x[0])\n    pred_positions = [v[0] for v in pred_positions_and_labels]\n    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n    return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]\n\ndef _pad_bert_inputs(examples, max_len, vocab):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    max_num_mlm_preds = round(max_len * 0.15)\n    all_token_ids, all_segments, valid_lens,  = [], [], []\n    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n    nsp_labels = []\n    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n         is_next) in examples:\n        all_token_ids.append(np.array(token_ids + [vocab['<pad>']] * (\n            max_len - len(token_ids)), dtype='int32'))\n        all_segments.append(np.array(segments + [0] * (\n            max_len - len(segments)), dtype='int32'))\n        # valid_lens不包括'<pad>'的计数\n        valid_lens.append(np.array(len(token_ids), dtype='float32'))\n        all_pred_positions.append(np.array(pred_positions + [0] * (\n            max_num_mlm_preds - len(pred_positions)), dtype='int32'))\n        # 填充词元的预测将通过乘以0权重在损失中过滤掉\n        all_mlm_weights.append(\n            np.array([1.0] * len(mlm_pred_label_ids) + [0.0] * (\n                max_num_mlm_preds - len(pred_positions)), dtype='float32'))\n        all_mlm_labels.append(np.array(mlm_pred_label_ids + [0] * (\n            max_num_mlm_preds - len(mlm_pred_label_ids)), dtype='int32'))\n        nsp_labels.append(np.array(is_next))\n    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n            all_mlm_weights, all_mlm_labels, nsp_labels)\n\nclass _WikiTextDataset(gluon.data.Dataset):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    def __init__(self, paragraphs, max_len):\n        # 输入paragraphs[i]是代表段落的句子字符串列表；\n        # 而输出paragraphs[i]是代表段落的句子列表，其中每个句子都是词元列表\n        paragraphs = [d2l.tokenize(\n            paragraph, token='word') for paragraph in paragraphs]\n        sentences = [sentence for paragraph in paragraphs\n                     for sentence in paragraph]\n        self.vocab = d2l.Vocab(sentences, min_freq=5, reserved_tokens=[\n            '<pad>', '<mask>', '<cls>', '<sep>'])\n        # 获取下一句子预测任务的数据\n        examples = []\n        for paragraph in paragraphs:\n            examples.extend(_get_nsp_data_from_paragraph(\n                paragraph, paragraphs, self.vocab, max_len))\n        # 获取遮蔽语言模型任务的数据\n        examples = [(_get_mlm_data_from_tokens(tokens, self.vocab)\n                      + (segments, is_next))\n                     for tokens, segments, is_next in examples]\n        # 填充输入\n        (self.all_token_ids, self.all_segments, self.valid_lens,\n         self.all_pred_positions, self.all_mlm_weights,\n         self.all_mlm_labels, self.nsp_labels) = _pad_bert_inputs(\n            examples, max_len, self.vocab)\n\n    def __getitem__(self, idx):\n        return (self.all_token_ids[idx], self.all_segments[idx],\n                self.valid_lens[idx], self.all_pred_positions[idx],\n                self.all_mlm_weights[idx], self.all_mlm_labels[idx],\n                self.nsp_labels[idx])\n\n    def __len__(self):\n        return len(self.all_token_ids)\n\ndef load_data_wiki(batch_size, max_len):\n    \"\"\"加载WikiText-2数据集\n\n    Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    num_workers = d2l.get_dataloader_workers()\n    data_dir = d2l.download_extract('wikitext-2', 'wikitext-2')\n    paragraphs = _read_wiki(data_dir)\n    train_set = _WikiTextDataset(paragraphs, max_len)\n    train_iter = gluon.data.DataLoader(train_set, batch_size, shuffle=True,\n                                       num_workers=num_workers)\n    return train_iter, train_set.vocab\n\ndef _get_batch_loss_bert(net, loss, vocab_size, tokens_X_shards,\n                         segments_X_shards, valid_lens_x_shards,\n                         pred_positions_X_shards, mlm_weights_X_shards,\n                         mlm_Y_shards, nsp_y_shards):\n    \"\"\"Defined in :numref:`sec_bert-pretraining`\"\"\"\n    mlm_ls, nsp_ls, ls = [], [], []\n    for (tokens_X_shard, segments_X_shard, valid_lens_x_shard,\n         pred_positions_X_shard, mlm_weights_X_shard, mlm_Y_shard,\n         nsp_y_shard) in zip(\n        tokens_X_shards, segments_X_shards, valid_lens_x_shards,\n        pred_positions_X_shards, mlm_weights_X_shards, mlm_Y_shards,\n        nsp_y_shards):\n        # 前向传播\n        _, mlm_Y_hat, nsp_Y_hat = net(\n            tokens_X_shard, segments_X_shard, valid_lens_x_shard.reshape(-1),\n            pred_positions_X_shard)\n        # 计算遮蔽语言模型损失\n        mlm_l = loss(\n            mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y_shard.reshape(-1),\n            mlm_weights_X_shard.reshape((-1, 1)))\n        mlm_l = mlm_l.sum() / (mlm_weights_X_shard.sum() + 1e-8)\n        # 计算下一句子预测任务的损失\n        nsp_l = loss(nsp_Y_hat, nsp_y_shard)\n        nsp_l = nsp_l.mean()\n        mlm_ls.append(mlm_l)\n        nsp_ls.append(nsp_l)\n        ls.append(mlm_l + nsp_l)\n        npx.waitall()\n    return mlm_ls, nsp_ls, ls\n\nd2l.DATA_HUB['aclImdb'] = (\n    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n    '01ada507287d82875905620988597833ad4e0903')\n\ndef read_imdb(data_dir, is_train):\n    \"\"\"读取IMDb评论数据集文本序列和标签\n\n    Defined in :numref:`sec_sentiment`\"\"\"\n    data, labels = [], []\n    for label in ('pos', 'neg'):\n        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n                                   label)\n        for file in os.listdir(folder_name):\n            with open(os.path.join(folder_name, file), 'rb') as f:\n                review = f.read().decode('utf-8').replace('\\n', '')\n                data.append(review)\n                labels.append(1 if label == 'pos' else 0)\n    return data, labels\n\ndef load_data_imdb(batch_size, num_steps=500):\n    \"\"\"返回数据迭代器和IMDb评论数据集的词表\n\n    Defined in :numref:`sec_sentiment`\"\"\"\n    data_dir = d2l.download_extract('aclImdb', 'aclImdb')\n    train_data = read_imdb(data_dir, True)\n    test_data = read_imdb(data_dir, False)\n    train_tokens = d2l.tokenize(train_data[0], token='word')\n    test_tokens = d2l.tokenize(test_data[0], token='word')\n    vocab = d2l.Vocab(train_tokens, min_freq=5)\n    train_features = np.array([d2l.truncate_pad(\n        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n    test_features = np.array([d2l.truncate_pad(\n        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n    train_iter = d2l.load_array((train_features, train_data[1]), batch_size)\n    test_iter = d2l.load_array((test_features, test_data[1]), batch_size,\n                               is_train=False)\n    return train_iter, test_iter, vocab\n\ndef predict_sentiment(net, vocab, sequence):\n    \"\"\"预测文本序列的情感\n\n    Defined in :numref:`sec_sentiment_rnn`\"\"\"\n    sequence = np.array(vocab[sequence.split()], ctx=d2l.try_gpu())\n    label = np.argmax(net(sequence.reshape(1, -1)), axis=1)\n    return 'positive' if label == 1 else 'negative'\n\nd2l.DATA_HUB['SNLI'] = (\n    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n\ndef read_snli(data_dir, is_train):\n    \"\"\"将SNLI数据集解析为前提、假设和标签\n\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    def extract_text(s):\n        # 删除我们不会使用的信息\n        s = re.sub('\\\\(', '', s)\n        s = re.sub('\\\\)', '', s)\n        # 用一个空格替换两个或多个连续的空格\n        s = re.sub('\\\\s{2,}', ' ', s)\n        return s.strip()\n    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n                             if is_train else 'snli_1.0_test.txt')\n    with open(file_name, 'r') as f:\n        rows = [row.split('\\t') for row in f.readlines()[1:]]\n    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n    hypotheses = [extract_text(row[2]) for row in rows if row[0] \\\n                in label_set]\n    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n    return premises, hypotheses, labels\n\nclass SNLIDataset(gluon.data.Dataset):\n    \"\"\"用于加载SNLI数据集的自定义数据集\n\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    def __init__(self, dataset, num_steps, vocab=None):\n        self.num_steps = num_steps\n        all_premise_tokens = d2l.tokenize(dataset[0])\n        all_hypothesis_tokens = d2l.tokenize(dataset[1])\n        if vocab is None:\n            self.vocab = d2l.Vocab(all_premise_tokens + \\\n                all_hypothesis_tokens, min_freq=5, reserved_tokens=['<pad>'])\n        else:\n            self.vocab = vocab\n        self.premises = self._pad(all_premise_tokens)\n        self.hypotheses = self._pad(all_hypothesis_tokens)\n        self.labels = np.array(dataset[2])\n        print('read ' + str(len(self.premises)) + ' examples')\n\n    def _pad(self, lines):\n        return np.array([d2l.truncate_pad(\n            self.vocab[line], self.num_steps, self.vocab['<pad>'])\n                         for line in lines])\n\n    def __getitem__(self, idx):\n        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n\n    def __len__(self):\n        return len(self.premises)\n\ndef load_data_snli(batch_size, num_steps=50):\n    \"\"\"下载SNLI数据集并返回数据迭代器和词表\n\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    num_workers = d2l.get_dataloader_workers()\n    data_dir = d2l.download_extract('SNLI')\n    train_data = read_snli(data_dir, True)\n    test_data = read_snli(data_dir, False)\n    train_set = SNLIDataset(train_data, num_steps)\n    test_set = SNLIDataset(test_data, num_steps, train_set.vocab)\n    train_iter = gluon.data.DataLoader(train_set, batch_size, shuffle=True,\n                                       num_workers=num_workers)\n    test_iter = gluon.data.DataLoader(test_set, batch_size, shuffle=False,\n                                      num_workers=num_workers)\n    return train_iter, test_iter, train_set.vocab\n\ndef split_batch_multi_inputs(X, y, devices):\n    \"\"\"将多输入'X'和'y'拆分到多个设备\n\n    Defined in :numref:`sec_natural-language-inference-attention`\"\"\"\n    X = list(zip(*[gluon.utils.split_and_load(\n        feature, devices, even_split=False) for feature in X]))\n    return (X, gluon.utils.split_and_load(y, devices, even_split=False))\n\ndef predict_snli(net, vocab, premise, hypothesis):\n    \"\"\"预测前提和假设之间的逻辑关系\n\n    Defined in :numref:`sec_natural-language-inference-attention`\"\"\"\n    premise = np.array(vocab[premise], ctx=d2l.try_gpu())\n    hypothesis = np.array(vocab[hypothesis], ctx=d2l.try_gpu())\n    label = np.argmax(net([premise.reshape((1, -1)),\n                           hypothesis.reshape((1, -1))]), axis=1)\n    return 'entailment' if label == 0 else 'contradiction' if label == 1 \\\n            else 'neutral'\n\n\n# Alias defined in config.ini\nsize = lambda a: a.size\ntranspose = lambda a: a.T\nnn_Module = nn.Block\n\nones = np.ones\nzeros = np.zeros\narange = np.arange\nmeshgrid = np.meshgrid\nsin = np.sin\nsinh = np.sinh\ncos = np.cos\ncosh = np.cosh\ntanh = np.tanh\nlinspace = np.linspace\nexp = np.exp\nlog = np.log\ntensor = np.array\nnormal = np.random.normal\nrandn = np.random.randn\nrand = np.random.rand\nmatmul = np.dot\nint32 = np.int32\nfloat32 = np.float32\nconcat = np.concatenate\nstack = np.stack\nabs = np.abs\neye = np.eye\nnumpy = lambda x, *args, **kwargs: x.asnumpy(*args, **kwargs)\nreshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\nto = lambda x, *args, **kwargs: x.as_in_context(*args, **kwargs)\nreduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\nargmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\nastype = lambda x, *args, **kwargs: x.astype(*args, **kwargs)\nreduce_mean = lambda x, *args, **kwargs: x.mean(*args, **kwargs)\n\n",
    "d2l/paddle.py": "#################   WARNING   ################\n# The below part is generated automatically through:\n#    d2lbook build lib\n# Don't edit it directly\n\nimport collections\nimport hashlib\nimport math\nimport os\nimport random\nimport re\nimport shutil\nimport sys\nimport tarfile\nimport time\nimport zipfile\nfrom collections import defaultdict\nimport pandas as pd\nimport requests\nfrom IPython import display\nfrom matplotlib import pyplot as plt\nfrom matplotlib_inline import backend_inline\n\nd2l = sys.modules[__name__]\n\nimport warnings\nimport numpy as np\n\nwarnings.filterwarnings(\"ignore\")\nimport paddle\nimport paddle.vision as paddlevision\nfrom paddle import nn\nfrom paddle.nn import functional as F\nfrom paddle.vision import transforms\nfrom PIL import Image\n\npaddle.disable_signal_handler()\n\ndef use_svg_display():\n    \"\"\"使用svg格式在Jupyter中显示绘图\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    backend_inline.set_matplotlib_formats('svg')\n\ndef set_figsize(figsize=(3.5, 2.5)):\n    \"\"\"设置matplotlib的图表大小\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    use_svg_display()\n    d2l.plt.rcParams['figure.figsize'] = figsize\n\ndef set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n    \"\"\"设置matplotlib的轴\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel)\n    axes.set_xscale(xscale)\n    axes.set_yscale(yscale)\n    axes.set_xlim(xlim)\n    axes.set_ylim(ylim)\n    if legend:\n        axes.legend(legend)\n    axes.grid()\n\ndef plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n         ylim=None, xscale='linear', yscale='linear',\n         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n    \"\"\"绘制数据点\n\n    Defined in :numref:`sec_calculus`\"\"\"\n    if legend is None:\n        legend = []\n\n    set_figsize(figsize)\n    axes = axes if axes else d2l.plt.gca()\n\n    # 如果X有一个轴，输出True\n    def has_one_axis(X):\n        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n                and not hasattr(X[0], \"__len__\"))\n\n    if has_one_axis(X):\n        X = [X]\n    if Y is None:\n        X, Y = [[]] * len(X), X\n    elif has_one_axis(Y):\n        Y = [Y]\n    if len(X) != len(Y):\n        X = X * len(Y)\n    axes.cla()\n    for x, y, fmt in zip(X, Y, fmts):\n        if len(x):\n            axes.plot(x, y, fmt)\n        else:\n            axes.plot(y, fmt)\n    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n\nclass Timer:\n    \"\"\"记录多次运行时间\"\"\"\n    def __init__(self):\n        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n        self.times = []\n        self.start()\n\n    def start(self):\n        \"\"\"启动计时器\"\"\"\n        self.tik = time.time()\n\n    def stop(self):\n        \"\"\"停止计时器并将时间记录在列表中\"\"\"\n        self.times.append(time.time() - self.tik)\n        return self.times[-1]\n\n    def avg(self):\n        \"\"\"返回平均时间\"\"\"\n        return sum(self.times) / len(self.times)\n\n    def sum(self):\n        \"\"\"返回时间总和\"\"\"\n        return sum(self.times)\n\n    def cumsum(self):\n        \"\"\"返回累计时间\"\"\"\n        return np.array(self.times).cumsum().tolist()\n\ndef synthetic_data(w, b, num_examples):\n    \"\"\"生成y=Xw+b+噪声\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    X = d2l.normal(0, 1, (num_examples, len(w)))\n    y = d2l.matmul(X, w) + b\n    y += d2l.normal(0, 0.01, y.shape)\n    return X, d2l.reshape(y, (-1, 1))\n\ndef linreg(X, w, b):\n    \"\"\"线性回归模型\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    return d2l.matmul(X, w) + b\n\ndef squared_loss(y_hat, y):\n    \"\"\"均方损失\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    return (y_hat - d2l.reshape(y, y_hat.shape)) ** 2 / 2\n\ndef sgd(params, lr, batch_size):\n    \"\"\"小批量随机梯度下降\n\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n    with paddle.no_grad():\n        for i, param in enumerate(params):\n            param -= lr * params[i].grad / batch_size\n            params[i].set_value(param)\n            params[i].clear_gradient()\n\ndef load_array(data_arrays, batch_size, is_train=True):\n    \"\"\"构造一个Paddle数据迭代器\n\n    Defined in :numref:`sec_linear_concise`\"\"\"\n    dataset = paddle.io.TensorDataset(data_arrays)\n    return paddle.io.DataLoader(dataset, batch_size=batch_size,\n                                shuffle=is_train,\n                                return_list=True)\n\ndef get_fashion_mnist_labels(labels):\n    \"\"\"返回Fashion-MNIST数据集的文本标签\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n\ndef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n    \"\"\"绘制图像列表\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten()\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if paddle.is_tensor(img):\n            # 图片张量\n            ax.imshow(img.numpy())\n        else:\n            # PIL图片\n            ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n\ndef get_dataloader_workers():\n    \"\"\"使用4个进程来读取数据\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    return 4\n\ndef load_data_fashion_mnist(batch_size, resize=None):\n    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\n\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    trans = [transforms.ToTensor()]\n    if resize:\n        trans.insert(0, transforms.Resize(resize))\n    trans = transforms.Compose(trans)\n    mnist_train = paddle.vision.datasets.FashionMNIST(mode=\"train\",\n                                                      transform=trans)\n    mnist_test = paddle.vision.datasets.FashionMNIST(mode=\"test\",\n                                                     transform=trans)\n    return (paddle.io.DataLoader(dataset=mnist_train,\n                                 batch_size=batch_size,\n                                 shuffle=True,\n                                 return_list=True,\n                                 num_workers=get_dataloader_workers()),\n            paddle.io.DataLoader(dataset=mnist_test,\n                                 batch_size=batch_size,\n                                 return_list=True,\n                                 shuffle=True,\n                                 num_workers=get_dataloader_workers()))\n\ndef accuracy(y_hat, y):\n    \"\"\"计算预测正确的数量\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n        y_hat = d2l.argmax(y_hat, axis=1)\n    cmp = d2l.astype(y_hat, y.dtype) == y\n    return float(d2l.reduce_sum(d2l.astype(cmp, y.dtype)))\n\ndef accuracy(y_hat, y):\n    \"\"\"计算预测正确的数量\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n        y_hat = y_hat.argmax(axis=1)\n    if len(y_hat.shape) < len(y.shape):\n        cmp = y_hat.astype(y.dtype) == y.squeeze()\n    else:\n        cmp = y_hat.astype(y.dtype) == y\n    return float(cmp.astype(y.dtype).sum())\n\ndef evaluate_accuracy(net, data_iter):\n    \"\"\"计算在指定数据集上模型的精度\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    if isinstance(net, paddle.nn.Layer):\n        net.eval()  # 将模型设置为评估模式\n    metric = Accumulator(2)  # 正确预测数、预测总数\n    with paddle.no_grad():\n        for X, y in data_iter:\n            metric.add(accuracy(net(X), y), d2l.size(y))\n    return metric[0] / metric[1]\n\nclass Accumulator:\n    \"\"\"在n个变量上累加\"\"\"\n    def __init__(self, n):\n        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n        self.data = [0.0] * n\n\n    def add(self, *args):\n        self.data = [a + float(b) for a, b in zip(self.data, args)]\n\n    def reset(self):\n        self.data = [0.0] * len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\ndef train_epoch_ch3(net, train_iter, loss, updater):\n    \"\"\"训练模型一个迭代周期（定义见第3章）\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    # 将模型设置为训练模式\n    if isinstance(net, paddle.nn.Layer):\n        net.train()\n    # 训练损失总和、训练准确度总和、样本数\n    metric = Accumulator(3)\n\n    for X, y in train_iter:\n        # 计算梯度并更新参数\n        y_hat = net(X)\n        l = loss(y_hat, y)\n        if isinstance(updater, paddle.optimizer.Optimizer):\n            # 使用PaddlePaddle内置的优化器和损失函数\n            updater.clear_grad()\n            l.mean().backward()\n            updater.step()\n        else:\n            # 使用定制的优化器和损失函数\n            l.sum().backward()\n            updater(X.shape[0])\n        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n    return metric[0] / metric[2], metric[1] / metric[2]\n\nclass Animator:\n    \"\"\"在动画中绘制数据\"\"\"\n    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n                 figsize=(3.5, 2.5)):\n        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n        # 增量地绘制多条线\n        if legend is None:\n            legend = []\n        d2l.use_svg_display()\n        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n        if nrows * ncols == 1:\n            self.axes = [self.axes, ]\n        # 使用lambda函数捕获参数\n        self.config_axes = lambda: d2l.set_axes(\n            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n        self.X, self.Y, self.fmts = None, None, fmts\n\n    def add(self, x, y):\n        # 向图表中添加多个数据点\n        if not hasattr(y, \"__len__\"):\n            y = [y]\n        n = len(y)\n        if not hasattr(x, \"__len__\"):\n            x = [x] * n\n        if not self.X:\n            self.X = [[] for _ in range(n)]\n        if not self.Y:\n            self.Y = [[] for _ in range(n)]\n        for i, (a, b) in enumerate(zip(x, y)):\n            if a is not None and b is not None:\n                self.X[i].append(a)\n                self.Y[i].append(b)\n        self.axes[0].cla()\n        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n            self.axes[0].plot(x, y, fmt)\n        self.config_axes()\n        display.display(self.fig)\n        display.clear_output(wait=True)\n\ndef train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n    \"\"\"训练模型（定义见第3章）\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n                        legend=['train loss', 'train acc', 'test acc'])\n    for epoch in range(num_epochs):\n        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n        test_acc = evaluate_accuracy(net, test_iter)\n        animator.add(epoch + 1, train_metrics + (test_acc,))\n    train_loss, train_acc = train_metrics\n    assert train_loss < 0.5, train_loss\n    assert train_acc <= 1 and train_acc > 0.7, train_acc\n    assert test_acc <= 1 and test_acc > 0.7, test_acc\n\ndef predict_ch3(net, test_iter, n=6):\n    \"\"\"预测标签（定义见第3章）\n\n    Defined in :numref:`sec_softmax_scratch`\"\"\"\n    for X, y in test_iter:\n        break\n    trues = d2l.get_fashion_mnist_labels(y)\n    preds = d2l.get_fashion_mnist_labels(d2l.argmax(net(X), axis=1))\n    titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n    d2l.show_images(\n        d2l.reshape(X[0:n], (n, 28, 28)), 1, n, titles=titles[0:n])\n\ndef evaluate_loss(net, data_iter, loss):\n    \"\"\"评估给定数据集上模型的损失。\n\n    Defined in :numref:`sec_model_selection`\"\"\"\n    metric = d2l.Accumulator(2)  # 损失的总和, 样本数量\n    for X, y in data_iter:\n        out = net(X)\n        y = y.reshape(out.shape)\n        l = loss(out, y)\n        metric.add(l.sum(), l.numel())\n    return metric[0] / metric[1]\n\nDATA_HUB = dict()\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n\ndef download(name, cache_dir=os.path.join('..', 'data')):\n    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\n\n    Defined in :numref:`sec_kaggle_house`\"\"\"\n    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n    url, sha1_hash = DATA_HUB[name]\n    os.makedirs(cache_dir, exist_ok=True)\n    fname = os.path.join(cache_dir, url.split('/')[-1])\n    if os.path.exists(fname):\n        sha1 = hashlib.sha1()\n        with open(fname, 'rb') as f:\n            while True:\n                data = f.read(1048576)\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() == sha1_hash:\n            return fname  # 命中缓存\n    print(f'正在从{url}下载{fname}...')\n    r = requests.get(url, stream=True, verify=True)\n    with open(fname, 'wb') as f:\n        f.write(r.content)\n    return fname\n\ndef download_extract(name, folder=None):\n    \"\"\"下载并解压zip/tar文件\n\n    Defined in :numref:`sec_kaggle_house`\"\"\"\n    fname = download(name)\n    base_dir = os.path.dirname(fname)\n    data_dir, ext = os.path.splitext(fname)\n    if ext == '.zip':\n        fp = zipfile.ZipFile(fname, 'r')\n    elif ext in ('.tar', '.gz'):\n        fp = tarfile.open(fname, 'r')\n    else:\n        assert False, '只有zip/tar文件可以被解压缩'\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n\ndef download_all():\n    \"\"\"下载DATA_HUB中的所有文件\n\n    Defined in :numref:`sec_kaggle_house`\"\"\"\n    for name in DATA_HUB:\n        download(name)\n\nDATA_HUB['kaggle_house_train'] = (\n    DATA_URL + 'kaggle_house_pred_train.csv',\n    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n\nDATA_HUB['kaggle_house_test'] = (\n    DATA_URL + 'kaggle_house_pred_test.csv',\n    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n\ndef try_gpu(i=0):\n    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()。\n\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    if paddle.device.cuda.device_count() >= i + 1:\n        return paddle.CUDAPlace(i)\n    return paddle.CPUPlace()\n\ndef try_all_gpus():\n    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。\n\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    devices = [paddle.CUDAPlace(i)\n               for i in range(paddle.device.cuda.device_count())]\n    return devices if devices else paddle.CPUPlace()\n\ndef corr2d(X, K):\n    \"\"\"计算二维互相关运算\n\n    Defined in :numref:`sec_conv_layer`\"\"\"\n    h, w = K.shape\n    Y = d2l.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = d2l.reduce_sum((X[i: i + h, j: j + w] * K))\n    return Y\n\ndef evaluate_accuracy_gpu(net, data_iter, device=None):\n    \"\"\"使用GPU计算模型在数据集上的精度\n\n    Defined in :numref:`sec_lenet`\"\"\"\n    if isinstance(net, nn.Layer):\n        net.eval()  # 设置为评估模式\n        if not device:\n            device = next(iter(net.parameters())).place\n    paddle.set_device(\"gpu:{}\".format(str(device)[-2]))\n    # 正确预测的数量，总预测的数量\n    metric = d2l.Accumulator(2)\n    with paddle.no_grad():\n        for X, y in data_iter:\n            if isinstance(X, list):\n                # BERT微调所需的\n                X = [paddle.to_tensor(x, place=device) for x in X]\n            else:\n                X = paddle.to_tensor(X, place=device)\n            y = paddle.to_tensor(y, place=device)\n            metric.add(d2l.accuracy(net(X), y), d2l.size(y))\n    return metric[0] / metric[1]\n\ndef train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n    \"\"\"用GPU训练模型(在第六章定义)\n\n    Defined in :numref:`sec_lenet`\"\"\"\n    def init_weights(m):\n        if type(m) == nn.Linear or type(m) == nn.Conv2D:\n            nn.initializer.XavierUniform(m.weight)\n    net.apply(init_weights)\n    print('training on', device)\n    net.to(device)\n    optimizer = paddle.optimizer.SGD(learning_rate=lr, parameters=net.parameters())\n    loss = nn.CrossEntropyLoss()\n    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n                            legend=['train loss', 'train acc', 'test acc'])\n    timer, num_batches = d2l.Timer(), len(train_iter)\n    for epoch in range(num_epochs):\n        # 训练损失之和，训练准确率之和，样本数\n        metric = d2l.Accumulator(3)\n        net.train()\n        for i, (X, y) in enumerate(train_iter):\n            timer.start()\n            optimizer.clear_grad()\n            X, y = paddle.to_tensor(X, place=device), paddle.to_tensor(y, place=device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            with paddle.no_grad():\n                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n            timer.stop()\n            train_l = metric[0] / metric[2]\n            train_acc = metric[1] / metric[2]\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (train_l, train_acc, None))\n        test_acc = evaluate_accuracy_gpu(net, test_iter)\n        animator.add(epoch + 1, (None, None, test_acc))\n    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n          f'test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n          f'on {str(device)}')\n\nclass Residual(nn.Layer):\n    def __init__(self, input_channels, num_channels, use_1x1conv=False,\n                 strides=1):\n        super(Residual, self).__init__()\n        self.conv1 = nn.Conv2D(input_channels, num_channels, kernel_size=3,\n                               padding=1, stride=strides)\n        self.conv2 = nn.Conv2D(num_channels, num_channels, kernel_size=3,\n                               padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.Conv2D(input_channels, num_channels,\n                                   kernel_size=1, stride=strides)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm2D(num_channels)\n        self.bn2 = nn.BatchNorm2D(num_channels)\n        self.relu = nn.ReLU()\n\n    def forward(self, X):\n        Y = F.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        if self.conv3:\n            X = self.conv3(X)\n        Y += X\n        return F.relu(Y)\n\nd2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt',\n                                '090b5e7e70c295757f55df93cb0a180b9691891a')\n\ndef read_time_machine():\n    \"\"\"将时间机器数据集加载到文本行的列表中\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    with open(d2l.download('time_machine'), 'r') as f:\n        lines = f.readlines()\n    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n\ndef tokenize(lines, token='word'):\n    \"\"\"将文本行拆分为单词或字符词元\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    if token == 'word':\n        return [line.split() for line in lines]\n    elif token == 'char':\n        return [list(line) for line in lines]\n    else:\n        print('错误：未知词元类型：' + token)\n\nclass Vocab:\n    \"\"\"文本词表\"\"\"\n    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n        \"\"\"Defined in :numref:`sec_text_preprocessing`\"\"\"\n        if tokens is None:\n            tokens = []\n        if reserved_tokens is None:\n            reserved_tokens = []\n        # 按出现频率排序\n        counter = count_corpus(tokens)\n        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                   reverse=True)\n        # 未知词元的索引为0\n        self.idx_to_token = ['<unk>'] + reserved_tokens\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n        for token, freq in self._token_freqs:\n            if freq < min_freq:\n                break\n            if token not in self.token_to_idx:\n                self.idx_to_token.append(token)\n                self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\n    @property\n    def unk(self):  # 未知词元的索引为0\n        return 0\n\n    @property\n    def token_freqs(self):\n        return self._token_freqs\n\ndef count_corpus(tokens):\n    \"\"\"统计词元的频率\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    # 这里的tokens是1D列表或2D列表\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        # 将词元列表展平成一个列表\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)\n\ndef load_corpus_time_machine(max_tokens=-1):\n    \"\"\"返回时光机器数据集的词元索引列表和词表\n\n    Defined in :numref:`sec_text_preprocessing`\"\"\"\n    lines = read_time_machine()\n    tokens = tokenize(lines, 'char')\n    vocab = Vocab(tokens)\n    # 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，\n    # 所以将所有文本行展平到一个列表中\n    corpus = [vocab[token] for line in tokens for token in line]\n    if max_tokens > 0:\n        corpus = corpus[:max_tokens]\n    return corpus, vocab\n\ndef seq_data_iter_random(corpus, batch_size, num_steps):\n    \"\"\"使用随机抽样生成一个小批量子序列\n\n    Defined in :numref:`sec_language_model`\"\"\"\n    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1\n    corpus = corpus[random.randint(0, num_steps - 1):]\n    # 减去1，是因为我们需要考虑标签\n    num_subseqs = (len(corpus) - 1) // num_steps\n    # 长度为num_steps的子序列的起始索引\n    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n    # 在随机抽样的迭代过程中，\n    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻\n    random.shuffle(initial_indices)\n\n    def data(pos):\n        # 返回从pos位置开始的长度为num_steps的序列\n        return corpus[pos: pos + num_steps]\n\n    num_batches = num_subseqs // batch_size\n    for i in range(0, batch_size * num_batches, batch_size):\n        # 在这里，initial_indices包含子序列的随机起始索引\n        initial_indices_per_batch = initial_indices[i: i + batch_size]\n        X = [data(j) for j in initial_indices_per_batch]\n        Y = [data(j + 1) for j in initial_indices_per_batch]\n        yield d2l.tensor(X), d2l.tensor(Y)\n\ndef seq_data_iter_sequential(corpus, batch_size, num_steps):\n    \"\"\"使用顺序分区生成一个小批量子序列\n\n    Defined in :numref:`sec_language_model`\"\"\"\n    # 从随机偏移量开始划分序列\n    offset = random.randint(0, num_steps)\n    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n    Xs = d2l.tensor(corpus[offset: offset + num_tokens])\n    Ys = d2l.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n    Xs, Ys = Xs.reshape((batch_size, -1)), Ys.reshape((batch_size, -1))\n    num_batches = Xs.shape[1] // num_steps\n    for i in range(0, num_steps * num_batches, num_steps):\n        X = Xs[:, i: i + num_steps]\n        Y = Ys[:, i: i + num_steps]\n        yield X, Y\n\nclass SeqDataLoader:\n    \"\"\"加载序列数据的迭代器\"\"\"\n    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n        \"\"\"Defined in :numref:`sec_language_model`\"\"\"\n        if use_random_iter:\n            self.data_iter_fn = d2l.seq_data_iter_random\n        else:\n            self.data_iter_fn = d2l.seq_data_iter_sequential\n        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)\n        self.batch_size, self.num_steps = batch_size, num_steps\n\n    def __iter__(self):\n        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n\ndef load_data_time_machine(batch_size, num_steps,\n                           use_random_iter=False, max_tokens=10000):\n    \"\"\"返回时光机器数据集的迭代器和词表\n\n    Defined in :numref:`sec_language_model`\"\"\"\n    data_iter = SeqDataLoader(\n        batch_size, num_steps, use_random_iter, max_tokens)\n    return data_iter, data_iter.vocab\n\nclass RNNModelScratch:\n    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n    def __init__(self, vocab_size, num_hiddens,\n                 get_params, init_state, forward_fn):\n        \"\"\"Defined in :numref:`sec_rnn_scratch`\"\"\"\n        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n        self.params = get_params(vocab_size, num_hiddens)\n        self.init_state, self.forward_fn = init_state, forward_fn\n\n    def __call__(self, X, state):\n        X = F.one_hot(X.T, self.vocab_size)\n        return self.forward_fn(X, state, self.params)\n\n    def begin_state(self, batch_size):\n        return self.init_state(batch_size, self.num_hiddens)\n\ndef predict_ch8(prefix, num_preds, net, vocab, device):\n    \"\"\"在prefix后面生成新字符\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    state = net.begin_state(batch_size=1)\n    outputs = [vocab[prefix[0]]]\n    get_input = lambda: d2l.reshape(d2l.tensor(outputs[-1], place=device), (1, 1))\n    for y in prefix[1:]:  # 预热期\n        _, state = net(get_input(), state)\n        outputs.append(vocab[y])\n    for _ in range(num_preds):  # 预测num_preds步\n        y, state = net(get_input(), state)\n        outputs.append(int(paddle.reshape(paddle.argmax(y,axis=1),shape=[1])))\n    return ''.join([vocab.idx_to_token[i] for i in outputs])\n\ndef grad_clipping(net, theta):\n    \"\"\"裁剪梯度\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    if isinstance(net, nn.Layer):\n        params = [p for p in net.parameters() if not p.stop_gradient]\n    else:\n        params = net.params\n    norm = paddle.sqrt(sum(paddle.sum((p.grad ** 2)) for p in params))\n    if norm > theta:\n        with paddle.no_grad():\n            for param in params:\n                param.grad.set_value(param.grad * theta / norm)\n\ndef train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n    \"\"\"训练网络一个迭代周期（定义见第8章)\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    state, timer = None, d2l.Timer()\n    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n    for X, Y in train_iter:\n        if state is None or use_random_iter:\n            # 在第一次迭代或使用随机抽样时初始化state\n            state = net.begin_state(batch_size=X.shape[0])\n        else:\n            if isinstance(net, nn.Layer) and not isinstance(state, tuple):\n                # state对于nn.GRU是个张量\n                state.stop_gradient=True\n            else:\n                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n                for s in state:\n                    s.stop_gradient=True\n        y = paddle.reshape(Y.T,shape=[-1])\n        X = paddle.to_tensor(X, place=device)\n        y = paddle.to_tensor(y, place=device)\n        y_hat, state = net(X, state)\n        l = loss(y_hat, y).mean()\n        if isinstance(updater, paddle.optimizer.Optimizer):\n            updater.clear_grad()\n            l.backward()\n            grad_clipping(net, 1)\n            updater.step()\n        else:\n            l.backward()\n            grad_clipping(net, 1)\n            # 因为已经调用了mean函数\n            updater(batch_size=1)\n\n        metric.add(l * d2l.size(y), d2l.size(y))\n    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()\n\ndef train_ch8(net, train_iter, vocab, lr, num_epochs, device, use_random_iter=False):\n    \"\"\"训练模型（定义见第8章）\n\n    Defined in :numref:`sec_rnn_scratch`\"\"\"\n    loss = nn.CrossEntropyLoss()\n    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n                            legend=['train'], xlim=[10, num_epochs])\n    # 初始化\n    if isinstance(net, nn.Layer):\n        updater = paddle.optimizer.SGD(\n                learning_rate=lr, parameters=net.parameters())\n    else:\n        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n    # 训练和预测\n    for epoch in range(num_epochs):\n        ppl, speed = train_epoch_ch8(\n            net, train_iter, loss, updater, device, use_random_iter)\n        if (epoch + 1) % 10 == 0:\n            print(predict('time traveller'))\n            animator.add(epoch + 1, [ppl])\n    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n    print(predict('time traveller'))\n    print(predict('traveller'))\n\nclass RNNModel(nn.Layer):\n    \"\"\"循环神经网络模型\n\n    Defined in :numref:`sec_rnn-concise`\"\"\"\n    def __init__(self, rnn_layer, vocab_size, **kwargs):\n        super(RNNModel, self).__init__(**kwargs)\n        self.rnn = rnn_layer\n        self.vocab_size = vocab_size\n        self.num_hiddens = self.rnn.hidden_size\n        # 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1\n        if self.rnn.num_directions==1:\n            self.num_directions = 1\n            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)\n        else:\n            self.num_directions = 2\n            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)\n\n    def forward(self, inputs, state):\n        X = F.one_hot(inputs.T, self.vocab_size)\n        Y, state = self.rnn(X, state)\n        # 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)\n        # 它的输出形状是(时间步数*批量大小,词表大小)。\n        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n        return output, state\n\n    def begin_state(self, batch_size=1):\n        if not isinstance(self.rnn, nn.LSTM):\n            # nn.GRU以张量作为隐状态\n            return  paddle.zeros(shape=[self.num_directions * self.rnn.num_layers,\n                                                           batch_size, self.num_hiddens])\n        else:\n            # nn.LSTM以元组作为隐状态\n            return (paddle.zeros(\n                shape=[self.num_directions * self.rnn.num_layers,\n                batch_size, self.num_hiddens]),\n                    paddle.zeros(\n                        shape=[self.num_directions * self.rnn.num_layers,\n                        batch_size, self.num_hiddens]))\n\nd2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n\ndef read_data_nmt():\n    \"\"\"载入“英语－法语”数据集\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    data_dir = d2l.download_extract('fra-eng')\n    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n             encoding='utf-8') as f:\n        return f.read()\n\ndef preprocess_nmt(text):\n    \"\"\"预处理“英语－法语”数据集\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    def no_space(char, prev_char):\n        return char in set(',.!?') and prev_char != ' '\n\n    # 使用空格替换不间断空格\n    # 使用小写字母替换大写字母\n    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n    # 在单词和标点符号之间插入空格\n    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n           for i, char in enumerate(text)]\n    return ''.join(out)\n\ndef tokenize_nmt(text, num_examples=None):\n    \"\"\"词元化“英语－法语”数据数据集\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    source, target = [], []\n    for i, line in enumerate(text.split('\\n')):\n        if num_examples and i > num_examples:\n            break\n        parts = line.split('\\t')\n        if len(parts) == 2:\n            source.append(parts[0].split(' '))\n            target.append(parts[1].split(' '))\n    return source, target\n\ndef show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n    \"\"\"绘制列表长度对的直方图\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    d2l.set_figsize()\n    _, _, patches = d2l.plt.hist(\n        [[len(l) for l in xlist], [len(l) for l in ylist]])\n    d2l.plt.xlabel(xlabel)\n    d2l.plt.ylabel(ylabel)\n    for patch in patches[1].patches:\n        patch.set_hatch('/')\n    d2l.plt.legend(legend)\n\ndef truncate_pad(line, num_steps, padding_token):\n    \"\"\"截断或填充文本序列\n\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    if len(line) > num_steps:\n        return line[:num_steps]  # 截断\n    return line + [padding_token] * (num_steps - len(line))  # 填充\n\ndef build_array_nmt(lines, vocab, num_steps):\n    \"\"\"将机器翻译的文本序列转换成小批量\n\n    Defined in :numref:`subsec_mt_data_loading`\"\"\"\n    lines = [vocab[l] for l in lines]\n    lines = [l + [vocab['<eos>']] for l in lines]\n    array = d2l.tensor([truncate_pad(\n        l, num_steps, vocab['<pad>']) for l in lines])\n    valid_len = d2l.reduce_sum(\n        d2l.astype(array != vocab['<pad>'], d2l.int32), 1)\n    return array, valid_len\n\ndef load_data_nmt(batch_size, num_steps, num_examples=600):\n    \"\"\"返回翻译数据集的迭代器和词表\n\n    Defined in :numref:`subsec_mt_data_loading`\"\"\"\n    text = preprocess_nmt(read_data_nmt())\n    source, target = tokenize_nmt(text, num_examples)\n    src_vocab = d2l.Vocab(source, min_freq=2,\n                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n    tgt_vocab = d2l.Vocab(target, min_freq=2,\n                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n    data_iter = d2l.load_array(data_arrays, batch_size)\n    return data_iter, src_vocab, tgt_vocab\n\nclass Encoder(nn.Layer):\n    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n    def __init__(self, **kwargs):\n        super(Encoder, self).__init__(**kwargs)\n\n    def forward(self, X, *args):\n        raise NotImplementedError\n\nclass Decoder(nn.Layer):\n    \"\"\"编码器-解码器架构的基本解码器接口\n\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n    def __init__(self, **kwargs):\n        super(Decoder, self).__init__(**kwargs)\n\n    def init_state(self, enc_outputs, *args):\n        raise NotImplementedError\n\n    def forward(self, X, state):\n        raise NotImplementedError\n\nclass EncoderDecoder(nn.Layer):\n    \"\"\"编码器-解码器架构的基类\n\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n    def __init__(self, encoder, decoder, **kwargs):\n        super(EncoderDecoder, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, enc_X, dec_X, *args):\n        enc_outputs = self.encoder(enc_X, *args)\n        dec_state = self.decoder.init_state(enc_outputs, *args)\n        return self.decoder(dec_X, dec_state)\n\nclass Seq2SeqEncoder(d2l.Encoder):\n    \"\"\"用于序列到序列学习的循环神经网络编码器\n\n    Defined in :numref:`sec_seq2seq`\"\"\"\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0, **kwargs):\n        super(Seq2SeqEncoder, self).__init__(**kwargs)\n        weight_ih_attr = paddle.ParamAttr(initializer=nn.initializer.XavierUniform())\n        weight_hh_attr = paddle.ParamAttr(initializer=nn.initializer.XavierUniform())\n        # 嵌入层\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout,\n                          time_major=True, weight_ih_attr=weight_ih_attr, weight_hh_attr=weight_hh_attr)\n\n    def forward(self, X, *args):\n        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n        X = self.embedding(X)\n        # 在循环神经网络模型中，第一个轴对应于时间步\n        X = X.transpose([1, 0, 2])\n        # 如果未提及状态，则默认为0\n        output, state = self.rnn(X)\n        # PaddlePaddle的GRU层output的形状:(batch_size,time_steps,num_directions * num_hiddens),\n        # 需设定time_major=True,指定input的第一个维度为time_steps\n        # state[0]的形状:(num_layers,batch_size,num_hiddens)\n        return output, state\n\ndef sequence_mask(X, valid_len, value=0):\n    \"\"\"在序列中屏蔽不相关的项\n\n    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n    maxlen = X.shape[1]\n    mask = paddle.arange((maxlen), dtype=paddle.float32)[None, :] < valid_len[:, None]\n    Xtype = X.dtype\n    X = X.astype(paddle.float32)\n    X[~mask] = float(value)\n    return X.astype(Xtype)\n\nclass MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n    \"\"\"带遮蔽的softmax交叉熵损失函数\n\n    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n    # pred的形状：(batch_size,num_steps,vocab_size)\n    # label的形状：(batch_size,num_steps)\n    # valid_len的形状：(batch_size,)\n    def forward(self, pred, label, valid_len):\n        weights = paddle.ones_like(label)\n        weights = sequence_mask(weights, valid_len)\n        self.reduction='none'\n        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n            pred, label)\n        weighted_loss = (unweighted_loss * weights).mean(axis=1)\n        return weighted_loss\n\ndef train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n    \"\"\"训练序列到序列模型\n\n    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n    optimizer = paddle.optimizer.Adam(learning_rate=lr, parameters=net.parameters())\n    loss = MaskedSoftmaxCELoss()\n    net.train()\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n                     xlim=[10, num_epochs])\n    for epoch in range(num_epochs):\n        timer = d2l.Timer()\n        metric = d2l.Accumulator(2)  # 训练损失总和，词元数量\n        for batch in data_iter:\n            optimizer.clear_grad()\n            X, X_valid_len, Y, Y_valid_len = [paddle.to_tensor(x, place=device) for x in batch]\n            bos = paddle.to_tensor([tgt_vocab['<bos>']] * Y.shape[0]).reshape([-1, 1])\n            dec_input = paddle.concat([bos, Y[:, :-1]], 1)  # 强制教学\n            Y_hat, _ = net(X, dec_input, X_valid_len.squeeze())\n            l = loss(Y_hat, Y, Y_valid_len.squeeze())\n            l.backward()\t# 损失函数的标量进行“反向传播”\n            d2l.grad_clipping(net, 1)\n            num_tokens = Y_valid_len.sum()\n            optimizer.step()\n            with paddle.no_grad():\n                metric.add(l.sum(), num_tokens)\n        if (epoch + 1) % 10 == 0:\n            animator.add(epoch + 1, (metric[0] / metric[1],))\n    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n        f'tokens/sec on {str(device)}')\n\ndef predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n                    device, save_attention_weights=False):\n    \"\"\"序列到序列模型的预测\n\n    Defined in :numref:`sec_seq2seq_training`\"\"\"\n    # 在预测时将net设置为评估模式\n    net.eval()\n    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n        src_vocab['<eos>']]\n    enc_valid_len = paddle.to_tensor([len(src_tokens)], place=device)\n    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n    # 添加批量轴\n    enc_X = paddle.unsqueeze(\n        paddle.to_tensor(src_tokens, dtype=paddle.int64, place=device), axis=0)\n    enc_outputs = net.encoder(enc_X, enc_valid_len)\n    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n    # 添加批量轴\n    dec_X = paddle.unsqueeze(paddle.to_tensor(\n        [tgt_vocab['<bos>']], dtype=paddle.int64, place=device), axis=0)\n    output_seq, attention_weight_seq = [], []\n    for _ in range(num_steps):\n        Y, dec_state = net.decoder(dec_X, dec_state)\n        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n        dec_X = Y.argmax(axis=2)\n        pred = dec_X.squeeze(axis=0).astype(paddle.int32).item()\n        # 保存注意力权重（稍后讨论）\n        if save_attention_weights:\n            attention_weight_seq.append(net.decoder.attention_weights)\n        # 一旦序列结束词元被预测，输出序列的生成就完成了\n        if pred == tgt_vocab['<eos>']:\n            break\n        output_seq.append(pred)\n    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n\ndef bleu(pred_seq, label_seq, k):\n    \"\"\"计算BLEU\n\n    Defined in :numref:`sec_seq2seq_training`\"\"\"\n    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n    len_pred, len_label = len(pred_tokens), len(label_tokens)\n    score = math.exp(min(0, 1 - len_label / len_pred))\n    for n in range(1, k + 1):\n        num_matches, label_subs = 0, collections.defaultdict(int)\n        for i in range(len_label - n + 1):\n            label_subs[' '.join(label_tokens[i: i + n])] += 1\n        for i in range(len_pred - n + 1):\n            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n                num_matches += 1\n                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n    return score\n\ndef show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n                  cmap='Reds'):\n    \"\"\"显示矩阵热图\n\n    Defined in :numref:`sec_attention-cues`\"\"\"\n    d2l.use_svg_display()\n    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize,\n                                 sharex=True, sharey=True, squeeze=False)\n    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n            pcm = ax.imshow(d2l.numpy(matrix), cmap=cmap)\n            if i == num_rows - 1:\n                ax.set_xlabel(xlabel)\n            if j == 0:\n                ax.set_ylabel(ylabel)\n            if titles:\n                ax.set_title(titles[j])\n    fig.colorbar(pcm, ax=axes, shrink=0.6);\n\ndef masked_softmax(X, valid_lens):\n    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\n\n    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n    # X:3D张量，valid_lens:1D或2D张量\n    if valid_lens is None:\n        return nn.functional.softmax(X, axis=-1)\n    else:\n        shape = X.shape\n        if valid_lens.dim() == 1:\n            valid_lens = paddle.repeat_interleave(valid_lens, shape[1])\n        else:\n            valid_lens = valid_lens.reshape((-1,))\n        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n        X = d2l.sequence_mask(X.reshape((-1, shape[-1])), valid_lens,\n                              value=-1e6)\n        return nn.functional.softmax(X.reshape(shape), axis=-1)\n\nclass AdditiveAttention(nn.Layer):\n    \"\"\"加性注意力\n\n    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n        super(AdditiveAttention, self).__init__(**kwargs)\n        self.W_k = nn.Linear(key_size, num_hiddens, bias_attr=False)\n        self.W_q = nn.Linear(query_size, num_hiddens, bias_attr=False)\n        self.w_v = nn.Linear(num_hiddens, 1, bias_attr=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, queries, keys, values, valid_lens):\n        queries, keys = self.W_q(queries), self.W_k(keys)\n        # 在维度扩展后，\n        # queries的形状：(batch_size，查询的个数，1，num_hidden)\n        # key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)\n        # 使用广播方式进行求和\n        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n        features = paddle.tanh(features)\n        # self.w_v仅有一个输出，因此从形状中移除最后那个维度。\n        # scores的形状：(batch_size，查询的个数，“键-值”对的个数)\n        scores = self.w_v(features).squeeze(-1)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        # values的形状：(batch_size，“键－值”对的个数，值的维度)\n        return paddle.bmm(self.dropout(self.attention_weights), values)\n\nclass DotProductAttention(nn.Layer):\n    \"\"\"缩放点积注意力\n\n    Defined in :numref:`subsec_additive-attention`\"\"\"\n    def __init__(self, dropout, **kwargs):\n        super(DotProductAttention, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n\n    # queries的形状：(batch_size，查询的个数，d)\n    # keys的形状：(batch_size，“键－值”对的个数，d)\n    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n    def forward(self, queries, keys, values, valid_lens=None):\n        d = queries.shape[-1]\n        # 设置transpose_b=True为了交换keys的最后两个维度\n        scores = paddle.bmm(queries, keys.transpose((0,2,1))) / math.sqrt(d)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        return paddle.bmm(self.dropout(self.attention_weights), values)\n\nclass AttentionDecoder(d2l.Decoder):\n    \"\"\"带有注意力机制解码器的基本接口\n\n    Defined in :numref:`sec_seq2seq_attention`\"\"\"\n    def __init__(self, **kwargs):\n        super(AttentionDecoder, self).__init__(**kwargs)\n\n    @property\n    def attention_weights(self):\n        raise NotImplementedError\n\nclass MultiHeadAttention(nn.Layer):\n    \"\"\"Defined in :numref:`sec_multihead-attention`\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n                 num_heads, dropout, bias=False, **kwargs):\n        super(MultiHeadAttention, self).__init__(**kwargs)\n        self.num_heads = num_heads\n        self.attention = d2l.DotProductAttention(dropout)\n        self.W_q = nn.Linear(query_size, num_hiddens, bias_attr=bias)\n        self.W_k = nn.Linear(key_size, num_hiddens, bias_attr=bias)\n        self.W_v = nn.Linear(value_size, num_hiddens, bias_attr=bias)\n        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias_attr=bias)\n\n    def forward(self, queries, keys, values, valid_lens):\n        # queries，keys，values的形状:\n        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n        # valid_lens　的形状:\n        # (batch_size，)或(batch_size，查询的个数)\n        # 经过变换后，输出的queries，keys，values　的形状:\n        # (batch_size*num_heads，查询或者“键－值”对的个数，\n        # num_hiddens/num_heads)\n        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n        values = transpose_qkv(self.W_v(values), self.num_heads)\n        if valid_lens is not None:\n            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n            # 然后如此复制第二项，然后诸如此类。\n            valid_lens = paddle.repeat_interleave(\n                valid_lens, repeats=self.num_heads, axis=0)\n\n        # output的形状:(batch_size*num_heads，查询的个数，\n        # num_hiddens/num_heads)\n        output = self.attention(queries, keys, values, valid_lens)\n\n        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n        output_concat = transpose_output(output, self.num_heads)\n        return self.W_o(output_concat)\n\ndef transpose_qkv(X, num_heads):\n    \"\"\"为了多注意力头的并行计算而变换形状\n\n    Defined in :numref:`sec_multihead-attention`\"\"\"\n    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n    # num_hiddens/num_heads)\n    X = X.reshape((X.shape[0], X.shape[1], num_heads, -1))\n\n    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n    # num_hiddens/num_heads)\n    X = X.transpose((0, 2, 1, 3))\n\n    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n    # num_hiddens/num_heads)\n    return X.reshape((-1, X.shape[2], X.shape[3]))\n\n\ndef transpose_output(X, num_heads):\n    \"\"\"逆转transpose_qkv函数的操作\n\n    Defined in :numref:`sec_multihead-attention`\"\"\"\n    X = X.reshape((-1, num_heads, X.shape[1], X.shape[2]))\n    X = X.transpose((0, 2, 1, 3))\n    return X.reshape((X.shape[0], X.shape[1], -1))\n\nclass PositionalEncoding(nn.Layer):\n    \"\"\"位置编码\n\n    Defined in :numref:`sec_self-attention-and-positional-encoding`\"\"\"\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        # 创建一个足够长的P\n        self.P = paddle.zeros((1, max_len, num_hiddens))\n        X = paddle.arange(max_len, dtype=paddle.float32).reshape(\n            (-1, 1)) / paddle.pow(paddle.to_tensor([10000.0]), paddle.arange(\n            0, num_hiddens, 2, dtype=paddle.float32) / num_hiddens)\n        self.P[:, :, 0::2] = paddle.sin(X)\n        self.P[:, :, 1::2] = paddle.cos(X)\n\n    def forward(self, X):\n        X = X + self.P[:, :X.shape[1], :]\n        return self.dropout(X)\n\nclass PositionWiseFFN(nn.Layer):\n    \"\"\"基于位置的前馈网络\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n                 **kwargs):\n        super(PositionWiseFFN, self).__init__(**kwargs)\n        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))\n\nclass AddNorm(nn.Layer):\n    \"\"\"残差连接后进行层规范化\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, normalized_shape, dropout, **kwargs):\n        super(AddNorm, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm(normalized_shape)\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)\n\nclass EncoderBlock(nn.Layer):\n    \"\"\"transformer编码器块\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n                 dropout, use_bias=False, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n        self.attention = d2l.MultiHeadAttention(\n            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n            use_bias)\n        self.addnorm1 = AddNorm(norm_shape, dropout)\n        self.ffn = PositionWiseFFN(\n            ffn_num_input, ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = AddNorm(norm_shape, dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n        return self.addnorm2(Y, self.ffn(Y))\n\nclass TransformerEncoder(d2l.Encoder):\n    \"\"\"transformer编码器\n\n    Defined in :numref:`sec_transformer`\"\"\"\n    def __init__(self, vocab_size, key_size, query_size, value_size,\n                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_layers):\n            self.blks.add_sublayer(str(i),\n                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n                             norm_shape, ffn_num_input, ffn_num_hiddens,\n                             num_heads, dropout, use_bias))\n\n    def forward(self, X, valid_lens, *args):\n        # 因为位置编码值在-1和1之间，\n        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n        # 然后再与位置编码相加。\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens)\n            self.attention_weights[\n                i] = blk.attention.attention.attention_weights\n        return X\n\ndef annotate(text, xy, xytext):\n    d2l.plt.gca().annotate(text, xy=xy, xytext=xytext,\n                           arrowprops=dict(arrowstyle='->'))\n\ndef train_2d(trainer, steps=20, f_grad=None):\n    \"\"\"用定制的训练机优化2D目标函数\n\n    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n    # s1和s2是稍后将使用的内部状态变量\n    x1, x2, s1, s2 = -5, -2, 0, 0\n    results = [(x1, x2)]\n    for i in range(steps):\n        if f_grad:\n            x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)\n        else:\n            x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n        results.append((x1, x2))\n    print(f'epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n    return results\n\ndef show_trace_2d(f, results):\n    \"\"\"显示优化过程中2D变量的轨迹\n\n    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n    d2l.set_figsize()\n    d2l.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n    x1, x2 = d2l.meshgrid(d2l.arange(-5.5, 1.0, 0.1, dtype='float32'),\n                          d2l.arange(-3.0, 1.0, 0.1, dtype='float32'))\n    d2l.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n    d2l.plt.xlabel('x1')\n    d2l.plt.ylabel('x2')\n\nd2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat',\n                           '76e5be1548fd8222e5074cf0faae75edff8cf93f')\n\ndef get_data_ch11(batch_size=10, n=1500):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    data = np.genfromtxt(d2l.download('airfoil'),\n                         dtype=np.float32, delimiter='\\t')\n    data = d2l.tensor((data - data.mean(axis=0)) / data.std(axis=0))\n    data_iter = d2l.load_array((data[:n, :-1], data[:n, -1]),\n                               batch_size, is_train=True)\n    return data_iter, data.shape[1]-1\n\ndef train_ch11(trainer_fn, states, hyperparams, data_iter,\n               feature_dim, num_epochs=2):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    # 初始化模型\n    w = d2l.tensor(d2l.normal(mean=0.0, std=0.01, shape=(feature_dim, 1)), stop_gradient=False)\n    b = d2l.tensor(d2l.zeros((1,)), stop_gradient=False)\n    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n    # 训练模型\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n    n, timer = 0, d2l.Timer()\n    for _ in range(num_epochs):\n        for X, y in data_iter:\n            l = loss(net(X), y).mean()\n            l.backward()\n            w, b = trainer_fn([w, b], states, hyperparams)\n            n += X.shape[0]\n            if n % 200 == 0:\n                timer.stop()\n                animator.add(n/X.shape[0]/len(data_iter),\n                             (d2l.evaluate_loss(net, data_iter, loss),))\n                timer.start()\n    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')\n    return timer.cumsum(), animator.Y[0]\n\ndef train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    # 初始化模型\n    net = nn.Sequential(nn.Linear(5, 1))\n    def init_weights(m):\n        if type(m) == nn.Linear:\n            paddle.nn.initializer.Normal(m.weight, std=0.01)\n\n    net.apply(init_weights)\n\n    optimizer = trainer_fn(parameters=net.parameters(), **hyperparams)\n    loss = nn.MSELoss(reduction='none')\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n    n, timer = 0, d2l.Timer()\n    for _ in range(num_epochs):\n        for X, y in data_iter:\n            optimizer.clear_grad()\n            out = net(X)\n            y = y.reshape(out.shape)\n            l = loss(out, y)\n            l.mean().backward()\n            optimizer.step()\n            n += X.shape[0]\n            if n % 200 == 0:\n                timer.stop()\n                # MSELoss计算平方误差时不带系数1/2\n                animator.add(n/X.shape[0]/len(data_iter),\n                             (d2l.evaluate_loss(net, data_iter, loss) / 2,))\n                timer.start()\n    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')\n\nclass Benchmark:\n    \"\"\"用于测量运行时间\"\"\"\n    def __init__(self, description='Done'):\n        \"\"\"Defined in :numref:`sec_hybridize`\"\"\"\n        self.description = description\n\n    def __enter__(self):\n        self.timer = d2l.Timer()\n        return self\n\n    def __exit__(self, *args):\n        print(f'{self.description}: {self.timer.stop():.4f} sec')\n\ndef split_batch(X, y, devices):\n    \"\"\"将X和y拆分到多个设备上\n\n    Defined in :numref:`sec_multi_gpu`\"\"\"\n    assert X.shape[0] == y.shape[0]\n    return (paddlescatter(X, devices),\n            paddlescatter(y, devices))\n\ndef resnet18(num_classes, in_channels=1):\n    \"\"\"稍加修改的ResNet-18模型\n\n    Defined in :numref:`sec_multi_gpu_concise`\"\"\"\n    def resnet_block(in_channels, out_channels, num_residuals,\n                     first_block=False):\n        blk = []\n        for i in range(num_residuals):\n            if i == 0 and not first_block:\n                blk.append(d2l.Residual(in_channels, out_channels,\n                                        use_1x1conv=True, strides=2))\n            else:\n                blk.append(d2l.Residual(out_channels, out_channels))\n        return nn.Sequential(*blk)\n\n    # 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层\n    net = nn.Sequential(\n        nn.Conv2D(in_channels, 64, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2D(64),\n        nn.ReLU())\n    net.add_sublayer(\"resnet_block1\", resnet_block(\n        64, 64, 2, first_block=True))\n    net.add_sublayer(\"resnet_block2\", resnet_block(64, 128, 2))\n    net.add_sublayer(\"resnet_block3\", resnet_block(128, 256, 2))\n    net.add_sublayer(\"resnet_block4\", resnet_block(256, 512, 2))\n    net.add_sublayer(\"global_avg_pool\", nn.AdaptiveAvgPool2D((1, 1)))\n    net.add_sublayer(\"fc\", nn.Sequential(nn.Flatten(),\n                                         nn.Linear(512, num_classes)))\n    return net\n\ndef train_batch_ch13(net, X, y, loss, trainer, devices):\n    \"\"\"Defined in :numref:`sec_image_augmentation`\"\"\"\n    \"\"\"用多GPU进行小批量训练\n    飞桨不支持在notebook上进行多GPU训练\n    Defined in :numref:`sec_image_augmentation`\"\"\"\n    if isinstance(X, list):\n        # 微调BERT中所需（稍后讨论）\n        X = [paddle.to_tensor(x, place=devices[0]) for x in X]\n    else:\n        X = paddle.to_tensor(X, place=devices[0])\n    y = paddle.to_tensor(y, place=devices[0])\n    net.train()\n    trainer.clear_grad()\n    pred = net(X)\n    l = loss(pred, y)\n    l.sum().backward()\n    trainer.step()\n    train_loss_sum = l.sum()\n    train_acc_sum = d2l.accuracy(pred, y)\n    return train_loss_sum, train_acc_sum\n\ndef train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n               devices=d2l.try_all_gpus()):\n    \"\"\"Defined in :numref:`sec_image_augmentation`\"\"\"\n    \"\"\"用多GPU进行模型训练\n    Defined in :numref:`sec_image_augmentation`\"\"\"\n    timer, num_batches = d2l.Timer(), len(train_iter)\n    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n                            legend=['train loss', 'train acc', 'test acc'])\n    net = paddle.DataParallel(net)\n    for epoch in range(num_epochs):\n        # 4个维度：储存训练损失，训练准确度，实例数，特点数\n        metric = d2l.Accumulator(4)\n        for i, (features, labels) in enumerate(train_iter):\n            timer.start()\n            l, acc = train_batch_ch13(\n                net, features, labels, loss, trainer, devices)\n            metric.add(l, acc, labels.shape[0], labels.numel())\n            timer.stop()\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (metric[0] / metric[2], metric[1] / metric[3],\n                              None))\n        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)\n        animator.add(epoch + 1, (None, None, test_acc))\n    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n          f'{str(devices)}')\n\nd2l.DATA_HUB['hotdog'] = (d2l.DATA_URL + 'hotdog.zip',\n                         'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n\ndef box_corner_to_center(boxes):\n    \"\"\"从（左上，右下）转换到（中间，宽度，高度）\n\n    Defined in :numref:`sec_bbox`\"\"\"\n    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    cx = (x1 + x2) / 2\n    cy = (y1 + y2) / 2\n    w = x2 - x1\n    h = y2 - y1\n    boxes = d2l.stack((cx, cy, w, h), axis=-1)\n    return boxes\n\ndef box_center_to_corner(boxes):\n    \"\"\"从（中间，宽度，高度）转换到（左上，右下）\n\n    Defined in :numref:`sec_bbox`\"\"\"\n    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    x1 = cx - 0.5 * w\n    y1 = cy - 0.5 * h\n    x2 = cx + 0.5 * w\n    y2 = cy + 0.5 * h\n    boxes = d2l.stack((x1, y1, x2, y2), axis=-1)\n    return boxes\n\ndef bbox_to_rect(bbox, color):\n    \"\"\"Defined in :numref:`sec_bbox`\"\"\"\n    # 将边界框(左上x,左上y,右下x,右下y)格式转换成matplotlib格式：\n    # ((左上x,左上y),宽,高)\n    return d2l.plt.Rectangle(\n        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],\n        fill=False, edgecolor=color, linewidth=2)\n\ndef multibox_prior(data, sizes, ratios):\n    \"\"\"生成以每个像素为中心具有不同形状的锚框\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    in_height, in_width = data.shape[-2:]\n    place, num_sizes, num_ratios = data.place, len(sizes), len(ratios)\n    boxes_per_pixel = (num_sizes + num_ratios - 1)\n    size_tensor = paddle.to_tensor(sizes, place=place)\n    ratio_tensor = paddle.to_tensor(ratios, place=place)\n\n    # 为了将锚点移动到像素的中心，需要设置偏移量。\n    # 因为一个像素的的高为1且宽为1，我们选择偏移我们的中心0.5\n    offset_h, offset_w = 0.5, 0.5\n    steps_h = 1.0 / in_height  # 在y轴上缩放步长\n    steps_w = 1.0 / in_width  # 在x轴上缩放步长\n\n    # 生成锚框的所有中心点\n    center_h = (paddle.arange(in_height) + offset_h) * steps_h\n    center_w = (paddle.arange(in_width) + offset_w) * steps_w\n    shift_y, shift_x = paddle.meshgrid(center_h, center_w)\n    shift_y, shift_x = shift_y.reshape([-1]), shift_x.reshape([-1])\n\n    # 生成“boxes_per_pixel”个高和宽，\n    # 之后用于创建锚框的四角坐标(xmin,xmax,ymin,ymax)\n    w = paddle.concat((size_tensor * paddle.sqrt(ratio_tensor[0]),\n                       sizes[0] * paddle.sqrt(ratio_tensor[1:])))\\\n                       * in_height / in_width  # 处理矩形输入\n    h = paddle.concat((size_tensor / paddle.sqrt(ratio_tensor[0]),\n                   sizes[0] / paddle.sqrt(ratio_tensor[1:])))\n    # 除以2来获得半高和半宽\n    anchor_manipulations = paddle.tile(paddle.stack((-w, -h, w, h)).T,\n                                        (in_height * in_width, 1)) / 2\n\n    # 每个中心点都将有“boxes_per_pixel”个锚框，\n    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n    out_grid = paddle.stack([shift_x, shift_y, shift_x, shift_y], axis=1)\n    out_grid = paddle.tile(out_grid, repeat_times=[boxes_per_pixel]).reshape((-1, out_grid.shape[1]))\n    output = out_grid + anchor_manipulations\n    return output.unsqueeze(0)\n\ndef show_bboxes(axes, bboxes, labels=None, colors=None):\n    \"\"\"显示所有边界框\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    def _make_list(obj, default_values=None):\n        if obj is None:\n            obj = default_values\n        elif not isinstance(obj, (list, tuple)):\n            obj = [obj]\n        return obj\n\n    labels = _make_list(labels)\n    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n    for i, bbox in enumerate(bboxes):\n        color = colors[i % len(colors)]\n        rect = d2l.bbox_to_rect(d2l.numpy(bbox), color)\n        axes.add_patch(rect)\n        if labels and len(labels) > i:\n            text_color = 'k' if color == 'w' else 'w'\n            axes.text(rect.xy[0], rect.xy[1], labels[i],\n                      va='center', ha='center', fontsize=9, color=text_color,\n                      bbox=dict(facecolor=color, lw=0))\n\ndef box_iou(boxes1, boxes2):\n    \"\"\"计算两个锚框或边界框列表中成对的交并比\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n                              (boxes[:, 3] - boxes[:, 1]))\n    # boxes1,boxes2,areas1,areas2的形状:\n    # boxes1：(boxes1的数量,4),\n    # boxes2：(boxes2的数量,4),\n    # areas1：(boxes1的数量,),\n    # areas2：(boxes2的数量,)\n    areas1 = box_area(boxes1)\n    areas2 = box_area(boxes2)\n    # inter_upperlefts,inter_lowerrights,inters的形状:\n    # (boxes1的数量,boxes2的数量,2)\n    inter_upperlefts = paddle.maximum(boxes1[:, None, :2], boxes2[:, :2])\n    inter_lowerrights = paddle.minimum(boxes1[:, None, 2:], boxes2[:, 2:])\n    inters = (inter_lowerrights - inter_upperlefts).clip(min=0)\n    # inter_areasandunion_areas的形状:(boxes1的数量,boxes2的数量)\n    inter_areas = inters[:, :, 0] * inters[:, :, 1]\n    union_areas = areas1[:, None] + areas2 - inter_areas\n    return inter_areas / union_areas\n\ndef assign_anchor_to_bbox(ground_truth, anchors, place, iou_threshold=0.5):\n    \"\"\"将最接近的真实边界框分配给锚框\n\n    Defined in :numref:`sec_anchor`\"\"\"\n    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]\n    # 位于第i行和第j列的元素x_ij是锚框i和真实边界框j的IoU\n    jaccard = box_iou(anchors, ground_truth)\n    # 对于每个锚框，分配的真实边界框的张量\n    anchors_bbox_map = paddle.full((num_anchors,), -1, dtype=paddle.int64)\n    # 根据阈值，决定是否分配真实边界框\n    max_ious = paddle.max(jaccard, axis=1)\n    indices = paddle.argmax(jaccard, axis=1)\n    anc_i = paddle.nonzero(max_ious >= 0.5).reshape([-1])\n    box_j = indices[max_ious >= 0.5]\n    anchors_bbox_map[anc_i] = box_j\n    col_discard = paddle.full((num_anchors,), -1)\n    row_discard = paddle.full((num_gt_boxes,), -1)\n    for _ in range(num_gt_boxes):\n        max_idx = paddle.argmax(jaccard)\n        box_idx = paddle.cast((max_idx % num_gt_boxes), dtype='int64')\n        anc_idx = paddle.cast((max_idx / num_gt_boxes), dtype='int64')\n        anchors_bbox_map[anc_idx] = box_idx\n        jaccard[:, box_idx] = col_discard\n        jaccard[anc_idx, :] = row_discard\n    return anchors_bbox_map\n\ndef offset_boxes(anchors, assigned_bb, eps=1e-6):\n    \"\"\"对锚框偏移量的转换\n\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    c_anc = d2l.box_corner_to_center(anchors)\n    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)\n    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]\n    offset_wh = 5 * d2l.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])\n    offset = d2l.concat([offset_xy, offset_wh], axis=1)\n    return offset\n\ndef multibox_target(anchors, labels):\n    \"\"\"使用真实边界框标记锚框\n\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    batch_size, anchors = labels.shape[0], anchors.squeeze(0)\n    batch_offset, batch_mask, batch_class_labels = [], [], []\n    place, num_anchors = anchors.place, anchors.shape[0]\n    for i in range(batch_size):\n        label = labels[i, :, :]\n        anchors_bbox_map = assign_anchor_to_bbox(\n            label[:, 1:], anchors, place)\n        bbox_mask = paddle.tile(paddle.to_tensor((anchors_bbox_map >= 0), dtype='float32').unsqueeze(-1), (1, 4))\n        # 将类标签和分配的边界框坐标初始化为零\n        class_labels = paddle.zeros(paddle.to_tensor(num_anchors), dtype=paddle.int64)\n        assigned_bb = paddle.zeros(paddle.to_tensor((num_anchors, 4)), dtype=paddle.float32)\n        # 使用真实边界框来标记锚框的类别。\n        # 如果一个锚框没有被分配，我们标记其为背景（值为零）\n        indices_true = paddle.nonzero(anchors_bbox_map >= 0).numpy()\n        bb_idx = anchors_bbox_map[indices_true].numpy()\n        class_labels[indices_true] = label.numpy()[bb_idx, 0][:] + 1\n        assigned_bb[indices_true] = label.numpy()[bb_idx, 1:]\n        class_labels = paddle.to_tensor(class_labels)\n        assigned_bb = paddle.to_tensor(assigned_bb)\n        # 偏移量转换\n        offset = offset_boxes(anchors, assigned_bb) * bbox_mask\n        batch_offset.append(offset.reshape([-1]))\n        batch_mask.append(bbox_mask.reshape([-1]))\n        batch_class_labels.append(class_labels)\n    bbox_offset = paddle.stack(batch_offset)\n    bbox_mask = paddle.stack(batch_mask)\n    class_labels = paddle.stack(batch_class_labels)\n    return (bbox_offset, bbox_mask, class_labels)\n\ndef offset_inverse(anchors, offset_preds):\n    \"\"\"根据带有预测偏移量的锚框来预测边界框\n\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    anc = d2l.box_corner_to_center(anchors)\n    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]\n    pred_bbox_wh = d2l.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]\n    pred_bbox = d2l.concat((pred_bbox_xy, pred_bbox_wh), axis=1)\n    predicted_bbox = d2l.box_center_to_corner(pred_bbox)\n    return predicted_bbox\n\ndef nms(boxes, scores, iou_threshold):\n    \"\"\"对预测边界框的置信度进行排序\n\n    Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"\n    B = paddle.argsort(scores, axis=-1, descending=True)\n    keep = []  # 保留预测边界框的指标\n    while B.numel().item() > 0:\n        i = B[0]\n        keep.append(i.item())\n        if B.numel().item() == 1: break\n        iou = box_iou(boxes[i.numpy(), :].reshape([-1, 4]),\n                      paddle.to_tensor(boxes.numpy()[B[1:].numpy(), :]).reshape([-1, 4])).reshape([-1])\n        inds = paddle.nonzero(iou <= iou_threshold).numpy().reshape([-1])\n        B = paddle.to_tensor(B.numpy()[inds + 1])\n    return paddle.to_tensor(keep, place=boxes.place, dtype='int64')\n\ndef multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,\n                       pos_threshold=0.009999999):\n    \"\"\"使用非极大值抑制来预测边界框\n\n    Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"\n    batch_size = cls_probs.shape[0]\n    anchors = anchors.squeeze(0)\n    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]\n    out = []\n    for i in range(batch_size):\n        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape([-1, 4])\n        conf = paddle.max(cls_prob[1:], 0)\n        class_id = paddle.argmax(cls_prob[1:], 0)\n        predicted_bb = offset_inverse(anchors, offset_pred)\n        keep = nms(predicted_bb, conf, nms_threshold)\n\n        # 找到所有的non_keep索引，并将类设置为背景\n        all_idx = paddle.arange(num_anchors, dtype='int64')\n        combined = paddle.concat((keep, all_idx))\n        uniques, counts = combined.unique(return_counts=True)\n        non_keep = uniques[counts == 1]\n        all_id_sorted = paddle.concat([keep, non_keep])\n        class_id[non_keep.numpy()] = -1\n        class_id = class_id[all_id_sorted]\n        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]\n        # pos_threshold是一个用于非背景预测的阈值\n        below_min_idx = (conf < pos_threshold)\n        class_id[below_min_idx.numpy()] = -1\n        conf[below_min_idx.numpy()] = 1 - conf[below_min_idx.numpy()]\n        pred_info = paddle.concat((paddle.to_tensor(class_id, dtype='float32').unsqueeze(1),\n                               paddle.to_tensor(conf, dtype='float32').unsqueeze(1),\n                               predicted_bb), axis=1)\n        out.append(pred_info)\n    return paddle.stack(out)\n\nd2l.DATA_HUB['banana-detection'] = (\n    d2l.DATA_URL + 'banana-detection.zip',\n    '5de26c8fce5ccdea9f91267273464dc968d20d72')\n\ndef read_data_bananas(is_train=True):\n    \"\"\"读取香蕉检测数据集中的图像和标签\n\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    data_dir = d2l.download_extract('banana-detection')\n    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train\n                             else 'bananas_val', 'label.csv')\n    csv_data = pd.read_csv(csv_fname)\n    csv_data = csv_data.set_index('img_name')\n    images, targets = [], []\n    for img_name, target in csv_data.iterrows():\n        paddle.vision.set_image_backend('cv2')\n        images.append(paddlevision.image_load(os.path.join(data_dir, 'bananas_train' if is_train else\n        'bananas_val', 'images', f'{img_name}'))[..., ::-1])\n        # 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y）\n        # 其中所有图像都具有相同的香蕉类（索引为0）\n        targets.append(list(target))\n    return images, paddle.to_tensor(targets).unsqueeze(1) / 256\n\nclass BananasDataset(paddle.io.Dataset):\n    \"\"\"一个用于加载香蕉检测数据集的自定义数据集\n\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    def __init__(self, is_train):\n        self.features, self.labels = read_data_bananas(is_train)\n        print('read ' + str(len(self.features)) + (f' training examples' if\n              is_train else f' validation examples'))\n\n    def __getitem__(self, idx):\n        return (paddle.to_tensor(self.features[idx], dtype='float32').transpose([2, 0, 1]), self.labels[idx])\n\n    def __len__(self):\n        return len(self.features)\n\ndef load_data_bananas(batch_size):\n    \"\"\"加载香蕉检测数据集\n\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    train_iter = paddle.io.DataLoader(BananasDataset(is_train=True),\n                                      batch_size=batch_size, return_list=True, shuffle=True)\n    val_iter = paddle.io.DataLoader(BananasDataset(is_train=False),\n                                    batch_size=batch_size, return_list=True)\n    return train_iter, val_iter\n\nd2l.DATA_HUB['voc2012'] = (d2l.DATA_URL + 'VOCtrainval_11-May-2012.tar',\n                           '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n\ndef read_voc_images(voc_dir, is_train=True):\n    \"\"\"Defined in :numref:`sec_semantic_segmentation`\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    \"\"\"读取所有VOC图像并标注\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',\n                             'train.txt' if is_train else 'val.txt')\n    with open(txt_fname, 'r') as f:\n        images = f.read().split()\n    features, labels = [], []\n    for i, fname in enumerate(images):\n        features.append(paddle.vision.image.image_load(os.path.join(\n            voc_dir, 'JPEGImages', f'{fname}.jpg'), backend='cv2')[..., ::-1].transpose(\n            [2, 0, 1]))\n        labels.append(paddle.vision.image.image_load(os.path.join(\n            voc_dir, 'SegmentationClass', f'{fname}.png'), backend='cv2')[..., ::-1].transpose(\n            [2, 0, 1]))\n    return features, labels\n\nVOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n                [0, 64, 128]]\n\nVOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n\ndef voc_colormap2label():\n    \"\"\"构建从RGB到VOC类别索引的映射\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    colormap2label = paddle.zeros([256 ** 3], dtype=paddle.int64)\n    for i, colormap in enumerate(VOC_COLORMAP):\n        colormap2label[\n            (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n    return colormap2label\n\ndef voc_label_indices(colormap, colormap2label):\n    \"\"\"将VOC标签中的RGB值映射到它们的类别索引\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    colormap = colormap.transpose([1, 2, 0]).astype('int32')\n    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n           + colormap[:, :, 2])\n    return colormap2label[idx]\n\ndef voc_rand_crop(feature, label, height, width):\n    \"\"\"随机裁剪特征和标签图像\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    rect = paddle.vision.transforms.RandomCrop((height, width))._get_param(\n        img=feature, output_size=(height, width))\n    feature = paddle.vision.transforms.crop(feature, *rect)\n    label = paddle.vision.transforms.crop(label, *rect)\n    return feature, label\n\nclass VOCSegDataset(paddle.io.Dataset):\n    \"\"\"Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    \"\"\"一个用于加载VOC数据集的自定义数据集\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n\n    def __init__(self, is_train, crop_size, voc_dir):\n        self.transform = paddle.vision.transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        self.crop_size = crop_size\n        features, labels = read_voc_images(voc_dir, is_train=is_train)\n        self.features = [self.normalize_image(feature)\n                         for feature in self.filter(features)]\n        self.labels = self.filter(labels)\n        self.colormap2label = voc_colormap2label()\n        print('read ' + str(len(self.features)) + ' examples')\n\n    def normalize_image(self, img):\n        return self.transform(img.astype(\"float32\") / 255)\n\n    def filter(self, imgs):\n        return [img for img in imgs if (\n            img.shape[1] >= self.crop_size[0] and\n            img.shape[2] >= self.crop_size[1])]\n\n    def __getitem__(self, idx):\n        feature = paddle.to_tensor(self.features[idx],dtype='float32')\n        label = paddle.to_tensor(self.labels[idx],dtype='float32')\n        feature, label = voc_rand_crop(feature,label,\n                                       *self.crop_size)\n        return (feature, voc_label_indices(label, self.colormap2label))\n\n    def __len__(self):\n        return len(self.features)\n\ndef load_data_voc(batch_size, crop_size):\n    \"\"\"加载VOC语义分割数据集\n\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    voc_dir = d2l.download_extract('voc2012', os.path.join(\n        'VOCdevkit', 'VOC2012'))\n    num_workers = d2l.get_dataloader_workers()\n    train_iter = paddle.io.DataLoader(\n        VOCSegDataset(True, crop_size, voc_dir), batch_size=batch_size,\n        shuffle=True, return_list=True, drop_last=True, num_workers=num_workers)\n    test_iter = paddle.io.DataLoader(\n        VOCSegDataset(False, crop_size, voc_dir), batch_size=batch_size,\n        drop_last=True, return_list=True, num_workers=num_workers)\n    return train_iter, test_iter\n\nd2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip',\n                                '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n\ndef read_csv_labels(fname):\n    \"\"\"读取fname来给标签字典返回一个文件名\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    with open(fname, 'r') as f:\n        # 跳过文件头行(列名)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\ndef copyfile(filename, target_dir):\n    \"\"\"将文件复制到目标目录\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n\ndef reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"将验证集从原始的训练集中拆分出来\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    # 训练数据集中样本最少的类别中的样本数\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # 验证集中每个类别的样本数\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label\n\ndef reorg_test(data_dir):\n    \"\"\"在预测期间整理测试集，以方便读取\n\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))\n\nd2l.DATA_HUB['dog_tiny'] = (d2l.DATA_URL + 'kaggle_dog_tiny.zip',\n                            '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d')\n\nd2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip',\n                       '319d85e578af0cdc590547f26231e4e31cdf1e42')\n\ndef read_ptb():\n    \"\"\"将PTB数据集加载到文本行的列表中\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    data_dir = d2l.download_extract('ptb')\n    # Readthetrainingset.\n    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n        raw_text = f.read()\n    return [line.split() for line in raw_text.split('\\n')]\n\ndef subsample(sentences, vocab):\n    \"\"\"下采样高频词\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    # 排除未知词元'<unk>'\n    sentences = [[token for token in line if vocab[token] != vocab.unk]\n                 for line in sentences]\n    counter = d2l.count_corpus(sentences)\n    num_tokens = sum(counter.values())\n\n    # 如果在下采样期间保留词元，则返回True\n    def keep(token):\n        return(random.uniform(0, 1) <\n               math.sqrt(1e-4 / counter[token] * num_tokens))\n\n    return ([[token for token in line if keep(token)] for line in sentences],\n            counter)\n\ndef get_centers_and_contexts(corpus, max_window_size):\n    \"\"\"返回跳元模型中的中心词和上下文词\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    centers, contexts = [], []\n    for line in corpus:\n        # 要形成“中心词-上下文词”对，每个句子至少需要有2个词\n        if len(line) < 2:\n            continue\n        centers += line\n        for i in range(len(line)):  # 上下文窗口中间i\n            window_size = random.randint(1, max_window_size)\n            indices = list(range(max(0, i - window_size),\n                                 min(len(line), i + 1 + window_size)))\n            # 从上下文词中排除中心词\n            indices.remove(i)\n            contexts.append([line[idx] for idx in indices])\n    return centers, contexts\n\nclass RandomGenerator:\n    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n    def __init__(self, sampling_weights):\n        \"\"\"Defined in :numref:`sec_word2vec_data`\"\"\"\n        # Exclude\n        self.population = list(range(1, len(sampling_weights) + 1))\n        self.sampling_weights = sampling_weights\n        self.candidates = []\n        self.i = 0\n\n    def draw(self):\n        if self.i == len(self.candidates):\n            # 缓存k个随机采样结果\n            self.candidates = random.choices(\n                self.population, self.sampling_weights, k=10000)\n            self.i = 0\n        self.i += 1\n        return self.candidates[self.i - 1]\n\ngenerator = RandomGenerator([2, 3, 4])\n[generator.draw() for _ in range(10)]\n\ndef get_negatives(all_contexts, vocab, counter, K):\n    \"\"\"返回负采样中的噪声词\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    # 索引为1、2、...（索引0是词表中排除的未知标记）\n    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n                        for i in range(1, len(vocab))]\n    all_negatives, generator = [], RandomGenerator(sampling_weights)\n    for contexts in all_contexts:\n        negatives = []\n        while len(negatives) < len(contexts) * K:\n            neg = generator.draw()\n            # 噪声词不能是上下文词\n            if neg not in contexts:\n                negatives.append(neg)\n        all_negatives.append(negatives)\n    return all_negatives\n\ndef batchify(data):\n    \"\"\"返回带有负采样的跳元模型的小批量样本\n\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    max_len = max(len(c) + len(n) for _, c, n in data)\n    centers, contexts_negatives, masks, labels = [], [], [], []\n    for center, context, negative in data:\n        cur_len = len(context) + len(negative)\n        centers += [center]\n        contexts_negatives += \\\n            [context + negative + [0] * (max_len - cur_len)]\n        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n    return (d2l.reshape(d2l.tensor(centers), (-1, 1)), d2l.tensor(\n        contexts_negatives), d2l.tensor(masks), d2l.tensor(labels))\n\ndef load_data_ptb(batch_size, max_window_size, num_noise_words):\n    \"\"\"下载PTB数据集，然后将其加载到内存中\n\n    Defined in :numref:`subsec_word2vec-minibatch-loading`\"\"\"\n    num_workers = d2l.get_dataloader_workers()\n    sentences = read_ptb()\n    vocab = d2l.Vocab(sentences, min_freq=10)\n    subsampled, counter = subsample(sentences, vocab)\n    corpus = [vocab[line] for line in subsampled]\n    all_centers, all_contexts = get_centers_and_contexts(\n        corpus, max_window_size)\n    all_negatives = get_negatives(\n        all_contexts, vocab, counter, num_noise_words)\n\n    class PTBDataset(paddle.io.Dataset):\n        def __init__(self, centers, contexts, negatives):\n            assert len(centers) == len(contexts) == len(negatives)\n            self.centers = centers\n            self.contexts = contexts\n            self.negatives = negatives\n\n        def __getitem__(self, index):\n            return (self.centers[index], self.contexts[index],\n                    self.negatives[index])\n\n        def __len__(self):\n            return len(self.centers)\n\n    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n\n    data_iter = paddle.io.DataLoader(\n        dataset, batch_size=batch_size, shuffle=True, return_list=True,\n        collate_fn=batchify, num_workers=num_workers)\n    return data_iter, vocab\n\nd2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n\nd2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n\nd2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n\nd2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n                           'c1816da3821ae9f43899be655002f6c723e91b88')\n\nclass TokenEmbedding:\n    \"\"\"GloVe嵌入\"\"\"\n    def __init__(self, embedding_name):\n        \"\"\"Defined in :numref:`sec_synonyms`\"\"\"\n        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n            embedding_name)\n        self.unknown_idx = 0\n        self.token_to_idx = {token: idx for idx, token in\n                             enumerate(self.idx_to_token)}\n\n    def _load_embedding(self, embedding_name):\n        idx_to_token, idx_to_vec = ['<unk>'], []\n        data_dir = d2l.download_extract(embedding_name)\n        # GloVe网站：https://nlp.stanford.edu/projects/glove/\n        # fastText网站：https://fasttext.cc/\n        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n            for line in f:\n                elems = line.rstrip().split(' ')\n                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n                # 跳过标题信息，例如fastText中的首行\n                if len(elems) > 1:\n                    idx_to_token.append(token)\n                    idx_to_vec.append(elems)\n        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n        return idx_to_token, d2l.tensor(idx_to_vec)\n\n    def __getitem__(self, tokens):\n        indices = [self.token_to_idx.get(token, self.unknown_idx)\n                   for token in tokens]\n        vecs = self.idx_to_vec[d2l.tensor(indices)]\n        return vecs\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\ndef get_tokens_and_segments(tokens_a, tokens_b=None):\n    \"\"\"获取输入序列的词元及其片段索引\n\n    Defined in :numref:`sec_bert`\"\"\"\n    tokens = ['<cls>'] + tokens_a + ['<sep>']\n    # 0和1分别标记片段A和B\n    segments = [0] * (len(tokens_a) + 2)\n    if tokens_b is not None:\n        tokens += tokens_b + ['<sep>']\n        segments += [1] * (len(tokens_b) + 1)\n    return tokens, segments\n\nclass BERTEncoder(nn.Layer):\n    \"\"\"BERT编码器\n\n    Defined in :numref:`subsec_bert_input_rep`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n                 ffn_num_hiddens, num_heads, num_layers, dropout,\n                 max_len=1000, key_size=768, query_size=768, value_size=768,\n                 **kwargs):\n        super(BERTEncoder, self).__init__(**kwargs)\n        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.segment_embedding = nn.Embedding(2, num_hiddens)\n        self.blks = nn.Sequential()\n        for i in range(num_layers):\n            self.blks.add_sublayer(f\"{i}\", d2l.EncoderBlock(\n                key_size, query_size, value_size, num_hiddens, norm_shape,\n                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))\n        # 在BERT中，位置嵌入是可学习的，因此我们创建一个足够长的位置嵌入参数\n        x = paddle.randn([1, max_len, num_hiddens])\n        self.pos_embedding = paddle.create_parameter(shape=x.shape, dtype=str(x.numpy().dtype),\n                                                     default_initializer=paddle.nn.initializer.Assign(x))\n\n    def forward(self, tokens, segments, valid_lens):\n        # 在以下代码段中，X的形状保持不变：（批量大小，最大序列长度，num_hiddens）\n        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n        X = X + self.pos_embedding[:, :X.shape[1], :]\n        for blk in self.blks:\n            X = blk(X, valid_lens)\n        return X\n\nclass MaskLM(nn.Layer):\n    \"\"\"BERT的掩蔽语言模型任务\n\n    Defined in :numref:`subsec_bert_input_rep`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):\n        super(MaskLM, self).__init__(**kwargs)\n        self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens),\n                                 nn.ReLU(),\n                                 nn.LayerNorm(num_hiddens),\n                                 nn.Linear(num_hiddens, vocab_size))\n\n    def forward(self, X, pred_positions):\n        num_pred_positions = pred_positions.shape[1]\n        pred_positions = pred_positions.reshape([-1])\n        batch_size = X.shape[0]\n        batch_idx = paddle.arange(0, batch_size)\n        # 假设batch_size=2，num_pred_positions=3\n        # 那么batch_idx是np.array（[0,0,0,1,1]）\n        batch_idx = paddle.repeat_interleave(batch_idx, num_pred_positions)\n        masked_X = X[batch_idx, pred_positions]\n        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n        mlm_Y_hat = self.mlp(masked_X)\n        return mlm_Y_hat\n\nclass NextSentencePred(nn.Layer):\n    \"\"\"BERT的下一句预测任务\n\n    Defined in :numref:`subsec_mlm`\"\"\"\n    def __init__(self, num_inputs, **kwargs):\n        super(NextSentencePred, self).__init__(**kwargs)\n        self.output = nn.Linear(num_inputs, 2)\n\n    def forward(self, X):\n        # X的形状：(batchsize,num_hiddens)\n        return self.output(X)\n\nclass BERTModel(nn.Layer):\n    \"\"\"BERT模型\n\n    Defined in :numref:`subsec_nsp`\"\"\"\n    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n                 ffn_num_hiddens, num_heads, num_layers, dropout,\n                 max_len=1000, key_size=768, query_size=768, value_size=768,\n                 hid_in_features=768, mlm_in_features=768,\n                 nsp_in_features=768):\n        super(BERTModel, self).__init__()\n        self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape,\n                    ffn_num_input, ffn_num_hiddens, num_heads, num_layers,\n                    dropout, max_len=max_len, key_size=key_size,\n                    query_size=query_size, value_size=value_size)\n        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n                                    nn.Tanh())\n        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n        self.nsp = NextSentencePred(nsp_in_features)\n\n    def forward(self, tokens, segments, valid_lens=None,\n                pred_positions=None):\n        encoded_X = self.encoder(tokens, segments, valid_lens)\n        if pred_positions is not None:\n            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n        else:\n            mlm_Y_hat = None\n        # 用于下一句预测的多层感知机分类器的隐藏层，0是“<cls>”标记的索引\n        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n        return encoded_X, mlm_Y_hat, nsp_Y_hat\n\nd2l.DATA_HUB['wikitext-2'] = (\n    'https://s3.amazonaws.com/research.metamind.io/wikitext/'\n    'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n\ndef _read_wiki(data_dir):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n    with open(file_name, 'r') as f:\n        lines = f.readlines()\n    # 大写字母转换为小写字母\n    paragraphs = [line.strip().lower().split(' . ')\n                  for line in lines if len(line.split(' . ')) >= 2]\n    random.shuffle(paragraphs)\n    return paragraphs\n\ndef _get_next_sentence(sentence, next_sentence, paragraphs):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    if random.random() < 0.5:\n        is_next = True\n    else:\n        # paragraphs是三重列表的嵌套\n        next_sentence = random.choice(random.choice(paragraphs))\n        is_next = False\n    return sentence, next_sentence, is_next\n\ndef _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    nsp_data_from_paragraph = []\n    for i in range(len(paragraph) - 1):\n        tokens_a, tokens_b, is_next = _get_next_sentence(\n            paragraph[i], paragraph[i + 1], paragraphs)\n        # 考虑1个'<cls>'词元和2个'<sep>'词元\n        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n            continue\n        tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n        nsp_data_from_paragraph.append((tokens, segments, is_next))\n    return nsp_data_from_paragraph\n\ndef _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,\n                        vocab):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    # 为遮蔽语言模型的输入创建新的词元副本，其中输入可能包含替换的“<mask>”或随机词元\n    mlm_input_tokens = [token for token in tokens]\n    pred_positions_and_labels = []\n    # 打乱后用于在遮蔽语言模型任务中获取15%的随机词元进行预测\n    random.shuffle(candidate_pred_positions)\n    for mlm_pred_position in candidate_pred_positions:\n        if len(pred_positions_and_labels) >= num_mlm_preds:\n            break\n        masked_token = None\n        # 80%的时间：将词替换为“<mask>”词元\n        if random.random() < 0.8:\n            masked_token = '<mask>'\n        else:\n            # 10%的时间：保持词不变\n            if random.random() < 0.5:\n                masked_token = tokens[mlm_pred_position]\n            # 10%的时间：用随机词替换该词\n            else:\n                masked_token = random.choice(vocab.idx_to_token)\n        mlm_input_tokens[mlm_pred_position] = masked_token\n        pred_positions_and_labels.append(\n            (mlm_pred_position, tokens[mlm_pred_position]))\n    return mlm_input_tokens, pred_positions_and_labels\n\ndef _get_mlm_data_from_tokens(tokens, vocab):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    candidate_pred_positions = []\n    # tokens是一个字符串列表\n    for i, token in enumerate(tokens):\n        # 在遮蔽语言模型任务中不会预测特殊词元\n        if token in ['<cls>', '<sep>']:\n            continue\n        candidate_pred_positions.append(i)\n    # 遮蔽语言模型任务中预测15%的随机词元\n    num_mlm_preds = max(1, round(len(tokens) * 0.15))\n    mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(\n        tokens, candidate_pred_positions, num_mlm_preds, vocab)\n    pred_positions_and_labels = sorted(pred_positions_and_labels,\n                                       key=lambda x: x[0])\n    pred_positions = [v[0] for v in pred_positions_and_labels]\n    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n    return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]\n\ndef _pad_bert_inputs(examples, max_len, vocab):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    max_num_mlm_preds = round(max_len * 0.15)\n    all_token_ids, all_segments, valid_lens,  = [], [], []\n    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n    nsp_labels = []\n    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n         is_next) in examples:\n        all_token_ids.append(paddle.to_tensor(token_ids + [vocab['<pad>']] * (\n            max_len - len(token_ids)), dtype=paddle.int64))\n        all_segments.append(paddle.to_tensor(segments + [0] * (\n            max_len - len(segments)), dtype=paddle.int64))\n        # valid_lens不包括'<pad>'的计数\n        valid_lens.append(paddle.to_tensor(len(token_ids), dtype=paddle.float32))\n        all_pred_positions.append(paddle.to_tensor(pred_positions + [0] * (\n            max_num_mlm_preds - len(pred_positions)), dtype=paddle.int64))\n        # 填充词元的预测将通过乘以0权重在损失中过滤掉\n        all_mlm_weights.append(\n            paddle.to_tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * (\n                max_num_mlm_preds - len(pred_positions)),\n                dtype=paddle.float32))\n        all_mlm_labels.append(paddle.to_tensor(mlm_pred_label_ids + [0] * (\n            max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=paddle.int64))\n        nsp_labels.append(paddle.to_tensor(is_next, dtype=paddle.int64))\n    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n            all_mlm_weights, all_mlm_labels, nsp_labels)\n\nclass _WikiTextDataset(paddle.io.Dataset):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    def __init__(self, paragraphs, max_len):\n        # 输入paragraphs[i]是代表段落的句子字符串列表；\n        # 而输出paragraphs[i]是代表段落的句子列表，其中每个句子都是词元列表\n        paragraphs = [d2l.tokenize(\n            paragraph, token='word') for paragraph in paragraphs]\n        sentences = [sentence for paragraph in paragraphs\n                     for sentence in paragraph]\n        self.vocab = d2l.Vocab(sentences, min_freq=5, reserved_tokens=[\n            '<pad>', '<mask>', '<cls>', '<sep>'])\n        # 获取下一句子预测任务的数据\n        examples = []\n        for paragraph in paragraphs:\n            examples.extend(_get_nsp_data_from_paragraph(\n                paragraph, paragraphs, self.vocab, max_len))\n        # 获取遮蔽语言模型任务的数据\n        examples = [(_get_mlm_data_from_tokens(tokens, self.vocab)\n                      + (segments, is_next))\n                     for tokens, segments, is_next in examples]\n        # 填充输入\n        (self.all_token_ids, self.all_segments, self.valid_lens,\n         self.all_pred_positions, self.all_mlm_weights,\n         self.all_mlm_labels, self.nsp_labels) = _pad_bert_inputs(\n            examples, max_len, self.vocab)\n\n    def __getitem__(self, idx):\n        return (self.all_token_ids[idx], self.all_segments[idx],\n                self.valid_lens[idx], self.all_pred_positions[idx],\n                self.all_mlm_weights[idx], self.all_mlm_labels[idx],\n                self.nsp_labels[idx])\n\n    def __len__(self):\n        return len(self.all_token_ids)\n\ndef load_data_wiki(batch_size, max_len):\n    \"\"\"加载WikiText-2数据集\n\n    Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    num_workers = d2l.get_dataloader_workers()\n    data_dir = d2l.download_extract('wikitext-2', 'wikitext-2')\n    paragraphs = _read_wiki(data_dir)\n    train_set = _WikiTextDataset(paragraphs, max_len)\n    train_iter = paddle.io.DataLoader(dataset=train_set, batch_size=batch_size, return_list=True,\n                                        shuffle=True, num_workers=num_workers)\n    return train_iter, train_set.vocab\n\ndef _get_batch_loss_bert(net, loss, vocab_size, tokens_X,\n                         segments_X, valid_lens_x,\n                         pred_positions_X, mlm_weights_X,\n                         mlm_Y, nsp_y):\n    \"\"\"Defined in :numref:`sec_bert-pretraining`\"\"\"\n    # 前向传播\n    _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,\n                                  valid_lens_x.reshape([-1]),\n                                  pred_positions_X)\n    # 计算遮蔽语言模型损失\n    mlm_l = loss(mlm_Y_hat.reshape([-1, vocab_size]), mlm_Y.reshape([-1])) *\\\n    mlm_weights_X.reshape([-1, 1])\n    mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)\n    # 计算下一句子预测任务的损失\n    nsp_l = loss(nsp_Y_hat, nsp_y)\n    l = mlm_l + nsp_l\n    return mlm_l, nsp_l, l\n\nd2l.DATA_HUB['aclImdb'] = (\n    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n    '01ada507287d82875905620988597833ad4e0903')\n\ndef read_imdb(data_dir, is_train):\n    \"\"\"读取IMDb评论数据集文本序列和标签\n\n    Defined in :numref:`sec_sentiment`\"\"\"\n    data, labels = [], []\n    for label in ('pos', 'neg'):\n        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n                                   label)\n        for file in os.listdir(folder_name):\n            with open(os.path.join(folder_name, file), 'rb') as f:\n                review = f.read().decode('utf-8').replace('\\n', '')\n                data.append(review)\n                labels.append(1 if label == 'pos' else 0)\n    return data, labels\n\ndef load_data_imdb(batch_size, num_steps=500):\n    \"\"\"返回数据迭代器和IMDb评论数据集的词表\n\n    Defined in :numref:`sec_sentiment`\"\"\"\n    data_dir = d2l.download_extract('aclImdb', 'aclImdb')\n    train_data = read_imdb(data_dir, True)\n    test_data = read_imdb(data_dir, False)\n    train_tokens = d2l.tokenize(train_data[0], token='word')\n    test_tokens = d2l.tokenize(test_data[0], token='word')\n    vocab = d2l.Vocab(train_tokens, min_freq=5)\n    train_features = d2l.tensor([d2l.truncate_pad(\n        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n    test_features = d2l.tensor([d2l.truncate_pad(\n        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n    train_iter = d2l.load_array((train_features, d2l.tensor(train_data[1])),\n                                batch_size)\n    test_iter = d2l.load_array((test_features, d2l.tensor(test_data[1])),\n                               batch_size,\n                               is_train=False)\n    return train_iter, test_iter, vocab\n\ndef predict_sentiment(net, vocab, sequence):\n    \"\"\"预测文本序列的情感\n\n    Defined in :numref:`sec_sentiment_rnn`\"\"\"\n    sequence = paddle.to_tensor(vocab[sequence.split()], place=d2l.try_gpu())\n    label = paddle.argmax(net(sequence.reshape((1, -1))), axis=1)\n    return 'positive' if label == 1 else 'negative'\n\nd2l.DATA_HUB['SNLI'] = (\n    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n\ndef read_snli(data_dir, is_train):\n    \"\"\"将SNLI数据集解析为前提、假设和标签\n\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    def extract_text(s):\n        # 删除我们不会使用的信息\n        s = re.sub('\\\\(', '', s)\n        s = re.sub('\\\\)', '', s)\n        # 用一个空格替换两个或多个连续的空格\n        s = re.sub('\\\\s{2,}', ' ', s)\n        return s.strip()\n    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n                             if is_train else 'snli_1.0_test.txt')\n    with open(file_name, 'r') as f:\n        rows = [row.split('\\t') for row in f.readlines()[1:]]\n    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n    hypotheses = [extract_text(row[2]) for row in rows if row[0] \\\n                in label_set]\n    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n    return premises, hypotheses, labels\n\nclass SNLIDataset(paddle.io.Dataset):\n    \"\"\"用于加载SNLI数据集的自定义数据集\n\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    def __init__(self, dataset, num_steps, vocab=None):\n        self.num_steps = num_steps\n        all_premise_tokens = d2l.tokenize(dataset[0])\n        all_hypothesis_tokens = d2l.tokenize(dataset[1])\n        if vocab is None:\n            self.vocab = d2l.Vocab(all_premise_tokens + \\\n                all_hypothesis_tokens, min_freq=5, reserved_tokens=['<pad>'])\n        else:\n            self.vocab = vocab\n        self.premises = self._pad(all_premise_tokens)\n        self.hypotheses = self._pad(all_hypothesis_tokens)\n        self.labels = paddle.to_tensor(dataset[2])\n        print('read ' + str(len(self.premises)) + ' examples')\n\n    def _pad(self, lines):\n        return paddle.to_tensor([d2l.truncate_pad(\n            self.vocab[line], self.num_steps, self.vocab['<pad>'])\n                         for line in lines])\n\n    def __getitem__(self, idx):\n        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n\n    def __len__(self):\n        return len(self.premises)\n\ndef load_data_snli(batch_size, num_steps=50):\n    \"\"\"下载SNLI数据集并返回数据迭代器和词表\n\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    num_workers = d2l.get_dataloader_workers()\n    data_dir = d2l.download_extract('SNLI')\n    train_data = read_snli(data_dir, True)\n    test_data = read_snli(data_dir, False)\n    train_set = SNLIDataset(train_data, num_steps)\n    test_set = SNLIDataset(test_data, num_steps, train_set.vocab)\n    train_iter = paddle.io.DataLoader(train_set,batch_size=batch_size,\n                                      shuffle=True,\n                                      num_workers=num_workers,\n                                      return_list=True)\n\n    test_iter = paddle.io.DataLoader(test_set, batch_size=batch_size,\n                                     shuffle=False,\n                                     num_workers=num_workers,\n                                     return_list=True)\n    return train_iter, test_iter, train_set.vocab\n\ndef predict_snli(net, vocab, premise, hypothesis):\n    \"\"\"预测前提和假设之间的逻辑关系\n\n    Defined in :numref:`sec_natural-language-inference-attention`\"\"\"\n    net.eval()\n    premise = paddle.to_tensor(vocab[premise], place=d2l.try_gpu())\n    hypothesis = paddle.to_tensor(vocab[hypothesis], place=d2l.try_gpu())\n    label = paddle.argmax(net([premise.reshape((1, -1)),\n                           hypothesis.reshape((1, -1))]), axis=1)\n\n    return 'entailment' if label == 0 else 'contradiction' if label == 1 \\\n            else 'neutral'\n\n\n# Alias defined in config.ini\nnn_Module = nn.Layer\n\nones = paddle.ones\nzeros = paddle.zeros\ntensor = paddle.to_tensor\narange = paddle.arange\nmeshgrid = paddle.meshgrid\nsin = paddle.sin\nsinh = paddle.sinh\ncos = paddle.cos\ncosh = paddle.cosh\ntanh = paddle.tanh\nlinspace = paddle.linspace\nexp = paddle.exp\nlog = paddle.log\nnormal = paddle.normal\nrand = paddle.rand\nrandn = paddle.randn\nmatmul = paddle.matmul\nint32 = paddle.int32\nfloat32 = paddle.float32\nconcat = paddle.concat\nstack = paddle.stack\nabs = paddle.abs\neye = paddle.eye\nnumpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)\nsize = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\nreshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\nto = lambda x, *args, **kwargs: x.to(*args, **kwargs)\nreduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\nargmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\nastype = lambda x, *args, **kwargs: x.astype(*args, **kwargs)\ntranspose = lambda x, *args, **kwargs: x.t(*args, **kwargs)\nreduce_mean = lambda x, *args, **kwargs: x.mean(*args, **kwargs)\n\n"
  },
  "requirements": null
}