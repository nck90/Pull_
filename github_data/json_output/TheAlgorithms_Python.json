{
  "repo_name": "TheAlgorithms/Python",
  "repo_url": "https://github.com/TheAlgorithms/Python",
  "description": "All Algorithms implemented in Python",
  "stars": 198511,
  "language": "Python",
  "created_at": "2016-07-16T09:44:01Z",
  "updated_at": "2025-03-19T05:21:00Z",
  "files": {
    "data_structures/hashing/tests/test_hash_map.py": "from operator import delitem, getitem, setitem\n\nimport pytest\n\nfrom data_structures.hashing.hash_map import HashMap\n\n\ndef _get(k):\n    return getitem, k\n\n\ndef _set(k, v):\n    return setitem, k, v\n\n\ndef _del(k):\n    return delitem, k\n\n\ndef _run_operation(obj, fun, *args):\n    try:\n        return fun(obj, *args), None\n    except Exception as e:\n        return None, e\n\n\n_add_items = (\n    _set(\"key_a\", \"val_a\"),\n    _set(\"key_b\", \"val_b\"),\n)\n\n_overwrite_items = [\n    _set(\"key_a\", \"val_a\"),\n    _set(\"key_a\", \"val_b\"),\n]\n\n_delete_items = [\n    _set(\"key_a\", \"val_a\"),\n    _set(\"key_b\", \"val_b\"),\n    _del(\"key_a\"),\n    _del(\"key_b\"),\n    _set(\"key_a\", \"val_a\"),\n    _del(\"key_a\"),\n]\n\n_access_absent_items = [\n    _get(\"key_a\"),\n    _del(\"key_a\"),\n    _set(\"key_a\", \"val_a\"),\n    _del(\"key_a\"),\n    _del(\"key_a\"),\n    _get(\"key_a\"),\n]\n\n_add_with_resize_up = [\n    *[_set(x, x) for x in range(5)],  # guaranteed upsize\n]\n\n_add_with_resize_down = [\n    *[_set(x, x) for x in range(5)],  # guaranteed upsize\n    *[_del(x) for x in range(5)],\n    _set(\"key_a\", \"val_b\"),\n]\n\n\n@pytest.mark.parametrize(\n    \"operations\",\n    [\n        pytest.param(_add_items, id=\"add items\"),\n        pytest.param(_overwrite_items, id=\"overwrite items\"),\n        pytest.param(_delete_items, id=\"delete items\"),\n        pytest.param(_access_absent_items, id=\"access absent items\"),\n        pytest.param(_add_with_resize_up, id=\"add with resize up\"),\n        pytest.param(_add_with_resize_down, id=\"add with resize down\"),\n    ],\n)\ndef test_hash_map_is_the_same_as_dict(operations):\n    my = HashMap(initial_block_size=4)\n    py = {}\n    for _, (fun, *args) in enumerate(operations):\n        my_res, my_exc = _run_operation(my, fun, *args)\n        py_res, py_exc = _run_operation(py, fun, *args)\n        assert my_res == py_res\n        assert str(my_exc) == str(py_exc)\n        assert set(py) == set(my)\n        assert len(py) == len(my)\n        assert set(my.items()) == set(py.items())\n\n\ndef test_no_new_methods_was_added_to_api():\n    def is_public(name: str) -> bool:\n        return not name.startswith(\"_\")\n\n    dict_public_names = {name for name in dir({}) if is_public(name)}\n    hash_public_names = {name for name in dir(HashMap()) if is_public(name)}\n\n    assert dict_public_names > hash_public_names\n",
    "data_structures/kd_tree/tests/test_kdtree.py": "#  Created by: Ramy-Badr-Ahmed (https://github.com/Ramy-Badr-Ahmed)\n#  in Pull Request: #11532\n#  https://github.com/TheAlgorithms/Python/pull/11532\n#\n#  Please mention me (@Ramy-Badr-Ahmed) in any issue or pull request\n#  addressing bugs/corrections to this file.\n#  Thank you!\n\nimport numpy as np\nimport pytest\n\nfrom data_structures.kd_tree.build_kdtree import build_kdtree\nfrom data_structures.kd_tree.example.hypercube_points import hypercube_points\nfrom data_structures.kd_tree.kd_node import KDNode\nfrom data_structures.kd_tree.nearest_neighbour_search import nearest_neighbour_search\n\n\n@pytest.mark.parametrize(\n    (\"num_points\", \"cube_size\", \"num_dimensions\", \"depth\", \"expected_result\"),\n    [\n        (0, 10.0, 2, 0, None),  # Empty points list\n        (10, 10.0, 2, 2, KDNode),  # Depth = 2, 2D points\n        (10, 10.0, 3, -2, KDNode),  # Depth = -2, 3D points\n    ],\n)\ndef test_build_kdtree(num_points, cube_size, num_dimensions, depth, expected_result):\n    \"\"\"\n    Test that KD-Tree is built correctly.\n\n    Cases:\n        - Empty points list.\n        - Positive depth value.\n        - Negative depth value.\n    \"\"\"\n    points = (\n        hypercube_points(num_points, cube_size, num_dimensions).tolist()\n        if num_points > 0\n        else []\n    )\n\n    kdtree = build_kdtree(points, depth=depth)\n\n    if expected_result is None:\n        # Empty points list case\n        assert kdtree is None, f\"Expected None for empty points list, got {kdtree}\"\n    else:\n        # Check if root node is not None\n        assert kdtree is not None, \"Expected a KDNode, got None\"\n\n        # Check if root has correct dimensions\n        assert len(kdtree.point) == num_dimensions, (\n            f\"Expected point dimension {num_dimensions}, got {len(kdtree.point)}\"\n        )\n\n        # Check that the tree is balanced to some extent (simplistic check)\n        assert isinstance(kdtree, KDNode), (\n            f\"Expected KDNode instance, got {type(kdtree)}\"\n        )\n\n\ndef test_nearest_neighbour_search():\n    \"\"\"\n    Test the nearest neighbor search function.\n    \"\"\"\n    num_points = 10\n    cube_size = 10.0\n    num_dimensions = 2\n    points = hypercube_points(num_points, cube_size, num_dimensions)\n    kdtree = build_kdtree(points.tolist())\n\n    rng = np.random.default_rng()\n    query_point = rng.random(num_dimensions).tolist()\n\n    nearest_point, nearest_dist, nodes_visited = nearest_neighbour_search(\n        kdtree, query_point\n    )\n\n    # Check that nearest point is not None\n    assert nearest_point is not None\n\n    # Check that distance is a non-negative number\n    assert nearest_dist >= 0\n\n    # Check that nodes visited is a non-negative integer\n    assert nodes_visited >= 0\n\n\ndef test_edge_cases():\n    \"\"\"\n    Test edge cases such as an empty KD-Tree.\n    \"\"\"\n    empty_kdtree = build_kdtree([])\n    query_point = [0.0] * 2  # Using a default 2D query point\n\n    nearest_point, nearest_dist, nodes_visited = nearest_neighbour_search(\n        empty_kdtree, query_point\n    )\n\n    # With an empty KD-Tree, nearest_point should be None\n    assert nearest_point is None\n    assert nearest_dist == float(\"inf\")\n    assert nodes_visited == 0\n\n\nif __name__ == \"__main__\":\n    import pytest\n\n    pytest.main()\n",
    "data_structures/suffix_tree/tests/test_suffix_tree.py": "#  Created by: Ramy-Badr-Ahmed (https://github.com/Ramy-Badr-Ahmed)\n#  in Pull Request: #11554\n#  https://github.com/TheAlgorithms/Python/pull/11554\n#\n#  Please mention me (@Ramy-Badr-Ahmed) in any issue or pull request\n#  addressing bugs/corrections to this file.\n#  Thank you!\n\nimport unittest\n\nfrom data_structures.suffix_tree.suffix_tree import SuffixTree\n\n\nclass TestSuffixTree(unittest.TestCase):\n    def setUp(self) -> None:\n        \"\"\"Set up the initial conditions for each test.\"\"\"\n        self.text = \"banana\"\n        self.suffix_tree = SuffixTree(self.text)\n\n    def test_search_existing_patterns(self) -> None:\n        \"\"\"Test searching for patterns that exist in the suffix tree.\"\"\"\n        patterns = [\"ana\", \"ban\", \"na\"]\n        for pattern in patterns:\n            with self.subTest(pattern=pattern):\n                assert self.suffix_tree.search(pattern), (\n                    f\"Pattern '{pattern}' should be found.\"\n                )\n\n    def test_search_non_existing_patterns(self) -> None:\n        \"\"\"Test searching for patterns that do not exist in the suffix tree.\"\"\"\n        patterns = [\"xyz\", \"apple\", \"cat\"]\n        for pattern in patterns:\n            with self.subTest(pattern=pattern):\n                assert not self.suffix_tree.search(pattern), (\n                    f\"Pattern '{pattern}' should not be found.\"\n                )\n\n    def test_search_empty_pattern(self) -> None:\n        \"\"\"Test searching for an empty pattern.\"\"\"\n        assert self.suffix_tree.search(\"\"), \"An empty pattern should be found.\"\n\n    def test_search_full_text(self) -> None:\n        \"\"\"Test searching for the full text.\"\"\"\n        assert self.suffix_tree.search(self.text), (\n            \"The full text should be found in the suffix tree.\"\n        )\n\n    def test_search_substrings(self) -> None:\n        \"\"\"Test searching for substrings of the full text.\"\"\"\n        substrings = [\"ban\", \"ana\", \"a\", \"na\"]\n        for substring in substrings:\n            with self.subTest(substring=substring):\n                assert self.suffix_tree.search(substring), (\n                    f\"Substring '{substring}' should be found.\"\n                )\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
    "digital_image_processing/test_digital_image_processing.py": "\"\"\"\nPyTest's for Digital Image Processing\n\"\"\"\n\nimport numpy as np\nfrom cv2 import COLOR_BGR2GRAY, cvtColor, imread\nfrom numpy import array, uint8\nfrom PIL import Image\n\nfrom digital_image_processing import change_contrast as cc\nfrom digital_image_processing import convert_to_negative as cn\nfrom digital_image_processing import sepia as sp\nfrom digital_image_processing.dithering import burkes as bs\nfrom digital_image_processing.edge_detection import canny\nfrom digital_image_processing.filters import convolve as conv\nfrom digital_image_processing.filters import gaussian_filter as gg\nfrom digital_image_processing.filters import local_binary_pattern as lbp\nfrom digital_image_processing.filters import median_filter as med\nfrom digital_image_processing.filters import sobel_filter as sob\nfrom digital_image_processing.resize import resize as rs\n\nimg = imread(r\"digital_image_processing/image_data/lena_small.jpg\")\ngray = cvtColor(img, COLOR_BGR2GRAY)\n\n\n# Test: convert_to_negative()\ndef test_convert_to_negative():\n    negative_img = cn.convert_to_negative(img)\n    # assert negative_img array for at least one True\n    assert negative_img.any()\n\n\n# Test: change_contrast()\ndef test_change_contrast():\n    with Image.open(\"digital_image_processing/image_data/lena_small.jpg\") as img:\n        # Work around assertion for response\n        assert str(cc.change_contrast(img, 110)).startswith(\n            \"<PIL.Image.Image image mode=RGB size=100x100 at\"\n        )\n\n\n# canny.gen_gaussian_kernel()\ndef test_gen_gaussian_kernel():\n    resp = canny.gen_gaussian_kernel(9, sigma=1.4)\n    # Assert ambiguous array\n    assert resp.all()\n\n\n# canny.py\ndef test_canny():\n    canny_img = imread(\"digital_image_processing/image_data/lena_small.jpg\", 0)\n    # assert ambiguous array for all == True\n    assert canny_img.all()\n    canny_array = canny.canny(canny_img)\n    # assert canny array for at least one True\n    assert canny_array.any()\n\n\n# filters/gaussian_filter.py\ndef test_gen_gaussian_kernel_filter():\n    assert gg.gaussian_filter(gray, 5, sigma=0.9).all()\n\n\ndef test_convolve_filter():\n    # laplace diagonals\n    laplace = array([[0.25, 0.5, 0.25], [0.5, -3, 0.5], [0.25, 0.5, 0.25]])\n    res = conv.img_convolve(gray, laplace).astype(uint8)\n    assert res.any()\n\n\ndef test_median_filter():\n    assert med.median_filter(gray, 3).any()\n\n\ndef test_sobel_filter():\n    grad, theta = sob.sobel_filter(gray)\n    assert grad.any()\n    assert theta.any()\n\n\ndef test_sepia():\n    sepia = sp.make_sepia(img, 20)\n    assert sepia.all()\n\n\ndef test_burkes(file_path: str = \"digital_image_processing/image_data/lena_small.jpg\"):\n    burkes = bs.Burkes(imread(file_path, 1), 120)\n    burkes.process()\n    assert burkes.output_img.any()\n\n\ndef test_nearest_neighbour(\n    file_path: str = \"digital_image_processing/image_data/lena_small.jpg\",\n):\n    nn = rs.NearestNeighbour(imread(file_path, 1), 400, 200)\n    nn.process()\n    assert nn.output.any()\n\n\ndef test_local_binary_pattern():\n    # pull request 10161 before:\n    # \"digital_image_processing/image_data/lena.jpg\"\n    # after: \"digital_image_processing/image_data/lena_small.jpg\"\n\n    from os import getenv  # Speed up our Continuous Integration tests\n\n    file_name = \"lena_small.jpg\" if getenv(\"CI\") else \"lena.jpg\"\n    file_path = f\"digital_image_processing/image_data/{file_name}\"\n\n    # Reading the image and converting it to grayscale\n    image = imread(file_path, 0)\n\n    # Test for get_neighbors_pixel function() return not None\n    x_coordinate = 0\n    y_coordinate = 0\n    center = image[x_coordinate][y_coordinate]\n\n    neighbors_pixels = lbp.get_neighbors_pixel(\n        image, x_coordinate, y_coordinate, center\n    )\n\n    assert neighbors_pixels is not None\n\n    # Test for local_binary_pattern function()\n    # Create a numpy array as the same height and width of read image\n    lbp_image = np.zeros((image.shape[0], image.shape[1]))\n\n    # Iterating through the image and calculating the local binary pattern value\n    # for each pixel.\n    for i in range(image.shape[0]):\n        for j in range(image.shape[1]):\n            lbp_image[i][j] = lbp.local_binary_value(image, i, j)\n\n    assert lbp_image.any()\n",
    "file_transfer/tests/test_send_file.py": "from unittest.mock import Mock, patch\n\nfrom file_transfer.send_file import send_file\n\n\n@patch(\"socket.socket\")\n@patch(\"builtins.open\")\ndef test_send_file_running_as_expected(file, sock):\n    # ===== initialization =====\n    conn = Mock()\n    sock.return_value.accept.return_value = conn, Mock()\n    f = iter([1, None])\n    file.return_value.__enter__.return_value.read.side_effect = lambda _: next(f)\n\n    # ===== invoke =====\n    send_file(filename=\"mytext.txt\", testing=True)\n\n    # ===== ensurance =====\n    sock.assert_called_once()\n    sock.return_value.bind.assert_called_once()\n    sock.return_value.listen.assert_called_once()\n    sock.return_value.accept.assert_called_once()\n    conn.recv.assert_called_once()\n\n    file.return_value.__enter__.assert_called_once()\n    file.return_value.__enter__.return_value.read.assert_called()\n\n    conn.send.assert_called_once()\n    conn.close.assert_called_once()\n    sock.return_value.shutdown.assert_called_once()\n    sock.return_value.close.assert_called_once()\n",
    "graphs/breadth_first_search_shortest_path.py": "\"\"\"Breath First Search (BFS) can be used when finding the shortest path\nfrom a given source node to a target node in an unweighted graph.\n\"\"\"\n\nfrom __future__ import annotations\n\ngraph = {\n    \"A\": [\"B\", \"C\", \"E\"],\n    \"B\": [\"A\", \"D\", \"E\"],\n    \"C\": [\"A\", \"F\", \"G\"],\n    \"D\": [\"B\"],\n    \"E\": [\"A\", \"B\", \"D\"],\n    \"F\": [\"C\"],\n    \"G\": [\"C\"],\n}\n\n\nclass Graph:\n    def __init__(self, graph: dict[str, list[str]], source_vertex: str) -> None:\n        \"\"\"\n        Graph is implemented as dictionary of adjacency lists. Also,\n        Source vertex have to be defined upon initialization.\n        \"\"\"\n        self.graph = graph\n        # mapping node to its parent in resulting breadth first tree\n        self.parent: dict[str, str | None] = {}\n        self.source_vertex = source_vertex\n\n    def breath_first_search(self) -> None:\n        \"\"\"\n        This function is a helper for running breath first search on this graph.\n        >>> g = Graph(graph, \"G\")\n        >>> g.breath_first_search()\n        >>> g.parent\n        {'G': None, 'C': 'G', 'A': 'C', 'F': 'C', 'B': 'A', 'E': 'A', 'D': 'B'}\n        \"\"\"\n        visited = {self.source_vertex}\n        self.parent[self.source_vertex] = None\n        queue = [self.source_vertex]  # first in first out queue\n\n        while queue:\n            vertex = queue.pop(0)\n            for adjacent_vertex in self.graph[vertex]:\n                if adjacent_vertex not in visited:\n                    visited.add(adjacent_vertex)\n                    self.parent[adjacent_vertex] = vertex\n                    queue.append(adjacent_vertex)\n\n    def shortest_path(self, target_vertex: str) -> str:\n        \"\"\"\n        This shortest path function returns a string, describing the result:\n        1.) No path is found. The string is a human readable message to indicate this.\n        2.) The shortest path is found. The string is in the form\n            `v1(->v2->v3->...->vn)`, where v1 is the source vertex and vn is the target\n            vertex, if it exists separately.\n\n        >>> g = Graph(graph, \"G\")\n        >>> g.breath_first_search()\n\n        Case 1 - No path is found.\n        >>> g.shortest_path(\"Foo\")\n        Traceback (most recent call last):\n            ...\n        ValueError: No path from vertex: G to vertex: Foo\n\n        Case 2 - The path is found.\n        >>> g.shortest_path(\"D\")\n        'G->C->A->B->D'\n        >>> g.shortest_path(\"G\")\n        'G'\n        \"\"\"\n        if target_vertex == self.source_vertex:\n            return self.source_vertex\n\n        target_vertex_parent = self.parent.get(target_vertex)\n        if target_vertex_parent is None:\n            msg = (\n                f\"No path from vertex: {self.source_vertex} to vertex: {target_vertex}\"\n            )\n            raise ValueError(msg)\n\n        return self.shortest_path(target_vertex_parent) + f\"->{target_vertex}\"\n\n\nif __name__ == \"__main__\":\n    g = Graph(graph, \"G\")\n    g.breath_first_search()\n    print(g.shortest_path(\"D\"))\n    print(g.shortest_path(\"G\"))\n    print(g.shortest_path(\"Foo\"))\n"
  },
  "requirements": "beautifulsoup4\nfake-useragent\nimageio\nkeras\nlxml\nmatplotlib\nnumpy\nopencv-python\npandas\npillow\nrequests\nrich\nscikit-learn\nsphinx-pyproject\nstatsmodels\nsympy\ntweepy\ntyping_extensions\nxgboost\n"
}