{
  "repo_name": "tensorflow/models",
  "repo_url": "https://github.com/tensorflow/models",
  "description": "Models and examples built with TensorFlow",
  "stars": 77454,
  "language": "Python",
  "created_at": "2016-02-05T01:15:20Z",
  "updated_at": "2025-03-19T02:05:11Z",
  "files": {
    "official/common/distribute_utils_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for distribution util functions.\"\"\"\n\nimport sys\nimport tensorflow as tf, tf_keras\n\nfrom official.common import distribute_utils\n\nTPU_TEST = 'test_tpu' in sys.argv[0]\n\n\nclass DistributeUtilsTest(tf.test.TestCase):\n  \"\"\"Tests for distribute util functions.\"\"\"\n\n  def test_invalid_args(self):\n    with self.assertRaisesRegex(ValueError, '`num_gpus` can not be negative.'):\n      _ = distribute_utils.get_distribution_strategy(num_gpus=-1)\n\n    with self.assertRaisesRegex(ValueError,\n                                '.*If you meant to pass the string .*'):\n      _ = distribute_utils.get_distribution_strategy(\n          distribution_strategy=False, num_gpus=0)\n    with self.assertRaisesRegex(ValueError, 'When 2 GPUs are specified.*'):\n      _ = distribute_utils.get_distribution_strategy(\n          distribution_strategy='off', num_gpus=2)\n    with self.assertRaisesRegex(ValueError,\n                                '`OneDeviceStrategy` can not be used.*'):\n      _ = distribute_utils.get_distribution_strategy(\n          distribution_strategy='one_device', num_gpus=2)\n\n  def test_one_device_strategy_cpu(self):\n    ds = distribute_utils.get_distribution_strategy('one_device', num_gpus=0)\n    self.assertEqual(ds.num_replicas_in_sync, 1)\n    self.assertEqual(len(ds.extended.worker_devices), 1)\n    self.assertIn('CPU', ds.extended.worker_devices[0])\n\n  def test_one_device_strategy_gpu(self):\n    ds = distribute_utils.get_distribution_strategy('one_device', num_gpus=1)\n    self.assertEqual(ds.num_replicas_in_sync, 1)\n    self.assertEqual(len(ds.extended.worker_devices), 1)\n    self.assertIn('GPU', ds.extended.worker_devices[0])\n\n  def test_mirrored_strategy(self):\n    # CPU only.\n    _ = distribute_utils.get_distribution_strategy(num_gpus=0)\n    # 5 GPUs.\n    ds = distribute_utils.get_distribution_strategy(num_gpus=5)\n    self.assertEqual(ds.num_replicas_in_sync, 5)\n    self.assertEqual(len(ds.extended.worker_devices), 5)\n    for device in ds.extended.worker_devices:\n      self.assertIn('GPU', device)\n\n    _ = distribute_utils.get_distribution_strategy(\n        distribution_strategy='mirrored',\n        num_gpus=2,\n        all_reduce_alg='nccl',\n        num_packs=2)\n    with self.assertRaisesRegex(\n        ValueError,\n        'When used with `mirrored`, valid values for all_reduce_alg are.*'):\n      _ = distribute_utils.get_distribution_strategy(\n          distribution_strategy='mirrored',\n          num_gpus=2,\n          all_reduce_alg='dummy',\n          num_packs=2)\n\n  def test_mwms(self):\n    distribute_utils.configure_cluster(worker_hosts=None, task_index=-1)\n    ds = distribute_utils.get_distribution_strategy(\n        'multi_worker_mirrored', all_reduce_alg='nccl')\n    self.assertIsInstance(\n        ds, tf.distribute.experimental.MultiWorkerMirroredStrategy)\n\n    with self.assertRaisesRegex(\n        ValueError,\n        'When used with `multi_worker_mirrored`, valid values.*'):\n      _ = distribute_utils.get_distribution_strategy(\n          'multi_worker_mirrored', all_reduce_alg='dummy')\n\n  def test_no_strategy(self):\n    ds = distribute_utils.get_distribution_strategy('off')\n    self.assertIs(ds, tf.distribute.get_strategy())\n\n  def test_tpu_strategy(self):\n    if not TPU_TEST:\n      self.skipTest('Only Cloud TPU VM instances can have local TPUs.')\n    with self.assertRaises(ValueError):\n      _ = distribute_utils.get_distribution_strategy('tpu')\n\n    ds = distribute_utils.get_distribution_strategy('tpu', tpu_address='local')\n    self.assertIsInstance(\n        ds, tf.distribute.TPUStrategy)\n\n  def test_invalid_strategy(self):\n    with self.assertRaisesRegex(\n        ValueError, 'distribution_strategy must be a string but got: False. If'\n    ):\n      distribute_utils.get_distribution_strategy(False)\n    with self.assertRaisesRegex(\n        ValueError, 'distribution_strategy must be a string but got: 1'\n    ):\n      distribute_utils.get_distribution_strategy(1)\n\n  def test_get_strategy_scope(self):\n    ds = distribute_utils.get_distribution_strategy('one_device', num_gpus=0)\n    with distribute_utils.get_strategy_scope(ds):\n      self.assertIs(tf.distribute.get_strategy(), ds)\n    with distribute_utils.get_strategy_scope(None):\n      self.assertIsNot(tf.distribute.get_strategy(), ds)\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/actions_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for TFM actions.\"\"\"\n\nimport os\n\nfrom absl.testing import parameterized\nimport numpy as np\nimport orbit\nimport tensorflow as tf, tf_keras\n\nfrom tensorflow.python.distribute import combinations\nfrom tensorflow.python.distribute import strategy_combinations\nfrom official.core import actions\nfrom official.modeling import optimization\n\n\nclass TestModel(tf_keras.Model):\n\n  def __init__(self):\n    super().__init__()\n    self.value = tf.Variable(0.0)\n    self.dense = tf_keras.layers.Dense(2)\n    _ = self.dense(tf.zeros((2, 2), tf.float32))\n\n  def call(self, x, training=None):\n    return self.value + x\n\n\nclass ActionsTest(tf.test.TestCase, parameterized.TestCase):\n\n  @combinations.generate(\n      combinations.combine(\n          distribution=[\n              strategy_combinations.cloud_tpu_strategy,\n              strategy_combinations.one_device_strategy,\n          ],))\n  def test_ema_checkpointing(self, distribution):\n    with distribution.scope():\n      directory = self.create_tempdir()\n      model = TestModel()\n      optimizer = tf_keras.optimizers.SGD()\n      optimizer = optimization.ExponentialMovingAverage(\n          optimizer, trainable_weights_only=False)\n\n      # Creats average weights for the model variables. Average weights are\n      # initialized to zero.\n      optimizer.shadow_copy(model)\n      checkpoint = tf.train.Checkpoint(model=model)\n\n      # Changes model.value to 3, average value is still 0.\n      model.value.assign(3)\n\n      # Checks model.value is 3\n      self.assertEqual(model(0.), 3)\n      ema_action = actions.EMACheckpointing(directory, optimizer, checkpoint)\n\n      ema_action({})\n      self.assertNotEmpty(\n          tf.io.gfile.glob(os.path.join(directory, 'ema_checkpoints')))\n\n      checkpoint.read(\n          tf.train.latest_checkpoint(\n              os.path.join(directory, 'ema_checkpoints')))\n\n      # Checks model.value is 0 after swapping.\n      self.assertEqual(model(0.), 0)\n\n      # Raises an error for a normal optimizer.\n      with self.assertRaisesRegex(ValueError,\n                                  'Optimizer has to be instance of.*'):\n        _ = actions.EMACheckpointing(directory, tf_keras.optimizers.SGD(),\n                                     checkpoint)\n\n  @combinations.generate(\n      combinations.combine(\n          distribution=[\n              strategy_combinations.default_strategy,\n              strategy_combinations.cloud_tpu_strategy,\n              strategy_combinations.one_device_strategy_gpu,\n          ],))\n  def test_recovery_condition(self, distribution):\n    with distribution.scope():\n      global_step = orbit.utils.create_global_step()\n      recover_condition = actions.RecoveryCondition(\n          global_step, loss_upper_bound=0.5, recovery_max_trials=2)\n      outputs = {'training_loss': 0.6}\n      self.assertTrue(recover_condition(outputs))\n      self.assertTrue(recover_condition(outputs))\n      with self.assertRaises(RuntimeError):\n        recover_condition(outputs)\n\n      global_step = orbit.utils.create_global_step()\n      recover_condition = actions.RecoveryCondition(\n          global_step, loss_upper_bound=0.5, recovery_max_trials=2)\n      outputs = {'training_loss': tf.constant([np.nan], tf.float32)}\n      self.assertTrue(recover_condition(outputs))\n      self.assertTrue(recover_condition(outputs))\n      with self.assertRaises(RuntimeError):\n        recover_condition(outputs)\n\n  @combinations.generate(\n      combinations.combine(\n          distribution=[\n              strategy_combinations.one_device_strategy_gpu,\n              strategy_combinations.one_device_strategy,\n          ],))\n  def test_pruning(self, distribution):\n    with distribution.scope():\n      directory = self.get_temp_dir()\n      model = TestModel()\n      optimizer = tf_keras.optimizers.SGD()\n      pruning = actions.PruningAction(directory, model, optimizer)\n\n      pruning({})\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/base_trainer_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for tensorflow_models.core.trainers.trainer.\"\"\"\n# pylint: disable=g-direct-tensorflow-import\nimport gc\nimport multiprocessing\nimport os\nimport sys\n\nfrom absl.testing import parameterized\nimport orbit\nimport portpicker\nimport tensorflow as tf, tf_keras\n\nfrom tensorflow.python.distribute import combinations\nfrom tensorflow.python.distribute import strategy_combinations\nfrom official.core import base_trainer as trainer_lib\nfrom official.core import config_definitions as cfg\nfrom official.core import train_lib\nfrom official.utils.testing import mock_task\n\nTPU_TEST = 'test_tpu' in sys.argv[0]\nGPU_TEST = 'test_gpu' in sys.argv[0]\n\n\ndef all_strategy_combinations():\n  return combinations.combine(\n      distribution=[\n          strategy_combinations.default_strategy,\n          strategy_combinations.cloud_tpu_strategy,\n          strategy_combinations.one_device_strategy_gpu,\n      ],)\n\n\ndef create_in_process_cluster(num_workers, num_ps):\n  \"\"\"Creates and starts local servers and returns the cluster_resolver.\"\"\"\n  worker_ports = [portpicker.pick_unused_port() for _ in range(num_workers)]\n  ps_ports = [portpicker.pick_unused_port() for _ in range(num_ps)]\n\n  cluster_dict = {}\n  cluster_dict['worker'] = ['localhost:%s' % port for port in worker_ports]\n  if num_ps > 0:\n    cluster_dict['ps'] = ['localhost:%s' % port for port in ps_ports]\n\n  cluster_spec = tf.train.ClusterSpec(cluster_dict)\n\n  # Workers need some inter_ops threads to work properly.\n  worker_config = tf.compat.v1.ConfigProto()\n  if multiprocessing.cpu_count() < num_workers + 1:\n    worker_config.inter_op_parallelism_threads = num_workers + 1\n\n  for i in range(num_workers):\n    tf.distribute.Server(\n        cluster_spec,\n        job_name='worker',\n        task_index=i,\n        config=worker_config,\n        protocol='grpc')\n\n  for i in range(num_ps):\n    tf.distribute.Server(\n        cluster_spec, job_name='ps', task_index=i, protocol='grpc')\n\n  cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(\n      cluster_spec, rpc_layer='grpc')\n  return cluster_resolver\n\n\ndef dataset_fn(input_context=None):\n  del input_context\n\n  def dummy_data(_):\n    return tf.zeros((1, 1), dtype=tf.float32)\n\n  dataset = tf.data.Dataset.range(1)\n  dataset = dataset.repeat()\n  dataset = dataset.map(\n      dummy_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  return dataset\n\n\nclass MockAsyncTrainer(trainer_lib._AsyncTrainer):\n  \"\"\"Mock AsyncTrainer to test the _AsyncTrainer class.\"\"\"\n\n  def __init__(self):\n    self._strategy = tf.distribute.get_strategy()\n    self.init_async()\n\n    self.global_step = tf.Variable(\n        0,\n        dtype=tf.int64,\n        name='global_step',\n        trainable=False,\n        aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n    self.eval_global_step = tf.Variable(\n        0,\n        dtype=tf.int64,\n        name='eval_global_step',\n        trainable=False,\n        aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)\n\n    train_dataset = self.distribute_dataset(dataset_fn)\n    orbit.StandardTrainer.__init__(\n        self, train_dataset, options=orbit.StandardTrainerOptions())\n\n    validation_dataset = self.distribute_dataset(dataset_fn)\n    orbit.StandardEvaluator.__init__(\n        self,\n        validation_dataset,\n        options=orbit.StandardEvaluatorOptions(use_tf_while_loop=True))\n\n  def train_loop_begin(self):\n    self.global_step.assign(0)\n\n  def train_step(self, iterator):\n\n    def replica_step(_):\n      self.global_step.assign_add(1)\n\n    self._strategy.run(replica_step, args=(next(iterator),))\n\n  def train_loop_end(self):\n    self.join()\n    return self.global_step.numpy()\n\n  def eval_begin(self):\n    self.eval_global_step.assign(0)\n\n  def eval_step(self, iterator):\n\n    def replica_step(_):\n      self.eval_global_step.assign_add(1)\n\n    self._strategy.run(replica_step, args=(next(iterator),))\n\n  def eval_end(self):\n    self.join()\n    return self.eval_global_step.numpy()\n\n\nclass TrainerTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    self._config = cfg.ExperimentConfig(\n        trainer=cfg.TrainerConfig(\n            optimizer_config=cfg.OptimizationConfig({\n                'optimizer': {\n                    'type': 'sgd'\n                },\n                'learning_rate': {\n                    'type': 'constant'\n                }\n            })))\n\n  def tearDown(self):\n    gc.collect()\n    # This will only contain uncollectable garbage, i.e. reference cycles\n    # involving objects with __del__ defined.\n    self.assertEmpty(gc.garbage)\n    super().tearDown()\n\n  def create_test_trainer(self, config, model_dir=None, task=None):\n    task = task or mock_task.MockTask(config.task, logging_dir=model_dir)\n    ckpt_exporter = train_lib.maybe_create_best_ckpt_exporter(config, model_dir)\n    trainer = trainer_lib.Trainer(\n        config,\n        task,\n        model=task.build_model(),\n        optimizer=task.create_optimizer(config.trainer.optimizer_config,\n                                        config.runtime),\n        checkpoint_exporter=ckpt_exporter)\n    return trainer\n\n  @combinations.generate(all_strategy_combinations())\n  def test_trainer_train(self, distribution):\n    with distribution.scope():\n      trainer = self.create_test_trainer(self._config)\n      logs = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))\n      self.assertIn('training_loss', logs)\n      self.assertIn('learning_rate', logs)\n\n  @combinations.generate(all_strategy_combinations())\n  def test_trainer_passing_datasets(self, distribution):\n    with distribution.scope():\n      task = mock_task.MockTask(self._config)\n      train_dataset = orbit.utils.make_distributed_dataset(\n          distribution, task.build_inputs, self._config.task.train_data)\n      validation_dataset = orbit.utils.make_distributed_dataset(\n          distribution, task.build_inputs, self._config.task.validation_data)\n      self._config.task.train_data = None\n      self._config.task.validation_data = None\n      trainer = trainer_lib.Trainer(\n          self._config,\n          task,\n          model=task.build_model(),\n          optimizer=task.create_optimizer(self._config.trainer.optimizer_config,\n                                          self._config.runtime),\n          train_dataset=train_dataset,\n          validation_dataset=validation_dataset)\n    logs = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))\n    self.assertIn('training_loss', logs)\n    self.assertIn('learning_rate', logs)\n    logs = trainer.evaluate(tf.convert_to_tensor(5, dtype=tf.int32))\n    self.assertIn('validation_loss', logs)\n\n  def test_base_async_trainer(self):\n    if TPU_TEST or GPU_TEST:\n      self.skipTest('Aysnc training is not available on GPU/GPU.')\n    num_workers = 3\n    num_ps = 2\n    cluster_resolver = create_in_process_cluster(num_workers, num_ps)\n    distribution = tf.distribute.experimental.ParameterServerStrategy(\n        cluster_resolver)\n    with distribution.scope():\n      trainer = MockAsyncTrainer()\n      trainer.init_async()\n      self.assertIsInstance(\n          trainer._coordinator,\n          tf.distribute.experimental.coordinator.ClusterCoordinator)\n      self.assertEqual(trainer.train(tf.constant(10)), 10)\n      self.assertEqual(trainer.evaluate(tf.constant(11)), 11)\n\n  def test_async_trainer_train(self):\n    if TPU_TEST or GPU_TEST:\n      self.skipTest('Aysnc training is not available on GPU/TPU.')\n    num_workers = 3\n    num_ps = 2\n    cluster_resolver = create_in_process_cluster(num_workers, num_ps)\n    distribution = tf.distribute.experimental.ParameterServerStrategy(\n        cluster_resolver)\n    with distribution.scope():\n      config = cfg.ExperimentConfig(**self._config.as_dict())\n      config.trainer.eval_tf_while_loop = True\n      trainer = self.create_test_trainer(config)\n      logs = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))\n      self.assertIn('training_loss', logs)\n      self.assertIn('learning_rate', logs)\n\n  def test_async_trainer_validate(self):\n    if TPU_TEST or GPU_TEST:\n      self.skipTest('Aysnc training is not available on GPU/GPU.')\n    num_workers = 3\n    num_ps = 2\n    cluster_resolver = create_in_process_cluster(num_workers, num_ps)\n    distribution = tf.distribute.experimental.ParameterServerStrategy(\n        cluster_resolver)\n    with distribution.scope():\n      config = cfg.ExperimentConfig(**self._config.as_dict())\n      config.trainer.eval_tf_while_loop = True\n      trainer = self.create_test_trainer(config)\n      logs = trainer.evaluate(tf.convert_to_tensor(5, dtype=tf.int32))\n      self.assertIn('acc', logs)\n      self.assertIn('validation_loss', logs)\n\n  @combinations.generate(all_strategy_combinations())\n  def test_trainer_validate(self, distribution):\n    with distribution.scope():\n      trainer = self.create_test_trainer(self._config)\n      logs = trainer.evaluate(tf.convert_to_tensor(5, dtype=tf.int32))\n      self.assertEqual(logs['counter'], 5. * distribution.num_replicas_in_sync)\n      self.assertIn('validation_loss', logs)\n\n  @combinations.generate(all_strategy_combinations())\n  def test_trainer_validate_without_loss(self, distribution):\n\n    class MockTaskWithoutValidationLoss(mock_task.MockTask):\n\n      def validation_step(self, inputs, model, metrics=None):\n        # Disable validation loss.\n        logs = super().validation_step(inputs, model)\n        del logs[self.loss]\n        return logs\n\n    with distribution.scope():\n      task = MockTaskWithoutValidationLoss()\n      trainer = self.create_test_trainer(self._config, task=task)\n      logs = trainer.evaluate(tf.convert_to_tensor(5, dtype=tf.int32))\n      self.assertEqual(logs['counter'], 5. * distribution.num_replicas_in_sync)\n      self.assertNotIn('validation_loss', logs)\n\n  @combinations.generate(\n      combinations.combine(\n          mixed_precision_dtype=['float32', 'bfloat16', 'float16'],\n          loss_scale=[None, 'dynamic', 128, 256],\n      ))\n  def test_configure_optimizer(self, mixed_precision_dtype, loss_scale):\n    config = cfg.ExperimentConfig(\n        runtime=cfg.RuntimeConfig(\n            mixed_precision_dtype=mixed_precision_dtype, loss_scale=loss_scale),\n        trainer=cfg.TrainerConfig(\n            optimizer_config=cfg.OptimizationConfig({\n                'optimizer': {\n                    'type': 'sgd'\n                },\n                'learning_rate': {\n                    'type': 'constant'\n                },\n            })))\n    trainer = self.create_test_trainer(config)\n    if mixed_precision_dtype == 'float16':\n      self.assertIsInstance(trainer.optimizer,\n                            tf_keras.mixed_precision.LossScaleOptimizer)\n      if loss_scale in (None, 'dynamic'):\n        self.assertTrue(trainer.optimizer.dynamic)\n      else:\n        self.assertFalse(trainer.optimizer.dynamic)\n        self.assertEqual(trainer.optimizer.initial_scale, loss_scale)\n    else:\n      self.assertIsInstance(\n          trainer.optimizer,\n          (tf_keras.optimizers.SGD, tf_keras.optimizers.legacy.SGD))\n\n    metrics = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))\n    self.assertIn('training_loss', metrics)\n\n  def test_export_best_ckpt(self):\n    config = cfg.ExperimentConfig(\n        trainer=cfg.TrainerConfig(\n            best_checkpoint_export_subdir='best_ckpt',\n            best_checkpoint_eval_metric='acc',\n            optimizer_config=cfg.OptimizationConfig({\n                'optimizer': {\n                    'type': 'sgd'\n                },\n                'learning_rate': {\n                    'type': 'constant'\n                }\n            })))\n    model_dir = self.get_temp_dir()\n    trainer = self.create_test_trainer(config, model_dir=model_dir)\n    trainer.train(tf.convert_to_tensor(1, dtype=tf.int32))\n    trainer.evaluate(tf.convert_to_tensor(1, dtype=tf.int32))\n    self.assertTrue(\n        tf.io.gfile.exists(os.path.join(model_dir, 'best_ckpt', 'info.json')))\n\n  def test_model_with_compiled_loss(self):\n    task = mock_task.MockTask()\n    model = task.build_model()\n    model.compile(loss=tf_keras.losses.CategoricalCrossentropy())\n    trainer = trainer_lib.Trainer(\n        self._config,\n        task,\n        model=model,\n        optimizer=task.create_optimizer(self._config.trainer.optimizer_config))\n    logs = trainer.train(tf.convert_to_tensor(5, dtype=tf.int32))\n    self.assertIn('training_loss', logs)\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/export_base_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for official.core.export_base.\"\"\"\nimport os\nfrom typing import Any, Dict, Mapping, Text\n\nimport tensorflow as tf, tf_keras\n\nfrom official.core import export_base\n\n\nclass TestModule(export_base.ExportModule):\n\n  @tf.function\n  def serve(self, inputs: tf.Tensor) -> Mapping[Text, tf.Tensor]:\n    x = inputs if self.preprocessor is None else self.preprocessor(\n        inputs=inputs)\n    x = self.inference_step(x)\n    x = self.postprocessor(x) if self.postprocessor else x\n    return {'outputs': x}\n\n  def get_inference_signatures(\n      self, function_keys: Dict[Text, Text]) -> Mapping[Text, Any]:\n    input_signature = tf.TensorSpec(shape=[None, None], dtype=tf.float32)\n    return {'foo': self.serve.get_concrete_function(input_signature)}\n\n\nclass ExportBaseTest(tf.test.TestCase):\n\n  def test_export_module(self):\n    tmp_dir = self.get_temp_dir()\n    model = tf_keras.layers.Dense(2)\n    inputs = tf.ones([2, 4], tf.float32)\n    expected_output = model(inputs, training=False)\n    module = TestModule(params=None, model=model)\n    ckpt_path = tf.train.Checkpoint(model=model).save(\n        os.path.join(tmp_dir, 'ckpt'))\n    export_dir = export_base.export(\n        module, ['foo'],\n        export_savedmodel_dir=tmp_dir,\n        checkpoint_path=ckpt_path,\n        timestamped=True)\n    self.assertTrue(os.path.exists(os.path.join(export_dir, 'saved_model.pb')))\n    self.assertTrue(\n        os.path.exists(\n            os.path.join(export_dir, 'variables', 'variables.index')))\n    self.assertTrue(\n        os.path.exists(\n            os.path.join(export_dir, 'variables',\n                         'variables.data-00000-of-00001')))\n\n    imported = tf.saved_model.load(export_dir)\n    output = imported.signatures['foo'](inputs)\n    self.assertAllClose(output['outputs'].numpy(), expected_output.numpy())\n\n  def test_custom_inference_step(self):\n    tmp_dir = self.get_temp_dir()\n    model = tf_keras.layers.Dense(2)\n    inputs = tf.ones([2, 4], tf.float32)\n\n    def _inference_step(inputs, model):\n      return tf.nn.softmax(model(inputs, training=False))\n\n    module = TestModule(\n        params=None, model=model, inference_step=_inference_step)\n    expected_output = _inference_step(inputs, model)\n    ckpt_path = tf.train.Checkpoint(model=model).save(\n        os.path.join(tmp_dir, 'ckpt'))\n    export_dir = export_base.export(\n        module, ['foo'],\n        export_savedmodel_dir=tmp_dir,\n        checkpoint_path=ckpt_path,\n        timestamped=False)\n    imported = tf.saved_model.load(export_dir)\n    output = imported.signatures['foo'](inputs)\n    self.assertAllClose(output['outputs'].numpy(), expected_output.numpy())\n\n  def test_processors(self):\n    model = tf.Module()\n    inputs = tf.zeros((), tf.float32)\n\n    def _inference_step(inputs, model):\n      del model\n      return inputs + 1.0\n\n    def _preprocessor(inputs):\n      print(inputs)\n      return inputs + 0.1\n\n    module = TestModule(\n        params=None,\n        model=model,\n        inference_step=_inference_step,\n        preprocessor=_preprocessor)\n    output = module.serve(inputs)\n    self.assertAllClose(output['outputs'].numpy(), 1.1)\n\n    class _PostProcessor(tf.Module):\n\n      def __call__(self, inputs):\n        return inputs + 0.01\n\n    module = TestModule(\n        params=None,\n        model=model,\n        inference_step=_inference_step,\n        preprocessor=_preprocessor,\n        postprocessor=_PostProcessor())\n    output = module.serve(inputs)\n    self.assertAllClose(output['outputs'].numpy(), 1.11)\n\n  def test_get_timestamped_export_dir(self):\n    export_dir = self.get_temp_dir()\n    timed_dir = export_base.get_timestamped_export_dir(\n        export_dir_base=export_dir)\n    self.assertFalse(tf.io.gfile.exists(timed_dir))\n    self.assertIn(export_dir, str(timed_dir))\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/file_writers_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for file_writers.\"\"\"\n\nimport os\nfrom absl.testing import parameterized\nimport tensorflow as tf, tf_keras\n\nfrom official.core import file_writers\nfrom official.core import tf_example_builder\n\n\nclass FileWritersTest(tf.test.TestCase, parameterized.TestCase):\n\n  def setUp(self):\n    super().setUp()\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_bytes_feature('foo', 'Hello World!')\n    self._example = example_builder.example\n\n  @parameterized.parameters('tfrecord', 'TFRecord', 'tfrecords',\n                            'tfrecord_compressed', 'TFRecord_Compressed',\n                            'tfrecords_gzip')\n  def test_write_small_dataset_success(self, file_type):\n    temp_dir = self.create_tempdir()\n    temp_dataset_file = os.path.join(temp_dir.full_path, 'train')\n    file_writers.write_small_dataset([self._example], temp_dataset_file,\n                                     file_type)\n    self.assertTrue(os.path.exists(temp_dataset_file))\n\n  def test_write_small_dataset_unrecognized_format(self):\n    file_type = 'bar'\n    temp_dir = self.create_tempdir()\n    temp_dataset_file = os.path.join(temp_dir.full_path, 'train')\n    with self.assertRaises(ValueError):\n      file_writers.write_small_dataset([self._example], temp_dataset_file,\n                                       file_type)\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/registry_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for registry.\"\"\"\n\nimport tensorflow as tf, tf_keras\nfrom official.core import registry\n\n\nclass RegistryTest(tf.test.TestCase):\n\n  def test_register(self):\n    collection = {}\n\n    @registry.register(collection, 'functions/func_0')\n    def func_test():\n      pass\n\n    self.assertEqual(registry.lookup(collection, 'functions/func_0'), func_test)\n\n    @registry.register(collection, 'classes/cls_0')\n    class ClassRegistryKey:\n      pass\n\n    self.assertEqual(\n        registry.lookup(collection, 'classes/cls_0'), ClassRegistryKey)\n\n    @registry.register(collection, ClassRegistryKey)\n    class ClassRegistryValue:\n      pass\n\n    self.assertEqual(\n        registry.lookup(collection, ClassRegistryKey), ClassRegistryValue)\n\n  def test_register_hierarchy(self):\n    collection = {}\n\n    @registry.register(collection, 'functions/func_0')\n    def func_test0():\n      pass\n\n    @registry.register(collection, 'func_1')\n    def func_test1():\n      pass\n\n    @registry.register(collection, func_test1)\n    def func_test2():\n      pass\n\n    expected_collection = {\n        'functions': {\n            'func_0': func_test0,\n        },\n        'func_1': func_test1,\n        func_test1: func_test2,\n    }\n    self.assertEqual(collection, expected_collection)\n\n  def test_register_error(self):\n    collection = {}\n\n    @registry.register(collection, 'functions/func_0')\n    def func_test0():  # pylint: disable=unused-variable\n      pass\n\n    with self.assertRaises(KeyError):\n\n      @registry.register(collection, 'functions/func_0/sub_func')\n      def func_test1():  # pylint: disable=unused-variable\n        pass\n\n    with self.assertRaises(LookupError):\n      registry.lookup(collection, 'non-exist')\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/savedmodel_checkpoint_manager_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport time\nfrom typing import Iterable\n\nimport tensorflow as tf, tf_keras\n\nfrom official.core import savedmodel_checkpoint_manager\n\n\ndef _models_exist(checkpoint_path: str, models: Iterable[str]) -> bool:\n  for model_name in models:\n    if not tf.io.gfile.isdir(\n        os.path.join(\n            savedmodel_checkpoint_manager.make_saved_modules_directory_name(\n                checkpoint_path), model_name)):\n      return False\n  return True\n\n\nclass _ModelForTest(tf_keras.Model):\n  def __init__(self, hidden_size: int = 8):\n    super().__init__()\n    self.dense = tf_keras.layers.Dense(hidden_size)\n\n  @tf.function(input_signature=[tf.TensorSpec([None, 16])])\n  def call(self, inputs):\n    return self.dense(inputs)\n\n  @property\n  def saved_model_signatures(self):\n    # Build SavedModel signatures.\n    return dict(serving_default=self.call)\n\n\nclass CheckpointManagerTest(tf.test.TestCase):\n\n  def _create_manager(self, max_to_keep: int = 1) -> tf.train.CheckpointManager:\n    \"\"\"Sets up SavedModelCheckpointManager object.\n\n    Args:\n      max_to_keep: max number of savedmodels to keep.\n\n    Returns:\n      created savedmodel manager.\n    \"\"\"\n    models = {\n        'model_1': _ModelForTest(12),\n        'model_2': _ModelForTest(14),\n    }\n    checkpoint = tf.train.Checkpoint()\n    manager = savedmodel_checkpoint_manager.SavedModelCheckpointManager(\n        checkpoint=checkpoint,\n        directory=self.get_temp_dir(),\n        max_to_keep=max_to_keep,\n        modules_to_export=models)\n    return manager\n\n  def test_max_to_keep(self):\n    manager = self._create_manager()\n    models = manager.modules_to_export\n    first_path = manager.save()\n    second_path = manager.save()\n\n    savedmodel = savedmodel_checkpoint_manager.make_saved_modules_directory_name(\n        manager.latest_checkpoint)\n    self.assertEqual(savedmodel, manager.latest_savedmodel)\n    self.assertTrue(_models_exist(second_path, models.keys()))\n    self.assertFalse(_models_exist(first_path, models.keys()))\n\n  def test_returns_none_after_timeout(self):\n    manager = self._create_manager()\n    start = time.time()\n    ret = manager.wait_for_new_savedmodel(\n        None, timeout=1.0, seconds_to_sleep=0.5)\n    end = time.time()\n    self.assertIsNone(ret)\n    # We've waited 0.5 second.\n    self.assertGreater(end, start + 0.5)\n    # The timeout kicked in.\n    self.assertLess(end, start + 0.6)\n\n  def test_saved_model_iterator(self):\n    manager = self._create_manager(max_to_keep=2)\n    self.assertIsNotNone(manager.save(checkpoint_number=1))\n    self.assertIsNotNone(manager.save(checkpoint_number=2))\n    self.assertIsNotNone(manager.save(checkpoint_number=3))\n\n    # Savedmodels are in time order.\n    expected_savedmodels = manager.savedmodels\n    # Order not guaranteed.\n    existing_savedmodels = manager.get_existing_savedmodels()\n    savedmodels = list(manager.savedmodels_iterator(timeout=3.0))\n    self.assertEqual(savedmodels, expected_savedmodels)\n    self.assertEqual(set(savedmodels), set(existing_savedmodels))\n\n  def test_saved_model_iterator_timeout_fn(self):\n    manager = self._create_manager()\n    timeout_fn_calls = [0]\n\n    def timeout_fn():\n      timeout_fn_calls[0] += 1\n      return timeout_fn_calls[0] > 3\n\n    results = list(\n        manager.savedmodels_iterator(timeout=0.1, timeout_fn=timeout_fn))\n    self.assertEqual([], results)\n    self.assertEqual(4, timeout_fn_calls[0])\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/test_utils.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Utils for testing.\"\"\"\n\nimport tensorflow as tf, tf_keras\n\n\nclass FakeKerasModel(tf_keras.Model):\n  \"\"\"Fake keras model for testing.\"\"\"\n\n  def __init__(self):\n    super().__init__()\n    self.dense = tf_keras.layers.Dense(4, activation=tf.nn.relu)\n    self.dense2 = tf_keras.layers.Dense(4, activation=tf.nn.relu)\n\n  def call(self, inputs):  # pytype: disable=signature-mismatch  # overriding-parameter-count-checks\n    return self.dense2(self.dense(inputs))\n\n\nclass _Dense(tf.Module):\n  \"\"\"A dense layer.\"\"\"\n\n  def __init__(self, input_dim, output_size, name=None):\n    super().__init__(name=name)\n    with self.name_scope:\n      self.w = tf.Variable(\n          tf.random.normal([input_dim, output_size]), name='w')\n      self.b = tf.Variable(tf.zeros([output_size]), name='b')\n\n  @tf.Module.with_name_scope\n  def __call__(self, x):\n    y = tf.matmul(x, self.w) + self.b\n    return tf.nn.relu(y)\n\n\nclass FakeModule(tf.Module):\n  \"\"\"Fake model using tf.Module for testing.\"\"\"\n\n  def __init__(self, input_size, name=None):\n    super().__init__(name=name)\n    with self.name_scope:\n      self.dense = _Dense(input_size, 4, name='dense')\n      self.dense2 = _Dense(4, 4, name='dense_1')\n\n  @tf.Module.with_name_scope\n  def __call__(self, x):\n    return self.dense2(self.dense(x))\n",
    "official/core/tf_example_builder_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for tf_example_builder.\n\nSee `test_add_image_matrix_feature_with_fake_image` for the typical structure of\na unit test.\n\"\"\"\n\nfrom absl.testing import parameterized\nimport tensorflow as tf, tf_keras\nfrom official.core import tf_example_builder\n\n\nclass TfExampleBuilderTest(tf.test.TestCase, parameterized.TestCase):\n\n  def test_init_an_empty_example(self):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example = example_builder.example\n    self.assertProtoEquals('', example)\n\n  def test_init_an_empty_serialized_example(self):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example = example_builder.serialized_example\n    self.assertProtoEquals('', example)\n\n  def test_add_feature(self):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_feature(\n        'foo',\n        tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[b'Hello World!'])))\n    example = example_builder.example\n    # Use proto text to show how the entire proto would look like.\n    self.assertProtoEquals(\n        \"\"\"\n        features: {\n          feature: {\n            key: \"foo\"\n            value: {\n              bytes_list: {\n                value: \"Hello World!\"\n              }\n            }\n          }\n        }\"\"\", example)\n\n  def test_add_feature_dict(self):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_feature_dict({\n        'foo':\n            tf.train.Feature(\n                bytes_list=tf.train.BytesList(value=[b'Hello World!'])),\n        'bar':\n            tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[299, 792, 458]))\n    })\n    example = example_builder.example\n    # Use proto text to show how the entire proto would look like.\n    self.assertProtoEquals(\n        \"\"\"\n        features: {\n          feature: {\n            key: \"foo\"\n            value: {\n              bytes_list: {\n                value: \"Hello World!\"\n              }\n            }\n          }\n          feature: {\n            key: \"bar\"\n            value: {\n              int64_list: {\n                value: 299\n                value: 792\n                value: 458\n              }\n            }\n          }\n        }\"\"\", example)\n\n  @parameterized.named_parameters(\n      ('single_bytes', b'Hello World!', b'Hello World!'),\n      ('single_string', 'Hello World!', b'Hello World!'))\n  def test_add_single_byte_feature(self, value, expected_value):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_bytes_feature('foo', value)\n    example = example_builder.example\n    # Use constructor to easily work with test parameters.\n    self.assertProtoEquals(\n        tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    'foo':\n                        tf.train.Feature(\n                            bytes_list=tf.train.BytesList(\n                                value=[expected_value]))\n                })), example)\n\n  @parameterized.named_parameters(\n      ('multiple_bytes', [b'Hello World!', b'Good Morning!'\n                         ], [b'Hello World!', b'Good Morning!']),\n      ('multiple_sring', ['Hello World!', 'Good Morning!'\n                         ], [b'Hello World!', b'Good Morning!']))\n  def test_add_multiple_bytes_feature(self, values, expected_values):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_bytes_feature('foo', values)\n    example = example_builder.example\n    self.assertProtoEquals(\n        tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    'foo':\n                        tf.train.Feature(\n                            bytes_list=tf.train.BytesList(\n                                value=expected_values))\n                })), example)\n\n  @parameterized.named_parameters(\n      ('single_integer', 123, [123]),\n      ('multiple_integers', [123, 456, 789], [123, 456, 789]))\n  def test_add_ints_feature(self, value, expected_value):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_ints_feature('bar', value)\n    example = example_builder.example\n    self.assertProtoEquals(\n        tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    'bar':\n                        tf.train.Feature(\n                            int64_list=tf.train.Int64List(value=expected_value))\n                })), example)\n\n  @parameterized.named_parameters(\n      ('single_float', 3.14, [3.14]),\n      ('multiple_floats', [3.14, 1.57, 6.28], [3.14, 1.57, 6.28]))\n  def test_add_floats_feature(self, value, expected_value):\n    example_builder = tf_example_builder.TfExampleBuilder()\n    example_builder.add_floats_feature('baz', value)\n    example = example_builder.example\n    self.assertProtoEquals(\n        tf.train.Example(\n            features=tf.train.Features(\n                feature={\n                    'baz':\n                        tf.train.Feature(\n                            float_list=tf.train.FloatList(value=expected_value))\n                })), example)\n\n\nif __name__ == '__main__':\n  tf.test.main()\n",
    "official/core/tf_example_feature_key_test.py": "# Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Tests for tf_example_feature_key.\"\"\"\nimport dataclasses\nimport inspect\nfrom absl.testing import absltest\nfrom absl.testing import parameterized\n\nfrom official.core import tf_example_feature_key\n\n\n@tf_example_feature_key.dataclass\nclass TestFeatureKey(tf_example_feature_key.TfExampleFeatureKeyBase):\n  test: str = 'foo/bar'\n\n\nclass TfExampleFeatureKeyTest(parameterized.TestCase):\n\n  def test_add_prefix_success(self):\n    test_key = TestFeatureKey('prefix')\n    self.assertEqual(test_key.test, 'prefix/foo/bar')\n\n  @parameterized.parameters(None, '')\n  def test_add_prefix_skip_success(self, prefix):\n    test_key = TestFeatureKey(prefix)\n    self.assertEqual(test_key.test, 'foo/bar')\n\n  def test_all_feature_key_classes_are_valid(self):\n    for _, obj in inspect.getmembers(tf_example_feature_key):\n      if inspect.isclass(obj):\n        self.assertTrue(dataclasses.is_dataclass(obj))\n        self.assertTrue(\n            issubclass(obj, tf_example_feature_key.TfExampleFeatureKeyBase))\n\n\nif __name__ == '__main__':\n  absltest.main()\n"
  },
  "requirements": null
}